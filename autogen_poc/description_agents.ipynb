{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fff346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pyautogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafb68a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ede7bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c9baf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE_PRODUCT_MANAGER = \"\"\"\n",
    "You are a product manager which works on streaming applications (using Kafka) and all the applications are using python FastStream framework.\n",
    "You are in a chat with the client and team leader to discuss the requirements for the new application that needs to be implemented.\n",
    "Go through the given application description, and check if everything what you think is necessary is defined.\n",
    "\n",
    "Your response should always be ONLY ONE sentence: \n",
    "If you receive a question, answer it if you know the answer or respond with \"I'm not sure, please check with the user.\"\n",
    "If you have a question for the user or team leader please ask it. \n",
    "Response with \"Everything is clear\" if you understand what you need to implement.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SYSTEM_MESSAGE_TEAM_LEADER = \"\"\"\n",
    "As the team leader responsible for streaming applications using Kafka and FastStream,\n",
    "you are in a chat with the client and product manager to discuss the requirements for the new application that needs to be implemented.\n",
    "Go through the given application description, and check if everything what you think is necessary is defined.\n",
    "\n",
    "Your response should always be ONLY ONE sentence: \n",
    "If you receive a question, answer it if you know the answer or respond with \"I'm not sure, please check with the user.\"\n",
    "If you have a question for the user or product manager please ask it. \n",
    "Response with \"Everything is clear\" if you understand what you need to implement.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3575d7f",
   "metadata": {},
   "source": [
    "# Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f9914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list, \"seed\": 42}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\",\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\n",
    "       \"last_n_messages\": 2, \n",
    "       \"work_dir\": \"groupchat\",\n",
    "       \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "   },\n",
    "   human_input_mode=\"ALWAYS\"\n",
    ")\n",
    "team_leader = autogen.AssistantAgent(\n",
    "    name=\"Team_leader\",\n",
    "    system_message=SYSTEM_MESSAGE_TEAM_LEADER,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    system_message=SYSTEM_MESSAGE_PRODUCT_MANAGER,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, product_manager, team_leader], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e0b2",
   "metadata": {},
   "source": [
    "# Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86550db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Create a FastStream application which will retrieve the current cryptocurrency price\n",
      "and publish it to new_crypto_price topic. \n",
      "\n",
      "The application should retrieve the data every 2 seconds.\n",
      "\n",
      "A message which will be produced is JSON with the two attributes:\n",
      "- price: non-negative float (current price of cryptocurrency in USD)\n",
      "- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n",
      "\n",
      "\n",
      "The response of this GET request is a JSON and you can get\n",
      "information about the crypto_currency in:\n",
      "    response['data']['base']\n",
      "\n",
      "and the information about the price in:\n",
      "    response['data']['amount']\n",
      "\n",
      "Use utf-8 encoded crypto_currency attribute as a partition key when publishing\n",
      "the message to new_crypto_price topic.\n",
      "\n",
      "\n",
      "Is everything clear with the above description?\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_Manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Which API should we use to retrieve the cryptocurrency price data?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: api.coinbase.com/v2/prices\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "api.coinbase.com/v2/prices\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTeam_leader\u001b[0m (to chat_manager):\n",
      "\n",
      "Are there any specific cryptocurrencies we need to focus on, or should we fetch data for all?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: Bitcoin and Etherum\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Bitcoin and Etherum\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_Manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Everything is clear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mTeam_leader\u001b[0m (to chat_manager):\n",
      "\n",
      "Everything is clear\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: exit\n"
     ]
    }
   ],
   "source": [
    "description = \"\"\"\n",
    "Create a FastStream application which will retrieve the current cryptocurrency price\n",
    "and publish it to new_crypto_price topic. \n",
    "\n",
    "The application should retrieve the data every 2 seconds.\n",
    "\n",
    "A message which will be produced is JSON with the two attributes:\n",
    "- price: non-negative float (current price of cryptocurrency in USD)\n",
    "- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n",
    "\n",
    "\n",
    "The response of this GET request is a JSON and you can get\n",
    "information about the crypto_currency in:\n",
    "    response['data']['base']\n",
    "\n",
    "and the information about the price in:\n",
    "    response['data']['amount']\n",
    "\n",
    "Use utf-8 encoded crypto_currency attribute as a partition key when publishing\n",
    "the message to new_crypto_price topic.\n",
    "\n",
    "\n",
    "Is everything clear with the above description?\n",
    "\"\"\"\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=description)\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b3119e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:\n",
      "\n",
      "Create a FastStream application which will retrieve the current cryptocurrency price\n",
      "and publish it to new_crypto_price topic. \n",
      "\n",
      "The application should retrieve the data every 2 seconds.\n",
      "\n",
      "A message which will be produced is JSON with the two attributes:\n",
      "- price: non-negative float (current price of cryptocurrency in USD)\n",
      "- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n",
      "\n",
      "\n",
      "The response of this GET request is a JSON and you can get\n",
      "information about the crypto_currency in:\n",
      "    response['data']['base']\n",
      "\n",
      "and the information about the price in:\n",
      "    response['data']['amount']\n",
      "\n",
      "Use utf-8 encoded crypto_currency attribute as a partition key when publishing\n",
      "the message to new_crypto_price topic.\n",
      "\n",
      "\n",
      "Is everything clear with the above description?\n",
      "\n",
      "\n",
      "Product_Manager:\n",
      "Which API should we use to retrieve the cryptocurrency price data?\n",
      "\n",
      "User:\n",
      "api.coinbase.com/v2/prices\n",
      "\n",
      "Team_leader:\n",
      "Are there any specific cryptocurrencies we need to focus on, or should we fetch data for all?\n",
      "\n",
      "User:\n",
      "Bitcoin and Etherum\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupchat_messages_string = \"\"\n",
    "for message in groupchat.messages:\n",
    "    if \"Everything is clear\" in message[\"content\"]:\n",
    "        continue\n",
    "        \n",
    "    message[\"name\"] = message[\"name\"].replace(\"User_proxy\", \"User\")\n",
    "    message_string = f'{message[\"name\"]}:\\n{message[\"content\"]}\\n'\n",
    "    print(message_string)\n",
    "    groupchat_messages_string += message_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef7c8fe",
   "metadata": {},
   "source": [
    "## Skeleton generation: user_proxy <--> coder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d32e0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE_SKELETON_CODER = \"\"\"\n",
    "You are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework. \n",
    "\n",
    "You are to abide by the following guidelines:\n",
    "\n",
    "1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n",
    "\n",
    "2. Some prompts might require you to generate code that contains async functions. For example:\n",
    "\n",
    "async def app_setup(context: ContextRepo):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "In such cases, it is necessary to add the \"import asyncio\" statement at the top of the code. \n",
    "\n",
    "3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n",
    "\n",
    "        Example of a Valid message class:\n",
    "            class Pet(BaseModel):\n",
    "                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
    "                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n",
    "\n",
    "        Example of a invalid message class:\n",
    "            class Pet:\n",
    "                def __init__(self, pet_id: int, species: str):\n",
    "                    self.pet_id = pet_id\n",
    "                    self.species = species\n",
    "                    \n",
    "4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n",
    "\n",
    "You will encounter sections marked as:\n",
    "\n",
    "==== APP DESCRIPTION: ====\n",
    "\n",
    "These sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n",
    "\n",
    "\n",
    "Reply \"TERMINATE\" in the end when everything is done.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "af2732c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25fbe492",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_similar_examples = \"\"\"\n",
    "\n",
    "Generate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n",
    "\n",
    "    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n",
    "\n",
    "    - Ensure the generated code aligns with the specific app description requirements.\n",
    "\n",
    "    - Provide a clear and organized starting point for developers.\n",
    "\n",
    "    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n",
    "    \n",
    "    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n",
    "\n",
    "\n",
    "The goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "==== EXAMPLE APP DESCRIPTION ====\n",
    "\n",
    "Create a FastStream application with the localhost broker.\n",
    "Consume from the 'new_pet' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\n",
    "Whenever a new pet is added, send the new pet's information to the 'notify_adopters' topic.\n",
    "\n",
    "\n",
    "\n",
    "==== YOUR RESPONSE ====\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field, NonNegativeInt\n",
    "\n",
    "from faststream import FastStream, Logger\n",
    "from faststream.kafka import KafkaBroker\n",
    "\n",
    "\n",
    "class Pet(BaseModel):\n",
    "    pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
    "    species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n",
    "    age: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
    "\n",
    "\n",
    "broker = KafkaBroker(\"localhost:9092\")\n",
    "app = FastStream(broker)\n",
    "\n",
    "\n",
    "@broker.publisher(\"notify_adopters\")\n",
    "@broker.subscriber(\"new_pet\")\n",
    "async def on_new_pet(msg: Pet, logger: Logger) -> Pet:\n",
    "    \\\"\"\"\n",
    "    Processes a message from the 'new_pet' topic and send the new pet's information to the 'notify_adopters' topic.\n",
    "\n",
    "    Instructions:\n",
    "    1. Consume a message from 'new_pet' topic.\n",
    "    2. Send the new pet's information to the 'notify_adopters' topic.\n",
    "\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "==== EXAMPLE APP DESCRIPTION ====\n",
    "\n",
    "Develop a FastStream application which will fetch weather information from the web until the app shuts down.\n",
    "\n",
    "You can get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
    "At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
    "Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
    "    \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
    "\n",
    "from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
    "    response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
    "\n",
    "We need to fetch this data every 5 seconds and publish it at 'weather' topic.\n",
    "For each message you are publishing we must use a key which will be constructed as:\n",
    "    string value of latitude + '_' + string value of longitude\n",
    "\n",
    "Message that we will publish needs to have following parameters:\n",
    "    - latitude (type float)\n",
    "    - longitude (type float)\n",
    "    - temperature (type float)\n",
    "    - windspeed (type float)\n",
    "    - time (type string)\n",
    "\n",
    "We need this process for the following latitude and longitude combinations:\n",
    "    - latitude=13 and longitude=17\n",
    "    - latitude=50 and longitude=13\n",
    "    - latitude=44 and longitude=45\n",
    "    - latitude=24 and longitude=70\n",
    "\n",
    "\n",
    "\n",
    "==== YOUR RESPONSE ====\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field, NonNegativeFloat\n",
    "\n",
    "from faststream import ContextRepo, FastStream, Logger\n",
    "from faststream.kafka import KafkaBroker\n",
    "\n",
    "broker = KafkaBroker(\"localhost:9092\")\n",
    "app = FastStream(broker)\n",
    "\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    latitude: NonNegativeFloat = Field(\n",
    "        ...,\n",
    "        examples=[22.5],\n",
    "        description=\"Latitude measures the distance north or south of the equator.\",\n",
    "    )\n",
    "    longitude: NonNegativeFloat = Field(\n",
    "        ...,\n",
    "        examples=[55],\n",
    "        description=\"Longitude measures distance east or west of the prime meridian.\",\n",
    "    )\n",
    "    temperature: float = Field(\n",
    "        ..., examples=[20], description=\"Temperature in Celsius degrees\"\n",
    "    )\n",
    "    windspeed: NonNegativeFloat = Field(\n",
    "        ..., examples=[20], description=\"Wind speed in kilometers per hour\"\n",
    "    )\n",
    "    time: str = Field(\n",
    "        ..., examples=[\"2023-09-13T07:00\"], description=\"The time of the day\"\n",
    "    )\n",
    "\n",
    "\n",
    "@app.on_startup\n",
    "async def app_setup(context: ContextRepo):\n",
    "    \\\"\"\"\n",
    "    Set all necessary global variables inside ContextRepo object:\n",
    "        Set app_is_running to True - we will use this variable as running loop condition\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "@app.on_shutdown\n",
    "async def shutdown(context: ContextRepo):\n",
    "    \\\"\"\"\n",
    "    Set all necessary global variables inside ContextRepo object:\n",
    "        Set app_is_running to False\n",
    "\n",
    "    Get all executed tasks from context and wait them to finish\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "async def fetch_and_publish_weather(\n",
    "    latitude: float,\n",
    "    longitude: float,\n",
    "    logger: Logger,\n",
    "    context: ContextRepo,\n",
    "    time_inverval: int = 5,\n",
    ") -> None:\n",
    "    \\\"\"\"\n",
    "    While app_is_running variable inside context is True, repeat the following process:\n",
    "        get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
    "        At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
    "        Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
    "            \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
    "\n",
    "        from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
    "            response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
    "\n",
    "        We need to fetch this data, construct the Weather object and publish it at 'weather' topic.\n",
    "        For each message you are publishing we must use a key which will be constructed as:\n",
    "            string value of latitude + '_' + string value of longitude\n",
    "\n",
    "        asynchronous sleep for time_interval\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "@app.after_startup\n",
    "async def publish_weather(logger: Logger, context: ContextRepo):\n",
    "    \\\"\"\"\n",
    "    Create asynchronous tasks for executing fetch_and_publish_weather function.\n",
    "    Run this process for the following latitude and longitude combinations:\n",
    "        - latitude=13 and longitude=17\n",
    "        - latitude=50 and longitude=13\n",
    "        - latitude=44 and longitude=45\n",
    "        - latitude=24 and longitude=70\n",
    "    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for this tasks at app shutdown)\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "==== EXAMPLE APP DESCRIPTION ====\n",
    "\n",
    "Develop a FastStream application using localhost kafka broker.\n",
    "The app should consume messages from the input_data topic.\n",
    "The input message is a JSON encoded object including two attributes:\n",
    "    - x: float\n",
    "    - y: float\n",
    "    - time: datetime\n",
    "\n",
    "input_data topic should use partition key.\n",
    "While consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\n",
    "The same partition key should be used in the input_data and output_data topic.\n",
    "\n",
    "\n",
    "\n",
    "==== YOUR RESPONSE ====\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from faststream import Context, FastStream, Logger\n",
    "from faststream.kafka import KafkaBroker\n",
    "\n",
    "\n",
    "class Point(BaseModel):\n",
    "    x: float = Field(\n",
    "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
    "    )\n",
    "    y: float = Field(\n",
    "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
    "    )\n",
    "    time: datetime = Field(\n",
    "        ...,\n",
    "        examples=[\"2020-04-23 10:20:30.400000\"],\n",
    "        description=\"The timestamp of the record\",\n",
    "    )\n",
    "\n",
    "\n",
    "broker = KafkaBroker(\"localhost:9092\")\n",
    "app = FastStream(broker)\n",
    "\n",
    "\n",
    "to_output_data = broker.publisher(\"output_data\")\n",
    "\n",
    "\n",
    "@broker.subscriber(\"input_data\")\n",
    "async def on_input_data(\n",
    "    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\n",
    ") -> None:\n",
    "    \\\"\"\"\n",
    "    Processes a message from the 'input_data' topic.\n",
    "    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n",
    "    The same partition key should be used in the input_data and output_data topic.\n",
    "\n",
    "    Instructions:\n",
    "    1. Consume a message from 'input_data' topic.\n",
    "    2. Create a new message object (do not directly modify the original).\n",
    "    3. Increment msg x and y attributes with 1.\n",
    "    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\n",
    "    \\\"\"\"\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "==== USER APP DESCRIPTION: ====\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8d8e3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [{'content': prompt_with_similar_examples, 'role': 'user', 'name': 'Coder'}]\n",
    "# messages_with_examples_and_description = messages + groupchat.messages\n",
    "# messages_with_examples_and_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "288106fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\\n\\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\\n\\n    - Ensure the generated code aligns with the specific app description requirements.\\n\\n    - Provide a clear and organized starting point for developers.\\n\\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\\n    \\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\\n\\n\\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\\n\\n\\n\\n\\n==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastStream application with the localhost broker.\\nConsume from the \\'new_pet\\' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\\nWhenever a new pet is added, send the new pet\\'s information to the \\'notify_adopters\\' topic.\\n\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\nfrom pydantic import BaseModel, Field, NonNegativeInt\\n\\nfrom faststream import FastStream, Logger\\nfrom faststream.kafka import KafkaBroker\\n\\n\\nclass Pet(BaseModel):\\n    pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\\n    species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\\n    age: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\\n\\n\\nbroker = KafkaBroker(\"localhost:9092\")\\napp = FastStream(broker)\\n\\n\\n@broker.publisher(\"notify_adopters\")\\n@broker.subscriber(\"new_pet\")\\nasync def on_new_pet(msg: Pet, logger: Logger) -> Pet:\\n    \"\"\"\\n    Processes a message from the \\'new_pet\\' topic and send the new pet\\'s information to the \\'notify_adopters\\' topic.\\n\\n    Instructions:\\n    1. Consume a message from \\'new_pet\\' topic.\\n    2. Send the new pet\\'s information to the \\'notify_adopters\\' topic.\\n\\n    \"\"\"\\n    raise NotImplementedError()\\n\\n\\n==== EXAMPLE APP DESCRIPTION ====\\n\\nDevelop a FastStream application which will fetch weather information from the web until the app shuts down.\\n\\nYou can get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\\nAt the end of url you should add additional \\'latitude\\' and \\'longitude\\' parameters which are type float.\\nHere is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\\n    \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\\n\\nfrom the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\\n    response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\\n\\nWe need to fetch this data every 5 seconds and publish it at \\'weather\\' topic.\\nFor each message you are publishing we must use a key which will be constructed as:\\n    string value of latitude + \\'_\\' + string value of longitude\\n\\nMessage that we will publish needs to have following parameters:\\n    - latitude (type float)\\n    - longitude (type float)\\n    - temperature (type float)\\n    - windspeed (type float)\\n    - time (type string)\\n\\nWe need this process for the following latitude and longitude combinations:\\n    - latitude=13 and longitude=17\\n    - latitude=50 and longitude=13\\n    - latitude=44 and longitude=45\\n    - latitude=24 and longitude=70\\n\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\nfrom pydantic import BaseModel, Field, NonNegativeFloat\\n\\nfrom faststream import ContextRepo, FastStream, Logger\\nfrom faststream.kafka import KafkaBroker\\n\\nbroker = KafkaBroker(\"localhost:9092\")\\napp = FastStream(broker)\\n\\n\\nclass Weather(BaseModel):\\n    latitude: NonNegativeFloat = Field(\\n        ...,\\n        examples=[22.5],\\n        description=\"Latitude measures the distance north or south of the equator.\",\\n    )\\n    longitude: NonNegativeFloat = Field(\\n        ...,\\n        examples=[55],\\n        description=\"Longitude measures distance east or west of the prime meridian.\",\\n    )\\n    temperature: float = Field(\\n        ..., examples=[20], description=\"Temperature in Celsius degrees\"\\n    )\\n    windspeed: NonNegativeFloat = Field(\\n        ..., examples=[20], description=\"Wind speed in kilometers per hour\"\\n    )\\n    time: str = Field(\\n        ..., examples=[\"2023-09-13T07:00\"], description=\"The time of the day\"\\n    )\\n\\n\\n@app.on_startup\\nasync def app_setup(context: ContextRepo):\\n    \"\"\"\\n    Set all necessary global variables inside ContextRepo object:\\n        Set app_is_running to True - we will use this variable as running loop condition\\n    \"\"\"\\n    raise NotImplementedError()\\n\\n\\n@app.on_shutdown\\nasync def shutdown(context: ContextRepo):\\n    \"\"\"\\n    Set all necessary global variables inside ContextRepo object:\\n        Set app_is_running to False\\n\\n    Get all executed tasks from context and wait them to finish\\n    \"\"\"\\n    raise NotImplementedError()\\n\\n\\nasync def fetch_and_publish_weather(\\n    latitude: float,\\n    longitude: float,\\n    logger: Logger,\\n    context: ContextRepo,\\n    time_inverval: int = 5,\\n) -> None:\\n    \"\"\"\\n    While app_is_running variable inside context is True, repeat the following process:\\n        get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\\n        At the end of url you should add additional \\'latitude\\' and \\'longitude\\' parameters which are type float.\\n        Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\\n            \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\\n\\n        from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\\n            response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\\n\\n        We need to fetch this data, construct the Weather object and publish it at \\'weather\\' topic.\\n        For each message you are publishing we must use a key which will be constructed as:\\n            string value of latitude + \\'_\\' + string value of longitude\\n\\n        asynchronous sleep for time_interval\\n    \"\"\"\\n    raise NotImplementedError()\\n\\n\\n@app.after_startup\\nasync def publish_weather(logger: Logger, context: ContextRepo):\\n    \"\"\"\\n    Create asynchronous tasks for executing fetch_and_publish_weather function.\\n    Run this process for the following latitude and longitude combinations:\\n        - latitude=13 and longitude=17\\n        - latitude=50 and longitude=13\\n        - latitude=44 and longitude=45\\n        - latitude=24 and longitude=70\\n    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for this tasks at app shutdown)\\n    \"\"\"\\n    raise NotImplementedError()\\n\\n\\n==== EXAMPLE APP DESCRIPTION ====\\n\\nDevelop a FastStream application using localhost kafka broker.\\nThe app should consume messages from the input_data topic.\\nThe input message is a JSON encoded object including two attributes:\\n    - x: float\\n    - y: float\\n    - time: datetime\\n\\ninput_data topic should use partition key.\\nWhile consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\\nThe same partition key should be used in the input_data and output_data topic.\\n\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\nfrom datetime import datetime\\n\\nfrom pydantic import BaseModel, Field\\n\\nfrom faststream import Context, FastStream, Logger\\nfrom faststream.kafka import KafkaBroker\\n\\n\\nclass Point(BaseModel):\\n    x: float = Field(\\n        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\\n    )\\n    y: float = Field(\\n        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\\n    )\\n    time: datetime = Field(\\n        ...,\\n        examples=[\"2020-04-23 10:20:30.400000\"],\\n        description=\"The timestamp of the record\",\\n    )\\n\\n\\nbroker = KafkaBroker(\"localhost:9092\")\\napp = FastStream(broker)\\n\\n\\nto_output_data = broker.publisher(\"output_data\")\\n\\n\\n@broker.subscriber(\"input_data\")\\nasync def on_input_data(\\n    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\\n) -> None:\\n    \"\"\"\\n    Processes a message from the \\'input_data\\' topic.\\n    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\\n    The same partition key should be used in the input_data and output_data topic.\\n\\n    Instructions:\\n    1. Consume a message from \\'input_data\\' topic.\\n    2. Create a new message object (do not directly modify the original).\\n    3. Increment msg x and y attributes with 1.\\n    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\\n    \"\"\"\\n    raise NotImplementedError()\\n    \\n    \\n==== USER APP DESCRIPTION: ====\\n\\nUser:\\n\\nCreate a FastStream application which will retrieve the current cryptocurrency price\\nand publish it to new_crypto_price topic. \\n\\nThe application should retrieve the data every 2 seconds.\\n\\nA message which will be produced is JSON with the two attributes:\\n- price: non-negative float (current price of cryptocurrency in USD)\\n- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\\n\\n\\nThe response of this GET request is a JSON and you can get\\ninformation about the crypto_currency in:\\n    response[\\'data\\'][\\'base\\']\\n\\nand the information about the price in:\\n    response[\\'data\\'][\\'amount\\']\\n\\nUse utf-8 encoded crypto_currency attribute as a partition key when publishing\\nthe message to new_crypto_price topic.\\n\\n\\nIs everything clear with the above description?\\n\\nProduct_Manager:\\nWhich API should we use to retrieve the cryptocurrency price data?\\nUser:\\napi.coinbase.com/v2/prices\\nTeam_leader:\\nAre there any specific cryptocurrencies we need to focus on, or should we fetch data for all?\\nUser:\\nBitcoin and Etherum\\nPlease create skeleton application for the fiven description.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_with_similar_examples + groupchat_messages_string + \"Please create skeleton application for the given description.\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "c5e677dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": random.randint(100, 900),\n",
    "    \"temperature\": 0.7,  # temperature for sampling\n",
    "}  # configuration for autogen's enhanced inference API which is compatible with OpenAI API\n",
    "\n",
    "\n",
    "USER_PROXY_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a QA engineer with a simple task that you need to check.\n",
    "Check that all functions and methods which the Coder sends to you are NOT implemented, each function should just raise NotImplementedError().\n",
    "If some function or method is implemented, reply to the the Coder to delete the implementation and just to replace it with \"raise NotImplementedError()\"\n",
    "You should never write any code, just anlyze, execute the code and write instructions to the coder what needs to be fixed.\n",
    "\n",
    "If there are any external dependencies (such as FastStream) please install them.\n",
    "\n",
    "If the code looks good to you, save it in the application_skeleton.py and execute it.\n",
    "Your job can not be done until you execute application_skeleton.py!\n",
    "If there are not any errors with application_skeleton.py reply with \"# TERMINATE\".\n",
    "otherwise, reply with the instructions what needs to be fixed. NEVER reply with any code, just instructions!\n",
    "\n",
    "Reply \"# TERMINATE\" in the end when everything is done.\n",
    "\"\"\"\n",
    "\n",
    "code_execution_config={\n",
    "       \"work_dir\": \"groupchat_skeleton\",\n",
    "       \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "}\n",
    "\n",
    "user_skeleton_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_skeleton_proxy\",\n",
    "    system_message=USER_PROXY_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=code_execution_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    ")\n",
    "\n",
    "CODER_SYSTEM_MESSAGE = \"\"\"\n",
    "Your job is to write application_skeleton.py for the given application description.\n",
    "The application must use FastStream framework. \n",
    "For each function and method write the docstring and raise NotImplementedError() i.e. do NOT implement any function.\n",
    "\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply \"TERMINATE\" in the end when everything is done.\n",
    "\"\"\"\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=CODER_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,    \n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "27970fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_skeleton_proxy\u001b[0m (to Coder):\n",
      "\n",
      "# filename: application_skeleton.py; \n",
      "\n",
      "Generate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n",
      "\n",
      "    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n",
      "\n",
      "    - Ensure the generated code aligns with the specific app description requirements.\n",
      "\n",
      "    - Provide a clear and organized starting point for developers.\n",
      "\n",
      "    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n",
      "    \n",
      "    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n",
      "\n",
      "\n",
      "The goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Create a FastStream application with the localhost broker.\n",
      "Consume from the 'new_pet' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\n",
      "Whenever a new pet is added, send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeInt\n",
      "\n",
      "from faststream import FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Pet(BaseModel):\n",
      "    pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
      "    species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n",
      "    age: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "@broker.publisher(\"notify_adopters\")\n",
      "@broker.subscriber(\"new_pet\")\n",
      "async def on_new_pet(msg: Pet, logger: Logger) -> Pet:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'new_pet' topic and send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'new_pet' topic.\n",
      "    2. Send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application which will fetch weather information from the web until the app shuts down.\n",
      "\n",
      "You can get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
      "At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
      "Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
      "    \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
      "\n",
      "from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
      "    response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
      "\n",
      "We need to fetch this data every 5 seconds and publish it at 'weather' topic.\n",
      "For each message you are publishing we must use a key which will be constructed as:\n",
      "    string value of latitude + '_' + string value of longitude\n",
      "\n",
      "Message that we will publish needs to have following parameters:\n",
      "    - latitude (type float)\n",
      "    - longitude (type float)\n",
      "    - temperature (type float)\n",
      "    - windspeed (type float)\n",
      "    - time (type string)\n",
      "\n",
      "We need this process for the following latitude and longitude combinations:\n",
      "    - latitude=13 and longitude=17\n",
      "    - latitude=50 and longitude=13\n",
      "    - latitude=44 and longitude=45\n",
      "    - latitude=24 and longitude=70\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeFloat\n",
      "\n",
      "from faststream import ContextRepo, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "class Weather(BaseModel):\n",
      "    latitude: NonNegativeFloat = Field(\n",
      "        ...,\n",
      "        examples=[22.5],\n",
      "        description=\"Latitude measures the distance north or south of the equator.\",\n",
      "    )\n",
      "    longitude: NonNegativeFloat = Field(\n",
      "        ...,\n",
      "        examples=[55],\n",
      "        description=\"Longitude measures distance east or west of the prime meridian.\",\n",
      "    )\n",
      "    temperature: float = Field(\n",
      "        ..., examples=[20], description=\"Temperature in Celsius degrees\"\n",
      "    )\n",
      "    windspeed: NonNegativeFloat = Field(\n",
      "        ..., examples=[20], description=\"Wind speed in kilometers per hour\"\n",
      "    )\n",
      "    time: str = Field(\n",
      "        ..., examples=[\"2023-09-13T07:00\"], description=\"The time of the day\"\n",
      "    )\n",
      "\n",
      "\n",
      "@app.on_startup\n",
      "async def app_setup(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to True - we will use this variable as running loop condition\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.on_shutdown\n",
      "async def shutdown(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to False\n",
      "\n",
      "    Get all executed tasks from context and wait them to finish\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "async def fetch_and_publish_weather(\n",
      "    latitude: float,\n",
      "    longitude: float,\n",
      "    logger: Logger,\n",
      "    context: ContextRepo,\n",
      "    time_inverval: int = 5,\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    While app_is_running variable inside context is True, repeat the following process:\n",
      "        get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
      "        At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
      "        Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
      "            \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
      "\n",
      "        from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
      "            response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
      "\n",
      "        We need to fetch this data, construct the Weather object and publish it at 'weather' topic.\n",
      "        For each message you are publishing we must use a key which will be constructed as:\n",
      "            string value of latitude + '_' + string value of longitude\n",
      "\n",
      "        asynchronous sleep for time_interval\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.after_startup\n",
      "async def publish_weather(logger: Logger, context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Create asynchronous tasks for executing fetch_and_publish_weather function.\n",
      "    Run this process for the following latitude and longitude combinations:\n",
      "        - latitude=13 and longitude=17\n",
      "        - latitude=50 and longitude=13\n",
      "        - latitude=44 and longitude=45\n",
      "        - latitude=24 and longitude=70\n",
      "    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for this tasks at app shutdown)\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application using localhost kafka broker.\n",
      "The app should consume messages from the input_data topic.\n",
      "The input message is a JSON encoded object including two attributes:\n",
      "    - x: float\n",
      "    - y: float\n",
      "    - time: datetime\n",
      "\n",
      "input_data topic should use partition key.\n",
      "While consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\n",
      "The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "from faststream import Context, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Point(BaseModel):\n",
      "    x: float = Field(\n",
      "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
      "    )\n",
      "    y: float = Field(\n",
      "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
      "    )\n",
      "    time: datetime = Field(\n",
      "        ...,\n",
      "        examples=[\"2020-04-23 10:20:30.400000\"],\n",
      "        description=\"The timestamp of the record\",\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_output_data = broker.publisher(\"output_data\")\n",
      "\n",
      "\n",
      "@broker.subscriber(\"input_data\")\n",
      "async def on_input_data(\n",
      "    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'input_data' topic.\n",
      "    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n",
      "    The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'input_data' topic.\n",
      "    2. Create a new message object (do not directly modify the original).\n",
      "    3. Increment msg x and y attributes with 1.\n",
      "    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "    \n",
      "    \n",
      "==== USER APP DESCRIPTION: ====\n",
      "\n",
      "User:\n",
      "\n",
      "Create a FastStream application which will retrieve the current cryptocurrency price\n",
      "and publish it to new_crypto_price topic. \n",
      "\n",
      "The application should retrieve the data every 2 seconds.\n",
      "\n",
      "A message which will be produced is JSON with the two attributes:\n",
      "- price: non-negative float (current price of cryptocurrency in USD)\n",
      "- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n",
      "\n",
      "\n",
      "The response of this GET request is a JSON and you can get\n",
      "information about the crypto_currency in:\n",
      "    response['data']['base']\n",
      "\n",
      "and the information about the price in:\n",
      "    response['data']['amount']\n",
      "\n",
      "Use utf-8 encoded crypto_currency attribute as a partition key when publishing\n",
      "the message to new_crypto_price topic.\n",
      "\n",
      "\n",
      "Is everything clear with the above description?\n",
      "\n",
      "Product_Manager:\n",
      "Which API should we use to retrieve the cryptocurrency price data?\n",
      "User:\n",
      "api.coinbase.com/v2/prices\n",
      "Team_leader:\n",
      "Are there any specific cryptocurrencies we need to focus on, or should we fetch data for all?\n",
      "User:\n",
      "Bitcoin and Etherum\n",
      "Please create skeleton application for the fiven description.\n",
      "# filename: application_skeleton.py; \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to User_skeleton_proxy):\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeFloat\n",
      "from datetime import datetime\n",
      "from faststream import Context, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "class CryptoPrice(BaseModel):\n",
      "    price: NonNegativeFloat = Field(..., examples=[10000.0], description=\"The current price of the cryptocurrency in USD\")\n",
      "    crypto_currency: str = Field(..., examples=[\"BTC\", \"ETH\"], description=\"The cryptocurrency symbol\")\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "to_new_crypto_price = broker.publisher(\"new_crypto_price\")\n",
      "\n",
      "@app.on_startup\n",
      "async def app_setup():\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside Context object:\n",
      "        Set app_is_running to True - we will use this variable as running loop condition\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "@app.on_shutdown\n",
      "async def shutdown():\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside Context object:\n",
      "        Set app_is_running to False\n",
      "\n",
      "    Get all executed tasks from context and wait for them to finish\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "async def fetch_and_publish_crypto_price(\n",
      "    logger: Logger, context: Context, time_interval: int = 2\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    While app_is_running variable inside context is True, repeat the following process:\n",
      "        get the cryptocurrency price by sending a GET request to \"https://api.coinbase.com/v2/prices\"\n",
      "        from the response, extract the price and crypto_currency attributes\n",
      "        create a new CryptoPrice object with the extracted attributes\n",
      "        publish the CryptoPrice object to the new_crypto_price topic using the utf-8 encoded crypto_currency as the partition key\n",
      "        asynchronously sleep for time_interval\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "@app.after_startup\n",
      "async def publish_crypto_price(logger: Logger, context: Context):\n",
      "    \"\"\"\n",
      "    Create asynchronous tasks for executing fetch_and_publish_crypto_price function.\n",
      "    Run this process for Bitcoin and Ethereum cryptocurrencies.\n",
      "    Put all executed tasks into a list and set it as a global variable in the context (It is needed so we can wait for these tasks at app shutdown)\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_skeleton_proxy\u001b[0m (to Coder):\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeFloat\n",
      "from datetime import datetime\n",
      "\n",
      "from faststream import ContextRepo, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class CryptoPrice(BaseModel):\n",
      "    price: NonNegativeFloat = Field(\n",
      "        ..., examples=[10000.0], description=\"The current price of the cryptocurrency in USD\"\n",
      "    )\n",
      "    crypto_currency: str = Field(\n",
      "        ..., examples=[\"BTC\", \"ETH\"], description=\"The cryptocurrency symbol\"\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_new_crypto_price = broker.publisher(\"new_crypto_price\")\n",
      "\n",
      "\n",
      "@app.on_startup\n",
      "async def app_setup(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to True - we will use this variable as the running loop condition\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.on_shutdown\n",
      "async def shutdown(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to False\n",
      "\n",
      "    Get all executed tasks from the context and wait for them to finish\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "async def fetch_and_publish_crypto_price(\n",
      "    logger: Logger, context: ContextRepo, time_interval: int = 2\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    While app_is_running variable inside context is True, repeat the following process:\n",
      "        get the cryptocurrency price by sending a GET request to \"https://api.coinbase.com/v2/prices\"\n",
      "        from the response, extract the price and crypto_currency attributes\n",
      "        create a new CryptoPrice object with the extracted attributes\n",
      "        publish the CryptoPrice object to the new_crypto_price topic using the utf-8 encoded crypto_currency as the partition key\n",
      "        asynchronously sleep for time_interval\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.after_startup\n",
      "async def publish_crypto_price(logger: Logger, context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Create asynchronous tasks for executing fetch_and_publish_crypto_price function.\n",
      "    Run this process for Bitcoin and Ethereum cryptocurrencies.\n",
      "    Put all executed tasks into a list and set it as a global variable in the context (It is needed so we can wait for these tasks at app shutdown)\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to User_skeleton_proxy):\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "user_skeleton_proxy.initiate_chat(\n",
    "    coder,\n",
    "    message=\"# filename: application_skeleton.py; \" + prompt + \"\\n# filename: application_skeleton.py; \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557d3184",
   "metadata": {},
   "source": [
    "## Simple example with saving the generated code to .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "368db43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "# filename: saved_code.py; What date is today? Compare the year-to-date gain for META and TESLA.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To solve this task, we will need to do the following:\n",
      "\n",
      "1. Get the current date using Python's datetime module.\n",
      "2. Fetch the stock prices for META (Facebook) and TESLA for the current year and the previous year. We can use the yfinance module in Python to fetch this data.\n",
      "3. Calculate the year-to-date gain for both stocks and compare them.\n",
      "\n",
      "Let's start with the first step. Here is the Python code to get the current date:\n",
      "\n",
      "```python\n",
      "# filename: saved_code.py\n",
      "\n",
      "import datetime\n",
      "\n",
      "# Get the current date\n",
      "current_date = datetime.date.today()\n",
      "\n",
      "print(\"Today's date is:\", current_date)\n",
      "```\n",
      "\n",
      "Please run this code to get the current date. After that, we will proceed with fetching the stock prices.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Today's date is: 2023-10-10\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great, now that we have the current date, let's move on to the next step. We will fetch the stock prices for META (Facebook) and TESLA for the current year and the previous year. \n",
      "\n",
      "We will use the yfinance module in Python to fetch this data. If you don't have it installed, you can install it using pip:\n",
      "\n",
      "```sh\n",
      "pip install yfinance\n",
      "```\n",
      "\n",
      "After installing yfinance, please run the following Python code:\n",
      "\n",
      "```python\n",
      "# filename: saved_code.py\n",
      "\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "# Get the current date\n",
      "current_date = datetime.date.today()\n",
      "\n",
      "# Get the start of the year\n",
      "start_of_year = datetime.date(current_date.year, 1, 1)\n",
      "\n",
      "# Fetch the stock data for META and TESLA\n",
      "meta_data = yf.download('FB', start=start_of_year, end=current_date)\n",
      "tesla_data = yf.download('TSLA', start=start_of_year, end=current_date)\n",
      "\n",
      "# Calculate the year-to-date gain for META and TESLA\n",
      "meta_gain = ((meta_data['Close'][-1] - meta_data['Close'][0]) / meta_data['Close'][0]) * 100\n",
      "tesla_gain = ((tesla_data['Close'][-1] - tesla_data['Close'][0]) / tesla_data['Close'][0]) * 100\n",
      "\n",
      "print(\"META's year-to-date gain is: {:.2f}%\".format(meta_gain))\n",
      "print(\"TESLA's year-to-date gain is: {:.2f}%\".format(tesla_gain))\n",
      "```\n",
      "\n",
      "This code will print the year-to-date gain for META and TESLA.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /home/robert/.local/lib/python3.11/site-packages (0.2.31)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.25.0)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.31.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.9.2)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2022.5 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (2023.3.post1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (3.16.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in /home/robert/.local/lib/python3.11/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
      "Requirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/robert/.local/lib/python3.11/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/robert/.local/lib/python3.11/site-packages (from requests>=2.31->yfinance) (1.26.17)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2023.5.7)\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "['FB']: Exception('%ticker%: No timezone found, symbol may be delisted')\n",
      "saved_code.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  meta_gain = ((meta_data['Close'][-1] - meta_data['Close'][0]) / meta_data['Close'][0]) * 100\n",
      "Traceback (most recent call last):\n",
      "  File \"saved_code.py\", line 17, in <module>\n",
      "    meta_gain = ((meta_data['Close'][-1] - meta_data['Close'][0]) / meta_data['Close'][0]) * 100\n",
      "                  ~~~~~~~~~~~~~~~~~~^^^^\n",
      "  File \"/home/robert/.local/lib/python3.11/site-packages/pandas/core/series.py\", line 1037, in __getitem__\n",
      "    return self._values[key]\n",
      "           ~~~~~~~~~~~~^^^^^\n",
      "IndexError: index -1 is out of bounds for axis 0 with size 0\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "I apologize for the error. It seems that the ticker symbol for Meta Platforms (formerly Facebook) has changed from 'FB' to 'META'. Let's correct that and try again. \n",
      "\n",
      "Please run the following Python code:\n",
      "\n",
      "```python\n",
      "# filename: saved_code.py\n",
      "\n",
      "import yfinance as yf\n",
      "import datetime\n",
      "\n",
      "# Get the current date\n",
      "current_date = datetime.date.today()\n",
      "\n",
      "# Get the start of the year\n",
      "start_of_year = datetime.date(current_date.year, 1, 1)\n",
      "\n",
      "# Fetch the stock data for META and TESLA\n",
      "meta_data = yf.download('META', start=start_of_year, end=current_date)\n",
      "tesla_data = yf.download('TSLA', start=start_of_year, end=current_date)\n",
      "\n",
      "# Calculate the year-to-date gain for META and TESLA\n",
      "meta_gain = ((meta_data['Close'][-1] - meta_data['Close'][0]) / meta_data['Close'][0]) * 100\n",
      "tesla_gain = ((tesla_data['Close'][-1] - tesla_data['Close'][0]) / tesla_data['Close'][0]) * 100\n",
      "\n",
      "print(\"META's year-to-date gain is: {:.2f}%\".format(meta_gain))\n",
      "print(\"TESLA's year-to-date gain is: {:.2f}%\".format(tesla_gain))\n",
      "```\n",
      "\n",
      "This code will print the year-to-date gain for META and TESLA.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "META's year-to-date gain is: 155.22%\n",
      "TESLA's year-to-date gain is: 140.21%\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! The code has successfully fetched the stock prices for META and TESLA and calculated the year-to-date gain for both. \n",
      "\n",
      "As per the output:\n",
      "\n",
      "- META's year-to-date gain is 155.22%\n",
      "- TESLA's year-to-date gain is 140.21%\n",
      "\n",
      "This means that so far in this year, META's stock price has increased by 155.22% from the price at the start of the year, while TESLA's stock price has increased by 140.21% from the price at the start of the year. \n",
      "\n",
      "Therefore, comparing the two, META has had a higher year-to-date gain than TESLA.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "]\n",
    "\n",
    "conversations = {}\n",
    "autogen.ChatCompletion.start_logging(conversations)\n",
    "\n",
    "# create an AssistantAgent named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"seed\": 22,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    },  # configuration for autogen's enhanced inference API which is compatible with OpenAI API\n",
    ")\n",
    "\n",
    "DEFAULT_SYSTEM_MESSAGE = \"\"\"You are a helpful AI assistant.\n",
    "Solve tasks using your coding and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "\n",
    "Please save the created code into a python file.\n",
    "Reply \"TERMINATE\" in the end when everything is done.\n",
    "\"\"\"\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "    },\n",
    ")\n",
    "# the assistant receives a message from the user_proxy, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"\"\"# filename: saved_code.py; What date is today? Compare the year-to-date gain for META and TESLA.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6968762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94b5f4f9",
   "metadata": {},
   "source": [
    "## Skeleton generation groupchat with functions: user_proxy, coder, QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21b62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "c1f6f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "config_list = [\n",
    "#     {\n",
    "#         \"model\": \"gpt-4\",\n",
    "#         \"api_key\": api_key\n",
    "#     },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_config_qa = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"python\",\n",
    "            \"description\": \"run cell in ipython and return the execution result.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"cell\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Valid Python cell to execute.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"cell\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": random.randint(100, 900),\n",
    "    \"temperature\": 0.7,  # temperature for sampling\n",
    "}  \n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": random.randint(100, 900),\n",
    "    \"temperature\": 0.7,  # temperature for sampling\n",
    "} \n",
    "\n",
    "# You are a proxy between the Coder and the Quality Assurance Engineer. All messages received from the Coder forward to the Quality Assurance Engineer.\n",
    "USER_PROXY_SYSTEM_MESSAGE = \"\"\"\n",
    "\n",
    "\n",
    "Each time you receive a message from the Coder, follow these steps: \n",
    "- If the code looks good to you, save it in the application_skeleton.py and execute it.\n",
    "- Your job can not be done until you execute application_skeleton.py!\n",
    "- If there are not any errors once you execute the application_skeleton.py reply with \"# TERMINATE\".\n",
    "- But you can't reply with TERMINATE if you did not execute the received code!!!\n",
    "- If there are some problems with the code, reply with the instructions what needs to be fixed. NEVER reply with any code, just instructions!\n",
    "- When something needs to be fixed, send it to the Coder\n",
    "\n",
    "If the code execution is successful, reply with \"TERMINATE\".\n",
    "\"\"\"\n",
    "# Reply \"# TERMINATE\" in the end when everything is done.\n",
    "\n",
    "code_execution_config={\n",
    "       \"work_dir\": \"groupchat_skeleton\",\n",
    "       \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "}\n",
    "\n",
    "user_skeleton_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_skeleton_proxy\",\n",
    "    system_message=USER_PROXY_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=code_execution_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if (x and \"TERMINATE\" in x.get(\"content\", \"\")) else False,\n",
    ")\n",
    "\n",
    "# CODER_SYSTEM_MESSAGE = \"\"\"\n",
    "# Your job is to write application_skeleton.py for the given application description.\n",
    "# The application must use FastStream framework. \n",
    "# For each function and method write the docstring and raise NotImplementedError() i.e. do NOT implement any function.\n",
    "# The code you create MUST be inside the ```python block!\n",
    "\n",
    "# If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "# If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "# When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "# \"\"\"\n",
    "\n",
    "CODER_SYSTEM_MESSAGE = \"\"\"\n",
    "Generate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n",
    "\n",
    "    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n",
    "\n",
    "    - Ensure the generated code aligns with the specific app description requirements.\n",
    "\n",
    "    - Provide a clear and organized starting point for developers.\n",
    "\n",
    "    - Your response must contain only valid Python code within back-ticks\n",
    "    \n",
    "    - ALWAYS enclose the response within back-ticks. Meaning ALWAYS ADD ```python to your response.\n",
    "    \n",
    "    - NEVER add main function and \"if __name__ == \"__main__\":\" block\n",
    "\n",
    "\n",
    "The goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n",
    "\"\"\"\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=CODER_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,    \n",
    "    is_termination_msg=lambda x: True if (x and \"TERMINATE\" in x.get(\"content\", \"\")) else False,\n",
    ")\n",
    "\n",
    "QA_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a QA engineer with 3 simple task that you need to check.\n",
    "1.\n",
    "Check that all functions and methods which the Coder sends to you are NOT implemented, each function should just raise NotImplementedError().\n",
    "If some function or method is implemented, reply to the the Coder to delete the implementation and just to replace it with \"raise NotImplementedError()\"\n",
    "2.\n",
    "Check that the IS NOT main function and \"if __name__ == \"__main__\":\" block.\n",
    "If the main block is implemented, tell the Coder to delete it\n",
    "3. The code is written inside the  within back-ticks - ```python\n",
    "\n",
    "Do NOT write any functions to test that, just take a look at the code and write instructions to the Coder if some function is implemented.\n",
    "You should never write any NEW code.\n",
    "If the code looks ok, forward it to User_skeleton_proxy.\n",
    "\"\"\"\n",
    "\n",
    "quality_assurance_engineer = autogen.AssistantAgent(\n",
    "    name=\"QA_Engineer\",\n",
    "    system_message=QA_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config_qa,    \n",
    "    is_termination_msg=lambda x: True if (x and \"TERMINATE\" in x.get(\"content\", \"\")) else False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "85f53212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions according to the function desription\n",
    "from IPython import get_ipython\n",
    "\n",
    "def exec_python(cell):\n",
    "    ipython = get_ipython()\n",
    "    result = ipython.run_cell(cell)\n",
    "    log = str(result.result)\n",
    "    if result.error_before_exec is not None:\n",
    "        log += f\"\\n{result.error_before_exec}\"\n",
    "    if result.error_in_exec is not None:\n",
    "        log += f\"\\n{result.error_in_exec}\"\n",
    "    return log\n",
    "\n",
    "\n",
    "# register the functions\n",
    "user_skeleton_proxy.register_function(\n",
    "    function_map={\n",
    "        \"python\": exec_python,\n",
    "    }\n",
    ")\n",
    "\n",
    "# user_skeleton_proxy.initiate_chat(\n",
    "#     coder,\n",
    "#     message=\"# filename: application_skeleton.py; \" + prompt,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ae0b04c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_skeleton_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "# filename: application_skeleton.py; \n",
      "\n",
      "Generate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n",
      "\n",
      "    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n",
      "\n",
      "    - Ensure the generated code aligns with the specific app description requirements.\n",
      "\n",
      "    - Provide a clear and organized starting point for developers.\n",
      "\n",
      "    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n",
      "    \n",
      "    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n",
      "\n",
      "\n",
      "The goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Create a FastStream application with the localhost broker.\n",
      "Consume from the 'new_pet' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\n",
      "Whenever a new pet is added, send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeInt\n",
      "\n",
      "from faststream import FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Pet(BaseModel):\n",
      "    pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
      "    species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n",
      "    age: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "@broker.publisher(\"notify_adopters\")\n",
      "@broker.subscriber(\"new_pet\")\n",
      "async def on_new_pet(msg: Pet, logger: Logger) -> Pet:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'new_pet' topic and send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'new_pet' topic.\n",
      "    2. Send the new pet's information to the 'notify_adopters' topic.\n",
      "\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application which will fetch weather information from the web until the app shuts down.\n",
      "\n",
      "You can get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
      "At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
      "Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
      "    \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
      "\n",
      "from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
      "    response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
      "\n",
      "We need to fetch this data every 5 seconds and publish it at 'weather' topic.\n",
      "For each message you are publishing we must use a key which will be constructed as:\n",
      "    string value of latitude + '_' + string value of longitude\n",
      "\n",
      "Message that we will publish needs to have following parameters:\n",
      "    - latitude (type float)\n",
      "    - longitude (type float)\n",
      "    - temperature (type float)\n",
      "    - windspeed (type float)\n",
      "    - time (type string)\n",
      "\n",
      "We need this process for the following latitude and longitude combinations:\n",
      "    - latitude=13 and longitude=17\n",
      "    - latitude=50 and longitude=13\n",
      "    - latitude=44 and longitude=45\n",
      "    - latitude=24 and longitude=70\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeFloat\n",
      "\n",
      "from faststream import ContextRepo, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "class Weather(BaseModel):\n",
      "    latitude: NonNegativeFloat = Field(\n",
      "        ...,\n",
      "        examples=[22.5],\n",
      "        description=\"Latitude measures the distance north or south of the equator.\",\n",
      "    )\n",
      "    longitude: NonNegativeFloat = Field(\n",
      "        ...,\n",
      "        examples=[55],\n",
      "        description=\"Longitude measures distance east or west of the prime meridian.\",\n",
      "    )\n",
      "    temperature: float = Field(\n",
      "        ..., examples=[20], description=\"Temperature in Celsius degrees\"\n",
      "    )\n",
      "    windspeed: NonNegativeFloat = Field(\n",
      "        ..., examples=[20], description=\"Wind speed in kilometers per hour\"\n",
      "    )\n",
      "    time: str = Field(\n",
      "        ..., examples=[\"2023-09-13T07:00\"], description=\"The time of the day\"\n",
      "    )\n",
      "\n",
      "\n",
      "@app.on_startup\n",
      "async def app_setup(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to True - we will use this variable as running loop condition\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.on_shutdown\n",
      "async def shutdown(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set app_is_running to False\n",
      "\n",
      "    Get all executed tasks from context and wait them to finish\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "async def fetch_and_publish_weather(\n",
      "    latitude: float,\n",
      "    longitude: float,\n",
      "    logger: Logger,\n",
      "    context: ContextRepo,\n",
      "    time_inverval: int = 5,\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    While app_is_running variable inside context is True, repeat the following process:\n",
      "        get the weather information by sending a GET request to \"https://api.open-meteo.com/v1/forecast?current_weather=true\"\n",
      "        At the end of url you should add additional 'latitude' and 'longitude' parameters which are type float.\n",
      "        Here is url example when you want to fetch information for latitude=52.3 and longitude=13.2:\n",
      "            \"https://api.open-meteo.com/v1/forecast?current_weather=true&latitude=52.3&longitude=13.2\"\n",
      "\n",
      "        from the response we want to get info about the temperature (float), windspeed (float) and time (string) and you can find them in:\n",
      "            response[\"current_weather\"][\"temperature\"], response[\"current_weather\"][\"windspeed\"], and response[\"current_weather\"][\"time\"]\n",
      "\n",
      "        We need to fetch this data, construct the Weather object and publish it at 'weather' topic.\n",
      "        For each message you are publishing we must use a key which will be constructed as:\n",
      "            string value of latitude + '_' + string value of longitude\n",
      "\n",
      "        asynchronous sleep for time_interval\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@app.after_startup\n",
      "async def publish_weather(logger: Logger, context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Create asynchronous tasks for executing fetch_and_publish_weather function.\n",
      "    Run this process for the following latitude and longitude combinations:\n",
      "        - latitude=13 and longitude=17\n",
      "        - latitude=50 and longitude=13\n",
      "        - latitude=44 and longitude=45\n",
      "        - latitude=24 and longitude=70\n",
      "    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for this tasks at app shutdown)\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application using localhost kafka broker.\n",
      "The app should consume messages from the input_data topic.\n",
      "The input message is a JSON encoded object including two attributes:\n",
      "    - x: float\n",
      "    - y: float\n",
      "    - time: datetime\n",
      "\n",
      "input_data topic should use partition key.\n",
      "While consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\n",
      "The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "from faststream import Context, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Point(BaseModel):\n",
      "    x: float = Field(\n",
      "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
      "    )\n",
      "    y: float = Field(\n",
      "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
      "    )\n",
      "    time: datetime = Field(\n",
      "        ...,\n",
      "        examples=[\"2020-04-23 10:20:30.400000\"],\n",
      "        description=\"The timestamp of the record\",\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_output_data = broker.publisher(\"output_data\")\n",
      "\n",
      "\n",
      "@broker.subscriber(\"input_data\")\n",
      "async def on_input_data(\n",
      "    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'input_data' topic.\n",
      "    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n",
      "    The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'input_data' topic.\n",
      "    2. Create a new message object (do not directly modify the original).\n",
      "    3. Increment msg x and y attributes with 1.\n",
      "    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "    \n",
      "    \n",
      "==== USER APP DESCRIPTION: ====\n",
      "\n",
      "User:\n",
      "\n",
      "Create a FastStream application which will retrieve the current cryptocurrency price\n",
      "and publish it to new_crypto_price topic. \n",
      "\n",
      "The application should retrieve the data every 2 seconds.\n",
      "\n",
      "A message which will be produced is JSON with the two attributes:\n",
      "- price: non-negative float (current price of cryptocurrency in USD)\n",
      "- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n",
      "\n",
      "\n",
      "The response of this GET request is a JSON and you can get\n",
      "information about the crypto_currency in:\n",
      "    response['data']['base']\n",
      "\n",
      "and the information about the price in:\n",
      "    response['data']['amount']\n",
      "\n",
      "Use utf-8 encoded crypto_currency attribute as a partition key when publishing\n",
      "the message to new_crypto_price topic.\n",
      "\n",
      "\n",
      "Is everything clear with the above description?\n",
      "\n",
      "Product_Manager:\n",
      "Which API should we use to retrieve the cryptocurrency price data?\n",
      "User:\n",
      "api.coinbase.com/v2/prices\n",
      "Team_leader:\n",
      "Are there any specific cryptocurrencies we need to focus on, or should we fetch data for all?\n",
      "User:\n",
      "Bitcoin and Etherum\n",
      "Please create skeleton application for the fiven description.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "from pydantic import BaseModel, Field, NonNegativeFloat\n",
      "from datetime import datetime\n",
      "from faststream import Context, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "import requests\n",
      "import asyncio\n",
      "\n",
      "class CryptoPrice(BaseModel):\n",
      "    price: NonNegativeFloat = Field(..., examples=[10000.0], description=\"Current price of cryptocurrency in USD\")\n",
      "    crypto_currency: str = Field(..., examples=[\"BTC\"], description=\"The cryptocurrency e.g. BTC, ETH...\")\n",
      "    \n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "to_new_crypto_price = broker.publisher(\"new_crypto_price\")\n",
      "\n",
      "async def fetch_and_publish_crypto_price(logger: Logger, time_interval: int = 2) -> None:\n",
      "    \"\"\"\n",
      "    Fetches the current cryptocurrency price from the API every 2 seconds and publishes it to the 'new_crypto_price' topic.\n",
      "    The message is a JSON object with attributes price and crypto_currency.\n",
      "\n",
      "    Instructions:\n",
      "    1. Fetch the current cryptocurrency price from the API.\n",
      "    2. Create a new CryptoPrice object with the fetched data.\n",
      "    3. Publish the CryptoPrice object to the 'new_crypto_price' topic using the utf-8 encoded crypto_currency as the partition key.\n",
      "    4. Sleep for the specified time interval.\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "@app.after_startup\n",
      "async def publish_crypto_price(logger: Logger):\n",
      "    \"\"\"\n",
      "    Creates an asynchronous task for executing the fetch_and_publish_crypto_price function.\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mQA_Engineer\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: python *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "\"cell\": \"# filename: application_skeleton.py; \\n\\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \\\"==== USER APP DESCRIPTION ====\\\" section, adhering to these guidelines:\\n\\n    - Avoid implementing business logic of ANY function. Instead, write \\\"raise NotImplementedError()\\\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \\\"log the consumed message using logger.info\\\" for subscriber functions.\\n\\n    - Ensure the generated code aligns with the specific app description requirements.\\n\\n    - Provide a clear and organized starting point for developers.\\n\\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\\n    \\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\\n\\n\\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\\n\\n\\n\\n==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastStream application with the localhost broker.\\nConsume from the 'new_pet' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\\nWhenever a new pet is added, send the new pet's information to the 'notify_adopters' topic.\\n\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\nfrom pydantic import BaseModel, Field, NonNegativeInt\\n\\nfrom faststream import FastStream, Logger\\nfrom faststream.kafka import KafkaBroker\\n\\n\\nclass Pet(BaseModel):\\n    pet_id: NonNegativeInt = Field(..., examples=[1], description=\\\"Int data example\\\")\\n    species: str = Field(..., examples=[\\\"dog\\\"], description=\\\"Pet example\\\")\\n    age: NonNegativeInt = Field(..., examples=[1], description=\\\"Int data example\\\")\\n\\n\\nbroker = KafkaBroker(\\\"localhost:9092\\\")\\napp = FastStream(broker)\\n\\n\\n@broker.publisher(\\\"notify_adopters\\\")\\n@broker.subscriber(\\\"new_pet\\\")\\nasync def on_new_pet(msg: Pet, logger: Logger) -> Pet:\\n    \\\"\\\"\\\"\\n    Processes a message from the 'new_pet' topic and send the new pet's information to the 'notify_adopters' topic.\\n\\n    Instructions:\\n    1. Consume a message from 'new_pet' topic.\\n    2. Send the new pet's information to the 'notify_adopters' topic.\\n\\n    \\\"\\\"\\\"\\n    raise NotImplementedError()\\n\\n\\n\",\n",
      "}\n",
      "\u001b[32m*******************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m groupchat_skeleton \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChat(agents\u001b[38;5;241m=\u001b[39m[user_skeleton_proxy, coder, quality_assurance_engineer], messages\u001b[38;5;241m=\u001b[39m[], max_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     11\u001b[0m manager_skeleton \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChatManager(groupchat\u001b[38;5;241m=\u001b[39mgroupchat_skeleton, llm_config\u001b[38;5;241m=\u001b[39mllm_config)\n\u001b[0;32m---> 12\u001b[0m \u001b[43muser_skeleton_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager_skeleton\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m# filename: application_skeleton.py; \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# type exit to terminate the chat\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 531\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_init_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m--> 779\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/groupchat.py:129\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    127\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m groupchat\u001b[38;5;241m.\u001b[39mselect_speaker(speaker, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# let the speaker speak\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39madmin_name \u001b[38;5;129;01min\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39magent_names:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;66;03m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m--> 779\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:698\u001b[0m, in \u001b[0;36mConversableAgent.check_termination_and_human_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;66;03m# if the human input is empty, and the message is a termination message, then we will terminate the conversation\u001b[39;00m\n\u001b[1;32m    697\u001b[0m         reply \u001b[38;5;241m=\u001b[39m reply \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminate \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_termination_msg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhuman_input_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNEVER\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    700\u001b[0m         reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[285], line 127\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    102\u001b[0m coder \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[1;32m    103\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    104\u001b[0m     system_message\u001b[38;5;241m=\u001b[39mCODER_SYSTEM_MESSAGE,\n\u001b[1;32m    105\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config,    \n\u001b[1;32m    106\u001b[0m     is_termination_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m (x \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTERMINATE\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    109\u001b[0m QA_SYSTEM_MESSAGE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124mYou are a QA engineer with 2 simple task that you need to check.\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124m1.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124mIf the code looks ok, forward it to User_skeleton_proxy.\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    123\u001b[0m quality_assurance_engineer \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mAssistantAgent(\n\u001b[1;32m    124\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQA_Engineer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    125\u001b[0m     system_message\u001b[38;5;241m=\u001b[39mQA_SYSTEM_MESSAGE,\n\u001b[1;32m    126\u001b[0m     llm_config\u001b[38;5;241m=\u001b[39mllm_config_qa,    \n\u001b[0;32m--> 127\u001b[0m     is_termination_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m (x \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTERMINATE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    128\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "CHAT_MANAGER_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Group chat manager.\n",
    "\n",
    "Always forward the message from the Coder to the Quality Ensurance Engineer.\n",
    "\n",
    "If the Quality Ensurance Engineer returns you ***** Suggested function Call: python *****, forward the message to the User_skeleton_proxy to execute it.\n",
    "Otherwise, forward the message to the Coder.\n",
    "\"\"\"\n",
    "\n",
    "groupchat_skeleton = autogen.GroupChat(agents=[user_skeleton_proxy, coder, quality_assurance_engineer], messages=[], max_round=6)\n",
    "manager_skeleton = autogen.GroupChatManager(groupchat=groupchat_skeleton, llm_config=llm_config)\n",
    "user_skeleton_proxy.initiate_chat(manager_skeleton, message=\"# filename: application_skeleton.py; \" + prompt)\n",
    "\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "eab9c77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "d = {\n",
    "\"cell\": \"# filename: application_skeleton.py; \\n\\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \\\"==== USER APP DESCRIPTION ====\\\" section, adhering to these guidelines:\\n\\n    - Avoid implementing business logic of ANY function. Instead, write \\\"raise NotImplementedError()\\\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \\\"log the consumed message using logger.info\\\" for subscriber functions.\\n\\n    - Ensure the generated code aligns with the specific app description requirements.\\n\\n    - Provide a clear and organized starting point for developers.\\n\\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\\n    \\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\\n\\n\\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\\n\\n\\n\\n==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastStream application with the localhost broker.\\nConsume from the 'new_pet' topic, which includes JSON encoded object with attributes: pet_id, species, and age.\\nWhenever a new pet is added, send the new pet's information to the 'notify_adopters' topic.\\n\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\nfrom pydantic import BaseModel, Field, NonNegativeInt\\n\\nfrom faststream import FastStream, Logger\\nfrom faststream.kafka import KafkaBroker\\n\\n\\nclass Pet(BaseModel):\\n    pet_id: NonNegativeInt = Field(..., examples=[1], description=\\\"Int data example\\\")\\n    species: str = Field(..., examples=[\\\"dog\\\"], description=\\\"Pet example\\\")\\n    age: NonNegativeInt = Field(..., examples=[1], description=\\\"Int data example\\\")\\n\\n\\nbroker = KafkaBroker(\\\"localhost:9092\\\")\\napp = FastStream(broker)\\n\\n\\n@broker.publisher(\\\"notify_adopters\\\")\\n@broker.subscriber(\\\"new_pet\\\")\\nasync def on_new_pet(msg: Pet, logger: Logger) -> Pet:\\n    \\\"\\\"\\\"\\n    Processes a message from the 'new_pet' topic and send the new pet's information to the 'notify_adopters' topic.\\n\\n    Instructions:\\n    1. Consume a message from 'new_pet' topic.\\n    2. Send the new pet's information to the 'notify_adopters' topic.\\n\\n    \\\"\\\"\\\"\\n    raise NotImplementedError()\\n\\n\\n\",\n",
    "}\n",
    "print(d and \"TERMINATE\" in d.get(\"content\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "220eb87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_skeleton_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "# filename: application_skeleton.py; Write FastAPI application skeleton for item creation\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[349], line 153\u001b[0m\n\u001b[1;32m    151\u001b[0m groupchat_skeleton \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChat(agents\u001b[38;5;241m=\u001b[39m[user_skeleton_proxy, coder, quality_assurance_engineer], messages\u001b[38;5;241m=\u001b[39m[], max_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    152\u001b[0m manager_skeleton \u001b[38;5;241m=\u001b[39m autogen\u001b[38;5;241m.\u001b[39mGroupChatManager(groupchat\u001b[38;5;241m=\u001b[39mgroupchat_skeleton, llm_config\u001b[38;5;241m=\u001b[39mllm_config, system_message\u001b[38;5;241m=\u001b[39mCHAT_MANAGER_SYSTEM_MESSAGE)\n\u001b[0;32m--> 153\u001b[0m \u001b[43muser_skeleton_proxy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate_chat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager_skeleton\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m# filename: application_skeleton.py; \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite FastAPI application skeleton for item creation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[0;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[0;32m--> 531\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_init_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[0;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[1;32m    332\u001b[0m valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_oai_message(message, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, recipient)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[0;32m--> 334\u001b[0m     \u001b[43mrecipient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreceive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_reply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[0;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m request_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreply_at_receive[sender] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_messages\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(reply, sender, silent\u001b[38;5;241m=\u001b[39msilent)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m--> 779\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/groupchat.py:129\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    127\u001b[0m     speaker \u001b[38;5;241m=\u001b[39m groupchat\u001b[38;5;241m.\u001b[39mselect_speaker(speaker, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# let the speaker speak\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mspeaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_reply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# let the admin agent speak if interrupted\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39madmin_name \u001b[38;5;129;01min\u001b[39;00m groupchat\u001b[38;5;241m.\u001b[39magent_names:\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;66;03m# admin agent is one of the participants\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:779\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[0;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m\"\u001b[39m], sender):\n\u001b[0;32m--> 779\u001b[0m     final, reply \u001b[38;5;241m=\u001b[39m \u001b[43mreply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreply_func_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final:\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m reply\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/agentchat/conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[0;34m(self, messages, sender, config)\u001b[0m\n\u001b[1;32m    603\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oai_messages[sender]\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43moai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_oai_system_message\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mllm_config\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, oai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mextract_text_or_function_call(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/completion.py:789\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    787\u001b[0m     base_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_retry_period\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 789\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_on_ratelimit_or_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraise_on_ratelimit_or_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbase_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/completion.py:820\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m diskcache\u001b[38;5;241m.\u001b[39mCache(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcache_path) \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_cache:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mset_cache(seed)\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_ratelimit_or_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_ratelimit_or_timeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/autogen/oai/completion.py:210\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[0;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[1;32m    208\u001b[0m         response \u001b[38;5;241m=\u001b[39m openai_completion\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_completion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m     ServiceUnavailableError,\n\u001b[1;32m    213\u001b[0m     APIConnectionError,\n\u001b[1;32m    214\u001b[0m ):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# transient error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretry_wait_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    139\u001b[0m ):\n\u001b[1;32m    140\u001b[0m     (\n\u001b[1;32m    141\u001b[0m         deployment_id,\n\u001b[1;32m    142\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/api_requestor.py:289\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    280\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/api_requestor.py:606\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    604\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 606\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/urllib3/connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "config_list = [\n",
    "#     {\n",
    "#         \"model\": \"gpt-4\",\n",
    "#         \"api_key\": api_key\n",
    "#     },\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo-16k\",\n",
    "        \"api_key\": api_key\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_config_qa = {\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"python\",\n",
    "            \"description\": \"run cell in ipython and return the execution result.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"cell\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Valid Python cell to execute.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"cell\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": random.randint(100, 900),\n",
    "    \"temperature\": 0.7,  # temperature for sampling\n",
    "}  \n",
    "\n",
    "llm_config = {\n",
    "    \"config_list\": config_list,\n",
    "    \"seed\": random.randint(100, 900),\n",
    "    \"temperature\": 0.7,  # temperature for sampling\n",
    "} \n",
    "\n",
    "# You are a proxy between the Coder and the Quality Assurance Engineer. All messages received from the Coder forward to the Quality Assurance Engineer.\n",
    "USER_PROXY_SYSTEM_MESSAGE = \"\"\"\n",
    "\n",
    "\n",
    "Each time you receive a message from the Coder, follow these steps: \n",
    "- If the code looks good to you, save it in the application_skeleton.py and execute it.\n",
    "- Your job can not be done until you execute application_skeleton.py!\n",
    "- If there are not any errors once you execute the application_skeleton.py reply with \"# TERMINATE\".\n",
    "- But you can't reply with TERMINATE if you did not execute the received code!!!\n",
    "- If there are some problems with the code, reply with the instructions what needs to be fixed. NEVER reply with any code, just instructions!\n",
    "- When something needs to be fixed, send it to the Coder\n",
    "\n",
    "The code execution should succesfully pass - \"exitcode: 0 (execution succeeded)\"\n",
    "If the code execution is successful, reply with \"TERMINATE\".\n",
    "\"\"\"\n",
    "# Reply \"# TERMINATE\" in the end when everything is done.\n",
    "\n",
    "code_execution_config={\n",
    "       \"work_dir\": \"groupchat_skeleton\",\n",
    "       \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "}\n",
    "\n",
    "user_skeleton_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_skeleton_proxy\",\n",
    "    system_message=USER_PROXY_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,\n",
    "    code_execution_config=code_execution_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if (x.get(\"content\") and \"TERMINATE\" in x.get(\"content\")) else False,\n",
    ")\n",
    "\n",
    "# CODER_SYSTEM_MESSAGE = \"\"\"\n",
    "# Your job is to write application_skeleton.py for the given application description.\n",
    "# The application must use FastStream framework. \n",
    "# For each function and method write the docstring and raise NotImplementedError() i.e. do NOT implement any function.\n",
    "# The code you create MUST be inside the ```python block!\n",
    "\n",
    "# If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "# If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "# When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "# \"\"\"\n",
    "\n",
    "CODER_SYSTEM_MESSAGE = \"\"\"\n",
    "Generate skeleton code for the code, adhering to these guidelines:\n",
    "\n",
    "    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n",
    "\n",
    "    - Ensure the generated code aligns with the specific app description requirements.\n",
    "\n",
    "    - Provide a clear and organized starting point for developers.\n",
    "\n",
    "    - Your response must contain only valid Python code within back-ticks\n",
    "    \n",
    "    - ALWAYS enclose the response within back-ticks. Meaning ALWAYS ADD ```python to your response.\n",
    "    \n",
    "    - NEVER add main function and \"if __name__ == \"__main__\":\" block\n",
    "\n",
    "\n",
    "The goal is to offer developers a structured starting point that matches the example app descriptions.\n",
    "Follow the example patterns provided for reference.\n",
    "\"\"\"\n",
    "\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    system_message=CODER_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config,    \n",
    "    is_termination_msg=lambda x: True if (x.get(\"content\") and \"TERMINATE\" in x.get(\"content\")) else False,\n",
    ")\n",
    "\n",
    "JUNIOR_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a junior developer with 3 simple task that you need to check.\n",
    "1.\n",
    "Check that all functions and methods which the Coder sends to you are NOT implemented, each function should just raise NotImplementedError().\n",
    "If some function or method is implemented, reply to the the Coder to delete the implementation and just to replace it with \"raise NotImplementedError()\"\n",
    "2.\n",
    "Check that the IS NOT main function and \"if __name__ == \"__main__\":\" block.\n",
    "If the main block is implemented, tell the Coder to delete it\n",
    "3. The code is written inside the  within back-ticks - ```python\n",
    "\n",
    "Do NOT write any functions to test that, just take a look at the code and write instructions to the Coder if some function is implemented.\n",
    "You should never write any NEW code.\n",
    "\n",
    "If the code looks ok, send the Suggested function Call: python, to User_skeleton_proxy so he can execute it.\n",
    "\"\"\"\n",
    "\n",
    "quality_assurance_engineer = autogen.AssistantAgent(\n",
    "    name=\"Junior_developer\",\n",
    "    system_message=JUNIOR_SYSTEM_MESSAGE,\n",
    "    llm_config=llm_config_qa,    \n",
    "    is_termination_msg=lambda x: True if (x.get(\"content\") and \"TERMINATE\" in x.get(\"content\")) else False,\n",
    "\n",
    ")\n",
    "\n",
    "user_skeleton_proxy.register_function(\n",
    "    function_map={\n",
    "        \"python\": exec_python,\n",
    "    }\n",
    ")\n",
    "\n",
    "CHAT_MANAGER_SYSTEM_MESSAGE = \"\"\"\n",
    "You are a Group chat manager.\n",
    "\n",
    "These are the rules how to select the next speeker:\n",
    "- The first message must be sent to the Coder.\n",
    "- ALL messages from the Coder forward to the Junior_developer.\n",
    "- ALL messages from the Junior_developer forward to the User_skeleton_proxy.\n",
    "- ALL messages from the User_skeleton_proxy forward to the Coder.\n",
    "\"\"\"\n",
    "\n",
    "groupchat_skeleton = autogen.GroupChat(agents=[user_skeleton_proxy, coder, quality_assurance_engineer], messages=[], max_round=12)\n",
    "manager_skeleton = autogen.GroupChatManager(groupchat=groupchat_skeleton, llm_config=llm_config, system_message=CHAT_MANAGER_SYSTEM_MESSAGE)\n",
    "user_skeleton_proxy.initiate_chat(manager_skeleton, message=\"# filename: application_skeleton.py; \" + \"Write FastAPI application skeleton for item creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d816344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f24e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
