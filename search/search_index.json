{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Code generator for FastStream","text":"<p><code>faststream-gen</code> is a Python library that uses generative AI to automatically generate FastStream applications. Simply describe your application requirements, and <code>faststream-gen</code> will generate a production-grade FastStream project that is ready to deploy in no time.</p> <p> </p> <p>Documentation: https://faststream-gen.airt.ai</p> <p>Source Code: https://github.com/airtai/faststream-gen</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>The code generator for FastStream is a Python library that automates the process of creating FastStream applications. It works by taking your application requirements and swiftly turning them into a ready-to-deploy FastStream application.</p> <p>The key features are:</p> <ul> <li>Automatic FastStream project generation: <code>faststream-gen</code> enables   you to easily generate complete FastStream application with minimal   effort. This library allows you to outline your application   requirements, and it will quickly transform them into a fully-fledged   FastStream project.</li> <li>Tested code: <code>faststream-gen</code> provides dependable code through   rigorous testing, including pre-implemented integration tests,   ensuring stability and functionality, saving development time, and   preventing common bugs.</li> <li>Script Templates: Streamline the deployment of your FastStream   application using faststream-gen\u2019s built-in scripts, tailored for   initiating, subscribing to Kafka topic and shutting down the local   Kafka broker.</li> <li>GitHub workflow files: <code>faststream-gen</code> integrates seamlessly with   your version control and continuous integration pipeline through its   GitHub workflow files. These predefined configuration files are   optimized for FastStream projects, enabling smooth integration with   GitHub Actions. You can automate tasks such as code validation,   testing, and deployment, ensuring that your FastStream application   remains in top shape throughout its development lifecycle.</li> </ul>        Your browser does not support the <code>video</code> element."},{"location":"#quick-start","title":"Quick start","text":"<p>The following quick start guide will walk you through installing and configuring the <code>faststream-gen</code> library, demonstrating the creation of a new FastStream project in seconds.</p>"},{"location":"#install","title":"Install","text":"<p><code>faststream-gen</code> is published as a Python package and can be installed with pip:</p> <pre><code>pip install faststream-gen\n</code></pre> <p>If the installation was successful, you should now have the faststream-gen installed on your system. Run the below command from the terminal to see the full list of available commands:</p> <pre><code>faststream_gen --help\n</code></pre> <pre><code> Usage: faststream_gen [OPTIONS] [DESCRIPTION]\n\n Effortlessly create a new FastStream project based on the app description.\n\n\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502   description      [DESCRIPTION]  Summarize your FastStream application in a \u2502\n\u2502                                   few sentences!                             \u2502\n\u2502                                                                              \u2502\n\u2502                                   Include details about messages, topics,    \u2502\n\u2502                                   servers, and a brief overview of the       \u2502\n\u2502                                   intended business logic.                   \u2502\n\u2502                                                                              \u2502\n\u2502                                   The simpler and more specific the app      \u2502\n\u2502                                   description is, the better the generated   \u2502\n\u2502                                   app will be. Please refer to the below     \u2502\n\u2502                                   example for inspiration:                   \u2502\n\u2502                                                                              \u2502\n\u2502                                   Create a FastStream application using      \u2502\n\u2502                                   localhost broker for testing and use the   \u2502\n\u2502                                   default port number.  It should consume    \u2502\n\u2502                                   messages from the \"input_data\" topic,      \u2502\n\u2502                                   where each message is a JSON encoded       \u2502\n\u2502                                   object containing a single attribute:      \u2502\n\u2502                                   'data'.  For each consumed message, create \u2502\n\u2502                                   a new message object and increment the     \u2502\n\u2502                                   value of the data attribute by 1. Finally, \u2502\n\u2502                                   send the modified message to the           \u2502\n\u2502                                   'output_data' topic.                       \u2502\n\u2502                                   [default: None]                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --input_file          -i      TEXT                   The path to the file    \u2502\n\u2502                                                      with the app            \u2502\n\u2502                                                      desription. This path   \u2502\n\u2502                                                      should be relative to   \u2502\n\u2502                                                      the current working     \u2502\n\u2502                                                      directory.              \u2502\n\u2502                                                      If the app description  \u2502\n\u2502                                                      is passed via both a    \u2502\n\u2502                                                      --input_file and a      \u2502\n\u2502                                                      command line argument,  \u2502\n\u2502                                                      the description from    \u2502\n\u2502                                                      the command line will   \u2502\n\u2502                                                      be used to create the   \u2502\n\u2502                                                      application.            \u2502\n\u2502                                                      [default: None]         \u2502\n\u2502 --output_path         -o      TEXT                   The path to the output  \u2502\n\u2502                                                      directory where the     \u2502\n\u2502                                                      generated project files \u2502\n\u2502                                                      will be saved. This     \u2502\n\u2502                                                      path should be relative \u2502\n\u2502                                                      to the current working  \u2502\n\u2502                                                      directory.              \u2502\n\u2502                                                      [default: .]            \u2502\n\u2502 --model               -m      [gpt-3.5-turbo-16k|gp  The OpenAI model that   \u2502\n\u2502                               t-4]                   will be used to create  \u2502\n\u2502                                                      the FastStream project. \u2502\n\u2502                                                      For better results, we  \u2502\n\u2502                                                      recommend using         \u2502\n\u2502                                                      'gpt-4'.                \u2502\n\u2502                                                      [default:               \u2502\n\u2502                                                      gpt-3.5-turbo-16k]      \u2502\n\u2502 --verbose             -v                             Enable verbose logging  \u2502\n\u2502                                                      by setting the logger   \u2502\n\u2502                                                      level to INFO.          \u2502\n\u2502 --dev                 -d                             Save the complete logs  \u2502\n\u2502                                                      generated by            \u2502\n\u2502                                                      faststream-gen inside   \u2502\n\u2502                                                      the output_path         \u2502\n\u2502                                                      directory.              \u2502\n\u2502 --install-completion                                 Install completion for  \u2502\n\u2502                                                      the current shell.      \u2502\n\u2502 --show-completion                                    Show completion for the \u2502\n\u2502                                                      current shell, to copy  \u2502\n\u2502                                                      it or customize the     \u2502\n\u2502                                                      installation.           \u2502\n\u2502 --help                                               Show this message and   \u2502\n\u2502                                                      exit.                   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"#generate-new-project","title":"Generate new project","text":"<p>The faststream-gen library uses OpenAI\u2019s model to generate FastStream projects. In order to use the library, you\u2019ll need to create an API key for OpenAI.</p> <p>Once you have your API key, store it in the OPENAI_API_KEY environment variable. This is a necessary step for the library to work.</p> <p>We\u2019re now ready to create a new FastStream application with the <code>faststream-gen</code> library.</p> <p>Simply run the following command to create a new FastStream application in the <code>my-awesome-project</code> directory:</p> <pre><code>faststream_gen \"Create a FastStream application using localhost broker for testing and use the default port number. It should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. While consuming from the topic, increment the value of the data attribute by 1. Finally, send message to the 'output_data' topic.\" -o \"./my-awesome-project\"\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n \u2714 Application description validated. \n \u2714 FastStream app skeleton code generated. akes around 15 to 45 seconds)...\n \u2714 The app and the tests are generated.  around 30 to 90 seconds)...\n \u2714 New FastStream project created. \n \u2714 Integration tests were successfully completed. \n Tokens used: 9398\n Total Cost (USD): $0.02865\n\u2728  All files were successfully generated!\n</code></pre> <p>Here\u2019s a look at the directory hierarchy:</p> <pre><code>my-awesome-project\n\u251c\u2500\u2500 .github\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workflows\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 deploy_docs.yml\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 test.yml\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 app\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 application.py\n\u251c\u2500\u2500 dev_requirements.txt\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 scripts\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 services.yml\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 start_kafka_broker_locally.sh\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 stop_kafka_broker_locally.sh\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 subscribe_to_kafka_broker_locally.sh\n\u2514\u2500\u2500 tests\n    \u2514\u2500\u2500 test_application.py\n\n5 directories, 14 files\n</code></pre> <p>Let\u2019s take a quick look at the generated application and test code.</p> <p><code>application.py</code>:</p> <pre><code>from faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\nto_output_data = broker.publisher(\"output_data\")\n\n\n@broker.subscriber(\"input_data\")\nasync def on_input_data(msg: dict, logger: Logger) -&gt; None:\n    logger.info(f\"{msg=}\")\n    incremented_data = msg[\"data\"] + 1\n    await to_output_data.publish({\"data\": incremented_data})\n</code></pre> <p><code>test_application.py</code>:</p> <pre><code>import pytest\n\nfrom faststream import Context\nfrom faststream.kafka import TestKafkaBroker\n\nfrom app.application import broker, on_input_data\n\n\n@broker.subscriber(\"output_data\")\nasync def on_output_data(msg: dict, key: bytes = Context(\"message.raw_message.key\")):\n    pass\n\n\n@pytest.mark.asyncio\nasync def test_data_was_incremented():\n    async with TestKafkaBroker(broker):\n        await broker.publish({\"data\": 1}, \"input_data\")\n        on_input_data.mock.assert_called_with({\"data\": 1})\n        on_output_data.mock.assert_called_with({\"data\": 2})\n</code></pre>"},{"location":"#start-localhost-kafka-broker","title":"Start localhost Kafka broker","text":"<p>In order for <code>FastStream</code> applications to publish and consume messages from the Kafka broker, it is necessary to have a running Kafka broker.</p> <p>Along with application and test, <code>faststream-gen</code> also generated <code>scripts</code> directory. You can start local Kafka broker (inside docker container) by executing following commands:</p> <pre><code>cd my-awesome-project\n# make all shell scripts executable\nchmod +x scripts/*.sh\n# start local kafka broker\n./scripts/start_kafka_broker_locally.sh\n</code></pre>"},{"location":"#start-application","title":"Start application","text":"<p>To start the FastKafka application, run the following command:</p> <pre><code>faststream run  app.application:app\n</code></pre>"},{"location":"#stop-application","title":"Stop application","text":"<p>To stop the FastKafka application, run the following command:</p> <pre><code>./scripts/stop_kafka_broker_locally.sh\n</code></pre>"},{"location":"#copyright","title":"Copyright","text":"<p>Copyright \u00a9 2023 onwards airt technologies ltd, Inc.</p>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the terms of the Apache License 2.0</p>"},{"location":"App_And_Test_Generator/","title":"App And Test Generator","text":"<pre><code>from contextlib import contextmanager\nimport unittest.mock\n\nimport pytest\nimport openai\n\nfrom faststream_gen._components.logger import suppress_timestamps\nfrom faststream_gen._code_generator.helper import mock_openai_create\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=30)\nlogger.info(\"ok\")\n</code></pre> <pre><code>fixture = \"\"\"\nprint(\"hi)\n\"\"\"\n\nexpected = \"\"\"print(\"hi\")\"\"\"\n\nactual = _fix_generated_code(fixture)\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>print(\"hi\")\n</code></pre> <pre><code>fixture_response = \"\"\"\n### application.py ###\n\nprint('hi')\n\n### test.py ###\ndef test_always_passes():\n    assert True\n\"\"\"\ntest_response = \"\"\"\ndef test_always_passes():\n    assert True\n\"\"\"\nwith TemporaryDirectory() as d:\n    expected = ([], \"\")\n    with mock_openai_create(test_response):\n        actual = _validate_response(fixture_response, d)\n        print(actual)\n        assert actual == expected\n</code></pre> <pre><code>([], '')\n</code></pre> <pre><code>fixture_response = \"\"\"\n### application.py ##\n\nprint('hi')\n\n### test.py ###\ndef test_always_passes():\n    assert True\n\"\"\"\ntest_response = \"\"\"\ndef test_always_passes():\n    assert True\n\"\"\"\nwith TemporaryDirectory() as d:\n    expected = (['Please add ### application.py ### and ### test.py ### in your response'], \"\\n### application.py ##\\n\\nprint('hi')\\n\\n### test.py ###\\ndef test_always_passes():\\n    assert True\\n\")\n    with mock_openai_create(test_response):\n        actual = _validate_response(fixture_response, d)\n        print(actual)\n        assert actual == expected, actual\n</code></pre> <pre><code>(['Please add ### application.py ### and ### test.py ### in your response'], \"\\n### application.py ##\\n\\nprint('hi')\\n\\n### test.py ###\\ndef test_always_passes():\\n    assert True\\n\")\n</code></pre> <pre><code>fixture_response = \"\"\"\n### application.py ###\n\nprint('hi')\n\n### test.py ###\n\ndef test_always_fails():\n    assert False\n\"\"\"\nfixture_app_code = \"print('hi')\"\n\ntest_response = \"\"\"\ndef test_always_fails():\n    assert False\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    with mock_openai_create(test_response):\n        actual = _validate_response(fixture_response, d)\n        print(actual[0])\n        assert actual != [], actual\n        print(\"OK\")\n</code></pre> <pre><code>['\\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.11.5, pytest-7.4.2, pluggy-1.3.0\\nrootdir: /tmp/tmp858giugx\\nplugins: anyio-3.7.1, asyncio-0.21.1\\nasyncio: mode=Mode.STRICT\\ncollected 1 item\\n\\ntests/test_application.py \\x1b[31mF\\x1b[0m\\x1b[31m                                              [100%]\\x1b[0m\\n\\n=================================== FAILURES ===================================\\n\\x1b[31m\\x1b[1m______________________________ test_always_fails _______________________________\\x1b[0m\\n\\x1b[1m\\x1b[31mtests/test_application.py\\x1b[0m:3: in test_always_fails\\n    \\x1b[94massert\\x1b[39;49;00m \\x1b[94mFalse\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE   assert False\\x1b[0m\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mFAILED\\x1b[0m tests/test_application.py::\\x1b[1mtest_always_fails\\x1b[0m - assert False\\n\\x1b[31m============================== \\x1b[31m\\x1b[1m1 failed\\x1b[0m\\x1b[31m in 0.04s\\x1b[0m\\x1b[31m ===============================\\x1b[0m\\n']\nOK\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some valid prompt\"\napp_skeleton = \"some app skeleton\"\ntotal_usage = []\n\ntest_response = \"\"\"\n### application.py ###\n\nprint('some valid python code')\n\n### test.py ###\n\nfrom app import application\n\ndef test_always_passes():\n    assert True\n\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    test_file_path = Path(d) / TEST_FILE_PATH\n    test_file_path.parent.mkdir(parents=True, exist_ok=True)\n    init_file_path = test_file_path.parent / \"__init__.py\"\n    init_file_path.touch()\n    with mock_openai_create(test_response):\n        total_usage, is_valid_app_code = _generate(\n            model, prompt, app_skeleton, total_usage, d\n        )\n\n    print(is_valid_app_code)\n\n    assert is_valid_app_code\n    assert isinstance(is_valid_app_code, bool)\n</code></pre> <pre><code>True\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some invalid prompt\"\napp_skeleton = \"some invalid app skeleton\"\ntotal_usage = []\n\ntest_response = \"\"\"\n### application.py ###\n\nprint(\"invalid app code\")\n\n### test.py ###\n\nimport pytest\n\nfrom faststream.kafka import TestKafkaBroker\n\nfrom .app import CourseUpdates, broker, on_course_update\n\n\nprint(\"invalid test code\")\n\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    test_file_path = Path(d) / TEST_FILE_PATH\n    test_file_path.parent.mkdir(parents=True, exist_ok=True)\n    init_file_path = test_file_path.parent / \"__init__.py\"\n    init_file_path.touch()\n    with mock_openai_create(test_response):\n        total_usage, is_valid_app_code = _generate(\n            model, prompt, app_skeleton, total_usage, d\n        )\n        print(is_valid_app_code)\n        assert not is_valid_app_code\n        assert isinstance(is_valid_app_code, bool)\n</code></pre> <pre><code>False\n</code></pre> <p>source</p>"},{"location":"App_And_Test_Generator/#generate_app_and_test","title":"generate_app_and_test","text":"<pre><code> generate_app_and_test (description:str, model:str, output_directory:str,\n                        total_usage:List[Dict[str,int]],\n                        relevant_prompt_examples:str)\n</code></pre> <p>Generate integration test for the FastStream app</p> <p>Args: description: Validated User application description code_gen_directory: The directory containing the generated files. relevant_prompt_examples: Relevant examples to add in the prompts.</p> <p>Returns: The generated integration test code for the application</p> <pre><code>fixture_skeleton_code = \"\"\"\nfrom pydantic import BaseModel, Field\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass Product(BaseModel):\n    product_name: str = Field(..., description=\"Name of the product\")\n    currency: str = Field(..., description=\"Currency of the price\")\n    price: float = Field(..., description=\"Price of the product\")\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.publisher(\"change_currency\")\n@broker.subscriber(\"store_product\")\nasync def on_store_product(product: Product, logger: Logger) -&gt; Product:\n    '''Processes a message from 'store_product' topic, changes currency to 'EUR' and divides price by 7.5 if currency is 'HRK'.\n\n    Instructions:\n    1. Consume a message from 'store_product' topic.\n    2. Log the consumed message using logger.info.\n    3. Check if the currency attribute is set to 'HRK'.\n    4. If the currency is 'HRK', change the currency to 'EUR' and divide the price by 7.5.\n    5. If the currency is not 'HRK', do not modify the original message.\n    6. Publish the consumed message to 'change_currency' topic.\n\n\n    '''\n    raise NotImplementedError()\n\"\"\"\n\nfixture_description = \"\"\"\nInvalid description\n\"\"\"\n\nrelevant_examples = '''no examples passed'''\n\ntest_response = \"\"\"\n### application.py ###\n\nprint(\"invalid app code\")\n\n### test.py ###\n\nimport pytest\n\nfrom faststream.kafka import TestKafkaBroker\n\nfrom .app import CourseUpdates, broker, on_course_update\n\n\nprint(\"invalid test code\")\n\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    app_skeleton_file_name = Path(d) / APPLICATION_FILE_PATH\n    write_file_contents(app_skeleton_file_name, fixture_skeleton_code)\n\n    with mock_openai_create(test_response):    \n        usage, is_valid_app_code = generate_app_and_test(fixture_description, OpenAIModel.gpt3.value, d, [], relevant_examples)\n\n    logs_dir = Path(d) / LOGS_DIR_NAME\n    assert logs_dir.exists()\n\n\nassert int(usage[0][\"total_tokens\"]) &gt; 0\nprint(usage)\n\nprint(is_valid_app_code)\nassert not is_valid_app_code\nassert isinstance(is_valid_app_code, bool)\n</code></pre> <pre><code>\u2839 Generating application and tests (usually takes around 30 to 90 seconds)...  \u2718 Error: Failed to generate a valid application and test code.               \n[defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390}), defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390}), defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390})]\nFalse\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:228: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(value) if value else value\n</code></pre> <pre><code># todo: fix the below test. have to mock the OpenAI call twice but should expect different response in each step\n\nfixture_skeleton_code = \"\"\"\nfrom pydantic import BaseModel, Field\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass Product(BaseModel):\n    product_name: str = Field(..., description=\"Name of the product\")\n    currency: str = Field(..., description=\"Currency of the price\")\n    price: float = Field(..., description=\"Price of the product\")\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.publisher(\"change_currency\")\n@broker.subscriber(\"store_product\")\nasync def on_store_product(product: Product, logger: Logger) -&gt; Product:\n    '''Processes a message from 'store_product' topic, changes currency to 'EUR' and divides price by 7.5 if currency is 'HRK'.\n\n    Instructions:\n    1. Consume a message from 'store_product' topic.\n    2. Log the consumed message using logger.info.\n    3. Check if the currency attribute is set to 'HRK'.\n    4. If the currency is 'HRK', change the currency to 'EUR' and divide the price by 7.5.\n    5. If the currency is not 'HRK', do not modify the original message.\n    6. Publish the consumed message to 'change_currency' topic.\n\n\n    '''\n    raise NotImplementedError()\n\"\"\"\n\nfixture_description = \"\"\"\nCreate a FastStream application using localhost broker for testing and use default port number. It should consume from 'store_product' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. 'EUR'. For each consumed message, check if the currency attribute is set to 'HRK'. If it is then change the currency to 'EUR' and divide the price by 7.5, if the currency is not set to 'HRK' don't change the original message. Finally, publish the consumed message to 'change_currency' topic.\n\"\"\"\n\ntest_response = '''\n\n### application.py ###\n\nfrom typing import Optional\n\nfrom pydantic import BaseModel, Field\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass CourseUpdates(BaseModel):\n    course_name: str = Field(..., examples=[\"Biology\"], description=\"Course example\")\n    new_content: Optional[str] = Field(\n        default=None, examples=[\"New content\"], description=\"Content example\"\n    )\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\n@broker.publisher(\"notify_updates\")\n@broker.subscriber(\"course_updates\")\nasync def on_course_update(msg: CourseUpdates, logger: Logger) -&gt; CourseUpdates:\n    logger.info(msg)\n\n    if msg.new_content:\n        logger.info(f\"Course has new content {msg.new_content=}\")\n        msg = CourseUpdates(\n            course_name=(\"Updated: \" + msg.course_name), new_content=msg.new_content\n        )\n    return msg\n\n### test.py ###\n\nimport pytest\n\nfrom faststream.kafka import TestKafkaBroker\n\nfrom app.application import CourseUpdates, broker, on_course_update\n\n\n@broker.subscriber(\"notify_updates\")\nasync def on_notify_update(msg: CourseUpdates):\n    pass\n\n\n@pytest.mark.asyncio\nasync def test_app_without_new_content():\n    async with TestKafkaBroker(broker):\n        await broker.publish(CourseUpdates(course_name=\"Biology\"), \"course_updates\")\n        on_course_update.mock.assert_called_with(\n            dict(CourseUpdates(course_name=\"Biology\"))\n        )\n        on_notify_update.mock.assert_called_with(\n            dict(CourseUpdates(course_name=\"Biology\"))\n        )\n\n\n@pytest.mark.asyncio\nasync def test_app_with_new_content():\n    async with TestKafkaBroker(broker):\n        await broker.publish(\n            CourseUpdates(\n                course_name=\"Biology\", new_content=\"We have additional classes...\"\n            ),\n            \"course_updates\",\n        )\n        on_course_update.mock.assert_called_with(\n            dict(\n                CourseUpdates(\n                    course_name=\"Biology\", new_content=\"We have additional classes...\"\n                )\n            )\n        )\n        on_notify_update.mock.assert_called_with(\n            dict(\n                CourseUpdates(\n                    course_name=\"Updated: Biology\",\n                    new_content=\"We have additional classes...\",\n                )\n            )\n        )\n\n'''\n\nwith TemporaryDirectory() as d:\n    app_skeleton_file_name = Path(d) / APPLICATION_FILE_PATH\n    write_file_contents(app_skeleton_file_name, fixture_skeleton_code)\n\n    test_file_path = Path(d) / TEST_FILE_PATH\n    test_file_path.parent.mkdir(parents=True, exist_ok=True)\n    init_file_path = test_file_path.parent / \"__init__.py\"\n    init_file_path.touch()\n\n    with mock_openai_create(test_response):    \n        usage, is_valid_app_code = generate_app_and_test(fixture_description, OpenAIModel.gpt3.value, d, [], relevant_examples)\n\n    logs_dir = Path(d) / LOGS_DIR_NAME\n    assert logs_dir.exists()\n\n\nassert int(usage[0][\"total_tokens\"]) &gt; 0\nprint(usage)\n\nprint(is_valid_app_code)\n# assert is_valid_app_code\n# assert isinstance(is_valid_app_code, bool)\n</code></pre> <pre><code>\u2839 Generating application and tests (usually takes around 30 to 90 seconds)...  \u2718 Error: Failed to generate a valid application and test code.               \n[defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390}), defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390}), defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390})]\nFalse\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:228: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(value) if value else value\n</code></pre>"},{"location":"App_Description_Validator/","title":"App Description Validator","text":"<pre><code>import pytest\n\nfrom faststream_gen._components.logger import suppress_timestamps\nfrom faststream_gen._code_generator.helper import mock_openai_create\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=20)\nlogger.info(\"ok\")\n</code></pre> <pre><code>[INFO] __main__: ok\n</code></pre> <p>source</p>"},{"location":"App_Description_Validator/#validate_app_description","title":"validate_app_description","text":"<pre><code> validate_app_description (description:str, model:str,\n                           total_usage:List[Dict[str,int]])\n</code></pre> <p>Validate the user\u2019s application description</p> <p>If the description is unrelated to FastStream or contains insensitive/inappropriate language, show an error message and exit the program. Otherwise, display the success message in the terminal.</p> <p>Args: description: User\u2019s application description</p> <p>Raises: ValueError: If the application description is invalid</p> <pre><code>test_response = \"0\"\n\nwith mock_openai_create(test_response):\n    with pytest.raises(ValueError) as e:\n        app_description = \"What is FastStream\"\n        validate_app_description(app_description, OpenAIModel.gpt3.value, [])\n\n\nprint(e.value)\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n[INFO] __main__: ==== App description validation ====\n\u280b Validating the application description...[INFO] faiss.loader: Loading faiss with AVX2 support.\n[INFO] faiss.loader: Successfully loaded faiss with AVX2 support.\n\u2819 Validating the application description... \u2834 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nWhat is FastStream\n==== YOUR RESPONSE ====\n\n\u2718 Error: Application description validation failed.\nI apologize, but I can only respond to queries related to FastStream code generation. Feel free to ask me about using FastStream, and I'll do my best to help you with that!\n\nIf you're unsure about how to construct the app description, consider the following example for guidance\n\nAPPLICATION DESCRIPTION EXAMPLE:\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre> <pre><code>test_response = \"1\"\n\nwith mock_openai_create(test_response):\n    with pytest.raises(ValueError) as e:\n        app_description = \"What is FastStream\"\n        validate_app_description(app_description, OpenAIModel.gpt3.value, [])\n\n\nprint(e.value)\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n[INFO] __main__: ==== App description validation ====\n\u2839 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nWhat is FastStream\n==== YOUR RESPONSE ====\n\n\u2718 Error: Application description validation failed.\n\nGreat to see your interest in FastStream! Unfortunately, I can only generate FastStream code and offer assistance in that area. For general information about FastStream, please visit https://fastkafka.airt.ai/\n\nIf you're unsure about how to construct the app description, consider the following example for guidance\n\nAPPLICATION DESCRIPTION EXAMPLE:\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n</code></pre> <pre><code>test_response = \"2\"\n\nwith mock_openai_create(test_response):\n    with pytest.raises(ValueError) as e:\n        app_description = \"What is FastStream\"\n        validate_app_description(app_description, OpenAIModel.gpt3.value, [])\n\n\nprint(e.value)\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n[INFO] __main__: ==== App description validation ====\n\u2839 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nWhat is FastStream\n==== YOUR RESPONSE ====\n\n\u2718 Error: Application description is incomplete.\n\nPlease check if your application description is missing some crucial information:\n- Description of the messages that will be produced or consumed\n- At least one topic\n- The business logic to implement while consuming or producing the messages\n\n\nIf you're unsure about how to construct the app description, consider the following example for guidance\n\nAPPLICATION DESCRIPTION EXAMPLE:\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n</code></pre> <pre><code>test_response = \"3\"\n\nwith mock_openai_create(test_response):\n    app_description = \"What is FastStream\"\n    validate_app_description(app_description, OpenAIModel.gpt3.value, [])\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n[INFO] __main__: ==== App description validation ====\n\u2839 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nWhat is FastStream\n==== YOUR RESPONSE ====\n\n \u2714 Application description validated.\n</code></pre>"},{"location":"App_Skeleton_Generator/","title":"App Skeleton Generator","text":"<pre><code>from tempfile import TemporaryDirectory\n\nimport pytest\n\nfrom faststream_gen._components.logger import suppress_timestamps\nfrom faststream_gen._code_generator.constants import OpenAIModel\nfrom faststream_gen._code_generator.helper import mock_openai_create\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=20)\nlogger.info(\"ok\")\n</code></pre> <pre><code>[INFO] __main__: ok\n</code></pre> <pre><code>fixture = '''\nimport asyncio\nimport json\n\nimport aiohttp\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(..., examples=[50000.0], description=\"Current price of cryptocurrency in USD\")\n    crypto_currency: str = Field(..., examples=[\"BTC\"], description=\"The cryptocurrency\")\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nasync def fetch_crypto_price(url: str) -&gt; dict:\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.json()\n\n\nasync def get_and_publish_crypto_price(\n    crypto_currency: str, logger: Logger, context: ContextRepo, time_interval: int = 2\n) -&gt; None:\n    \"\"\"\n    While app_is_running variable inside context is True, repeat the following process:\n        Retrieve the current cryptocurrency price by sending a GET request to the appropriate URL.\n        Extract the price and crypto_currency from the response JSON.\n        Create a CryptoPrice object with the retrieved data.\n        Publish the CryptoPrice object to the 'new_crypto_price' topic, using the utf-8 encoded crypto_currency as the partition key.\n        Asynchronously sleep for the specified time_interval.\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to True - we will use this variable as running loop condition\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_shutdown\nasync def shutdown(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to False\n\n    Get all executed tasks from context and wait for them to finish\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.after_startup\nasync def publish_crypto_price(logger: Logger, context: ContextRepo):\n    \"\"\"\n    Create asynchronous tasks for executing get_and_publish_crypto_price function.\n    Run this process for Bitcoin and Ethereum.\n    Put all executed tasks into a list and set it as a global variable in the context (It is needed so we can wait for these tasks at app shutdown)\n    \"\"\"\n    raise NotImplementedError()\n'''\n\nactual = _check_response_for_implementation(fixture)\nprint(actual)\nassert actual == [CODE_CONTAINS_IMPLEMENTATION_ERROR]\n</code></pre> <pre><code>['Error: The response contains code implementation. Rewrite the skeleton code without implementing the business logic for the functions. Ensure the new code has only google styled docstring describing the business logic step by step and raise NotImplementedError()']\n</code></pre> <pre><code>fixture = '''\nimport asyncio\nimport json\n\nimport aiohttp\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(\n        ..., examples=[50000.0], description=\"Current price of cryptocurrency in USD\"\n    )\n    crypto_currency: str = Field(\n        ..., examples=[\"BTC\"], description=\"The cryptocurrency symbol\"\n    )\n\n\nasync def fetch_crypto_price(\n    url: str, crypto_currency: str, logger: Logger, context: ContextRepo\n) -&gt; None:\n    \"\"\"\n    Fetches the current cryptocurrency price from the provided URL and publishes it to the 'new_crypto_price' topic.\n\n    Instructions:\n    1. Send a GET request to the provided URL.\n    2. Retrieve the current price and cryptocurrency symbol from the response JSON.\n    3. Create a CryptoPrice object with the retrieved data.\n    4. Publish the CryptoPrice object to the 'new_crypto_price' topic, using the crypto_currency as the partition key.\n    5. Sleep for 2 seconds.\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to True - we will use this variable as running loop condition\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_shutdown\nasync def shutdown(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to False\n\n    Get all executed tasks from context and wait them to finish\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.after_startup\nasync def fetch_crypto_prices(logger: Logger, context: ContextRepo):\n    \"\"\"\n    Create asynchronous tasks for executing fetch_crypto_price function.\n    Run this process for Bitcoin (BTC) and Ethereum (ETH).\n    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for these tasks at app shutdown)\n    \"\"\"\n    raise NotImplementedError()\n'''\n\nactual = _check_response_for_implementation(fixture)\nprint(actual)\nassert actual == []\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture = \"\"\"\nimport os\nimport invalid_module\ndef say_hello():\n    print(\"hello\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    actual = _validate_response(fixture, d)\n    expected = [\"ModuleNotFoundError: No module named 'invalid_module'\"]\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[\"ModuleNotFoundError: No module named 'invalid_module'\"]\n</code></pre> <pre><code>fixture = \"\"\"\nimport os\ndef say_hello():\n    print(\"hello\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    actual = _validate_response(fixture, d)\n    expected = [CODE_CONTAINS_IMPLEMENTATION_ERROR]\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>['Error: The response contains code implementation. Rewrite the skeleton code without implementing the business logic for the functions. Ensure the new code has only google styled docstring describing the business logic step by step and raise NotImplementedError()']\n</code></pre> <pre><code>fixture = '''\nimport os\ndef say_hello():\n    \"\"\"This is a docstring\"\"\"\n    raise NotImplementedError()\n'''\n\nwith TemporaryDirectory() as d:\n    actual = _validate_response(fixture, d)\n    expected = []\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture = '''\nimport asyncio\nimport json\n\nimport aiohttp\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(\n        ..., examples=[50000.0], description=\"Current price of cryptocurrency in USD\"\n    )\n    crypto_currency: str = Field(\n        ..., examples=[\"BTC\"], description=\"The cryptocurrency symbol\"\n    )\n\n\nasync def fetch_crypto_price(\n    url: str, crypto_currency: str, logger: Logger, context: ContextRepo\n) -&gt; None:\n    \"\"\"\n    Fetches the current cryptocurrency price from the provided URL and publishes it to the 'new_crypto_price' topic.\n\n    Instructions:\n    1. Send a GET request to the provided URL.\n    2. Retrieve the current price and cryptocurrency symbol from the response JSON.\n    3. Create a CryptoPrice object with the retrieved data.\n    4. Publish the CryptoPrice object to the 'new_crypto_price' topic, using the crypto_currency as the partition key.\n    5. Sleep for 2 seconds.\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to True - we will use this variable as running loop condition\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.on_shutdown\nasync def shutdown(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set app_is_running to False\n\n    Get all executed tasks from context and wait them to finish\n    \"\"\"\n    raise NotImplementedError()\n\n\n@app.after_startup\nasync def fetch_crypto_prices(logger: Logger, context: ContextRepo):\n    \"\"\"\n    Create asynchronous tasks for executing fetch_crypto_price function.\n    Run this process for Bitcoin (BTC) and Ethereum (ETH).\n    Put all executed tasks to list and set it as global variable in context (It is needed so we can wait for these tasks at app shutdown)\n    \"\"\"\n    raise NotImplementedError()\n'''\n\nwith TemporaryDirectory() as d:\n    actual = _validate_response(fixture, d)\n    expected = []\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture = '''\nimport asyncio\nimport json\n\nimport aiohttp\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(..., examples=[50000.0], description=\"Current price of cryptocurrency in USD\")\n    crypto_currency: str = Field(..., examples=[\"BTC\"], description=\"The cryptocurrency\")\n\n\nasync def fetch_crypto_price(url: str) -&gt; dict:\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as response:\n            return await response.json()\n\n\nasync def get_crypto_price(crypto_currency: str) -&gt; CryptoPrice:\n    url = f\"https://api.coinbase.com/v2/prices/{crypto_currency}-USD/spot\"\n    response = await fetch_crypto_price(url)\n    price = response[\"data\"][\"amount\"]\n    return CryptoPrice(price=price, crypto_currency=crypto_currency)\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    context.crypto_currencies = [\"BTC\", \"ETH\"]\n\n\n@app.on_shutdown\nasync def shutdown(context: ContextRepo):\n    context.app_is_running = False\n    await asyncio.gather(*context.tasks)\n\n\nasync def fetch_and_publish_crypto_price(\n    crypto_currency: str, logger: Logger, context: ContextRepo, interval: int = 2\n) -&gt; None:\n    while context.app_is_running:\n        crypto_price = await get_crypto_price(crypto_currency)\n        await broker.publish(\n            topic=\"new_crypto_price\",\n            key=crypto_currency.encode(\"utf-8\"),\n            value=crypto_price.json().encode(\"utf-8\"),\n        )\n        await asyncio.sleep(interval)\n\n\n@app.after_startup\nasync def publish_crypto_price(logger: Logger, context: ContextRepo):\n    context.tasks = []\n    for crypto_currency in context.crypto_currencies:\n        task = asyncio.create_task(\n            fetch_and_publish_crypto_price(crypto_currency, logger, context)\n        )\n        context.tasks.append(task)\n\n\nif __name__ == \"__main__\":\n    asyncio.run(app.run())\n'''\n\nwith TemporaryDirectory() as d:\n    actual = _validate_response(fixture, d)\n    expected = [CODE_CONTAINS_IMPLEMENTATION_ERROR]\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>['Error: The response contains code implementation. Rewrite the skeleton code without implementing the business logic for the functions. Ensure the new code has only google styled docstring describing the business logic step by step and raise NotImplementedError()']\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some valid prompt\"\napp_description_content = \"some valid app description\"\ntotal_usage = [defaultdict(int)]\n\n\ntest_response = \"\"\"\nprint(\"some valid skeleton code\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    with mock_openai_create(test_response):\n        total_usage, is_valid_skeleton_code = _generate(\n            model, prompt, app_description_content, total_usage, d\n        )\n        assert is_valid_skeleton_code == True\n        print(\"OK\")\n</code></pre> <pre><code>[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome valid prompt\n\n===Role:user===\n\nMessage:\nsome valid app description\n==== YOUR RESPONSE ====\n\nsome valid skeleton code\nOK\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some invalid prompt\"\napp_description_content = \"some invalid app description\"\ntotal_usage = [defaultdict(int)]\n\ntest_response = \"\"\"\nprint(\"some valid skeleton code\"\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    with mock_openai_create(test_response):\n        total_usage, is_valid_skeleton_code = _generate(\n            model, prompt, app_description_content, total_usage, d\n        )\n        print(is_valid_skeleton_code)\n        assert is_valid_skeleton_code == False\n        print(\"OK\")\n</code></pre> <pre><code>[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.helper: Attempt 0 failed. Restarting step.\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.helper: Attempt 1 failed. Restarting step.\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\nSome invalid prompt\n\n===Role:user===\n\nMessage:\nsome invalid app description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\n\nprint(\"some valid skeleton code\"\n\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: '(' was never closed (application.py, line 2)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: '(' was never closed (application.py, line 2)\n[INFO] faststream_gen._code_generator.helper: Attempt 2 failed. Restarting step.\nFalse\nOK\n</code></pre> <p>source</p>"},{"location":"App_Skeleton_Generator/#generate_app_skeleton","title":"generate_app_skeleton","text":"<pre><code> generate_app_skeleton (validated_description:str, output_directory:str,\n                        model:str, total_usage:List[Dict[str,int]],\n                        relevant_prompt_examples:str)\n</code></pre> <p>Generate skeleton code for the new FastStream app from the application description</p> <p>Args: code_gen_directory: The directory containing the generated files. total_usage: list of token usage. relevant_prompt_examples: Relevant examples to add in the prompts.</p> <p>Returns: The total token used to generate the FastStream code</p> <pre><code>fixture_description = \"Some valid description\"\n\nrelevant_prompt_examples = \"Some valid examples\"\n\nfixture_response = 'print(\"hi\")'\n\nwith mock_openai_create(fixture_response):\n    with TemporaryDirectory() as d:\n        output_file = Path(d) / APPLICATION_FILE_PATH\n\n        usage, is_valid_skeleton_code = generate_app_skeleton(\n            fixture_description, d, OpenAIModel.gpt3.value, [], relevant_prompt_examples\n        )\n\n        assert Path(output_file).exists()\n\n        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n            actual = f.read()\n\n        print(actual)\n        assert actual == fixture_response\n\n        assert is_valid_skeleton_code\n</code></pre> <pre><code>[INFO] __main__: ==== Description to Skeleton Generation ====\n\u280b Generating FastStream app skeleton code (usually takes around 15 to 45 seconds)...[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome valid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome valid description\n==== YOUR RESPONSE ====\n\nhi\n \u2714 FastStream app skeleton code generated.                                           \nprint(\"hi\")\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre> <pre><code>fixture_description = \"Some invalid description\"\n\nrelevant_prompt_examples = \"Some invalid examples\"\n\nfixture_response = 'i am a not a python code'\n\nwith mock_openai_create(fixture_response):\n    with TemporaryDirectory() as d:\n        output_file = Path(d) / APPLICATION_FILE_PATH\n        usage, is_valid_skeleton_code = generate_app_skeleton(\n            fixture_description, d, OpenAIModel.gpt3.value, [], relevant_prompt_examples\n        )\n        print(is_valid_skeleton_code)\n        assert not is_valid_skeleton_code\n</code></pre> <pre><code>[INFO] __main__: ==== Description to Skeleton Generation ====\n\u280b Generating FastStream app skeleton code (usually takes around 15 to 45 seconds)...[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.helper: Attempt 0 failed. Restarting step.\n\u2839 Generating FastStream app skeleton code (usually takes around 15 to 45 seconds)... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.helper: Attempt 1 failed. Restarting step.\n\u283c Generating FastStream app skeleton code (usually takes around 15 to 45 seconds)... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n[INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\n3. Whenever you are creating a message class while generating Faststream skeleton and the application code, make sure the message class is a derived class of BaseModel from pydantic.\n\n        Example of a Valid message class:\n            class Pet(BaseModel):\n                pet_id: NonNegativeInt = Field(..., examples=[1], description=\"Int data example\")\n                species: str = Field(..., examples=[\"dog\"], description=\"Pet example\")\n\n        Example of a invalid message class:\n            class Pet:\n                def __init__(self, pet_id: int, species: str):\n                    self.pet_id = pet_id\n                    self.species = species\n\n4. When generating a lists of external dependencies from both the ==== APP CODE ==== and ==== TEST CODE ==== sections, include only external libraries and not internal Python libraries like json, time, asyncio, etc., in the ==== APP REQUIREMENT ==== or ==== TEST REQUIREMENT ==== sections. Additionally do not include pytest in the ==== TEST REQUIREMENT ====\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\n\n\nGenerate skeleton code for FastStream applications based on provided app descriptions in the \"==== USER APP DESCRIPTION ====\" section, adhering to these guidelines:\n\n    - Avoid implementing business logic of ANY function. Instead, write \"raise NotImplementedError()\" and create Google-style docstrings to describe their intended functionality when handling received or produced messages. In each docstring, include a clear instruction to \"log the consumed message using logger.info\" for subscriber functions.\n\n    - Ensure the generated code aligns with the specific app description requirements.\n\n    - Provide a clear and organized starting point for developers.\n\n    - Your response must contain only valid Python code, saveable as a .py script; no additional text is allowed.\n\n    - DO NOT enclose the response within back-ticks. Meaning NEVER ADD ```python to your response.\n\n\nThe goal is to offer developers a structured starting point that matches the example app descriptions, aiding in FastStream application development. Follow the example patterns provided for reference.\n\n\n\nSome invalid examples\n\n\n==== USER APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nSome invalid description\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n\n\n===Role:user===\n\nMessage:\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\ni am a not a python code\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nSyntaxError: invalid syntax (application.py, line 1)\n==== YOUR RESPONSE ====\n\n\u2834 Generating FastStream app skeleton code (usually takes around 15 to 45 seconds)... [INFO] faststream_gen._code_generator.chat: Validation failed, trying again...Errors:\nSyntaxError: invalid syntax (application.py, line 1)\n[INFO] faststream_gen._code_generator.helper: Attempt 2 failed. Restarting step.\n \u2718 Error: Failed to generate a valid application skeleton code.                      \nFalse\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:228: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(value) if value else value\n</code></pre>"},{"location":"Benchmark_CLI/","title":"Benchmark CLI","text":"<pre><code>from typer.testing import CliRunner\n</code></pre> <p>source</p>"},{"location":"Benchmark_CLI/#benchmark","title":"benchmark","text":"<pre><code> benchmark (fixtures_path:str=&lt;typer.models.ArgumentInfo object at\n            0x7fa335392550&gt;, no_repeat:int=&lt;typer.models.OptionInfo object\n            at 0x7fa335392f10&gt;)\n</code></pre> <pre><code>runner = CliRunner()\nresult = runner.invoke(app, [\"benchmark\", \"--help\"])\n</code></pre> <pre>                                                                                                                   \n Usage: run_benchmark [OPTIONS] FIXTURES_PATH                                                                      \n                                                                                                                   \n</pre> <pre> Run benchmark against pre-defined example app descriptions                                                        \n                                                                                                                   \n</pre> <pre>\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 *    fixtures_path      TEXT  The path to the pre-defined example app descriptions [default: None] [required]   \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre>\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --repeat              -r      INTEGER  [default: 1]                                                             \u2502\n\u2502 --install-completion                   Install completion for the current shell.                                \u2502\n\u2502 --show-completion                      Show completion for the current shell, to copy it or customize the       \u2502\n\u2502                                        installation.                                                            \u2502\n\u2502 --help                                 Show this message and exit.                                              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre><code>fixture = \"\"\"\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_description = Path(d) / \"hello_world.txt\"\n    with app_description.open(\"w\", encoding=\"utf-8\") as f:\n        f.write(fixture)\n\n    result = runner.invoke(app, [d])\n\n    benchkark_dir = Path(d) / BENCHMARK_RESULTS_DIR\n    assert benchkark_dir.exists()\n\n    files = [f for f in benchkark_dir.rglob(\"*.py\")]\n    print(files)\n\n    file_names = [f.stem for f in files]\n    assert \"test_application\" in file_names\n    assert \"application\" in file_names\n</code></pre> <pre><code>[PosixPath('/tmp/tmp38j6f9uc/benchmark-results/hello_world/tests/__init__.py'), PosixPath('/tmp/tmp38j6f9uc/benchmark-results/hello_world/tests/test_application.py'), PosixPath('/tmp/tmp38j6f9uc/benchmark-results/hello_world/app/application.py')]\n</code></pre>"},{"location":"CHANGELOG/","title":"Release notes","text":""},{"location":"CHANGELOG/#017","title":"0.1.7","text":""},{"location":"CHANGELOG/#bugs-squashed","title":"Bugs Squashed","text":"<ul> <li>Ensure that the skeleton code generation does not include function implementations (#176), thanks to @harishmohanraj</li> <li>Closes #175</li> </ul>"},{"location":"CHANGELOG/#016","title":"0.1.6","text":""},{"location":"CHANGELOG/#bugs-squashed_1","title":"Bugs Squashed","text":"<ul> <li>Prompt fixes and updates (#155), thanks to @harishmohanraj</li> </ul>"},{"location":"CHANGELOG/#015","title":"0.1.5","text":""},{"location":"CHANGELOG/#new-features","title":"New Features","text":"<ul> <li>Change the permission of the generated script files (#151), thanks to @harishmohanraj</li> </ul>"},{"location":"CHANGELOG/#bugs-squashed_2","title":"Bugs Squashed","text":"<ul> <li>Prompt fixes and updates (#151), thanks to @harishmohanraj</li> </ul>"},{"location":"CHANGELOG/#014","title":"0.1.4","text":""},{"location":"CHANGELOG/#new-features_1","title":"New Features","text":"<ul> <li>Create a benchmark for measuring success rate of code generation (#135), thanks to @harishmohanraj</li> <li> <p>Closes #88</p> </li> <li> <p>Save generated files on exceptions during code generation (#132), thanks to @harishmohanraj</p> </li> <li>Closes #131</li> </ul>"},{"location":"CHANGELOG/#013","title":"0.1.3","text":""},{"location":"CHANGELOG/#new-features_2","title":"New Features","text":"<ul> <li>Update FastStream version, thanks to @harishmohanraj</li> <li>Update Tutorial documentation (#124), thanks to @rjambrecic</li> </ul>"},{"location":"CHANGELOG/#012","title":"0.1.2","text":""},{"location":"CHANGELOG/#new-features_3","title":"New Features","text":"<ul> <li>Update FastStream version, thanks to @harishmohanraj</li> </ul>"},{"location":"CHANGELOG/#011","title":"0.1.1","text":""},{"location":"CHANGELOG/#new-features_4","title":"New Features","text":"<ul> <li>Update FastStream version, thanks to @harishmohanraj</li> </ul>"},{"location":"CHANGELOG/#010","title":"0.1.0","text":""},{"location":"CHANGELOG/#new-features_5","title":"New Features","text":"<ul> <li>Initial release (#121), thanks to @harishmohanraj</li> </ul>"},{"location":"CLI/","title":"CLI","text":"<pre><code>from typer.testing import CliRunner\nfrom tempfile import TemporaryDirectory\n\nimport pytest\n\nfrom faststream_gen._components.logger import suppress_timestamps\nfrom faststream_gen._code_generator.helper import mock_openai_create\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=20)\nlogger.info(\"ok\")\n</code></pre> <pre><code>[INFO] __main__: ok\n</code></pre> <pre><code>runner = CliRunner()\n</code></pre> <pre><code>usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n\nusage_list = [usage, usage]\ntotal_tokens_usage = add_tokens_usage(usage_list)\n\nactual = _calculate_price(total_tokens_usage, \"gpt-4\")\nexpected = 0.007859999999999999\n\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>0.007859999999999999\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    input_path = f\"{d}/app_description.txt\"\n    description = \"\"\"Create a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use default port number.\n\nIt should consume from 'store_product' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. 'EUR'.\nFor each consumed message, check if the currency attribute is set to 'HRK'. If it is then change the currency to 'EUR' and divide the price by 7.5, if the currency is not set to 'HRK' don't change the original message. Finally, publish the consumed message to 'change_currency' topic.\n\nUse SASL_SSL with SCRAM-SHA-256 for authentication with username and password.\"\"\"\n\n\n    write_file_contents(input_path, description)\n    actual = _get_description(input_path)\n    display(actual)\n    expected = \"Create a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use default port number.\\n\\r\\n\\rIt should consume from 'store_product' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. 'EUR'.\\n\\rFor each consumed message, check if the currency attribute is set to 'HRK'. If it is then change the currency to 'EUR' and divide the price by 7.5, if the currency is not set to 'HRK' don't change the original message. Finally, publish the consumed message to 'change_currency' topic.\\n\\r\\n\\rUse SASL_SSL with SCRAM-SHA-256 for authentication with username and password.\"         \n\n    assert actual == expected, actual\n</code></pre> <pre><code>[INFO] __main__: Reading application description from '/tmp/tmp_3ppo83e/app_description.txt'.\n\n\"Create a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use default port number.\\n\\r\\n\\rIt should consume from 'store_product' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. 'EUR'.\\n\\rFor each consumed message, check if the currency attribute is set to 'HRK'. If it is then change the currency to 'EUR' and divide the price by 7.5, if the currency is not set to 'HRK' don't change the original message. Finally, publish the consumed message to 'change_currency' topic.\\n\\r\\n\\rUse SASL_SSL with SCRAM-SHA-256 for authentication with username and password.\"\n</code></pre> <pre><code>with pytest.raises(ValueError) as e:\n        _get_description(\"incorrect_path\")\n\nprint(e.value)\nassert str(e.value) == f\"Error while reading from the file: '{str(Path('incorrect_path').absolute())}'\\n[Errno 2] No such file or directory: 'incorrect_path'\"\n</code></pre> <pre><code>Error while reading from the file: '/work/fastkafka-gen/nbs/incorrect_path'\n[Errno 2] No such file or directory: 'incorrect_path'\n</code></pre> <pre><code>with pytest.raises(ValueError) as e:\n    _validate_app_description(None, None, OpenAIModel.gpt3, [])\n</code></pre> <pre><code>test_response = \"3\"\n\nwith mock_openai_create(test_response):\n    validated_description, tokens_list = _validate_app_description(\"some valid description\", None, OpenAIModel.gpt3, [])\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n[INFO] faststream_gen._code_generator.app_description_validator: ==== App description validation ====\n\u280b Validating the application description...[INFO] faiss.loader: Loading faiss with AVX2 support.\n[INFO] faiss.loader: Successfully loaded faiss with AVX2 support.\n\u2819 Validating the application description... \u2826 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\nsome valid description\n==== YOUR RESPONSE ====\n\n \u2714 Application description validated.\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre> <pre><code>test_response = \"3\"\n\nwith TemporaryDirectory() as d:\n    input_path = Path(d)/\"input.txt\"\n    with open(input_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"app description\")\n\n    with mock_openai_create(test_response):\n        validated_description, tokens_list = _validate_app_description(None, str(input_path), OpenAIModel.gpt3, [])\n</code></pre> <pre><code>[INFO] __main__: Reading application description from '/tmp/tmpguglgo12/input.txt'.\n\u2728  Generating a new FastStream application!\n[INFO] faststream_gen._code_generator.app_description_validator: ==== App description validation ====\n\u2838 Validating the application description... [INFO] faststream_gen._code_generator.chat:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both packages and created the unified way to write services capable of processing streamed data regradless of the underliying protocol. We'll continue to maintain both packages, but new development will be in this project. If you are starting a new service, this package is the recommended way to do it.\n\nFeatures\n\nFastStream simplifies the process of writing producers and consumers for message queues, handling all the\nparsing, networking and documentation generation automatically.\n\nMaking streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use-cases. Here's a look at the core features that make FastStream a go-to framework for modern, data-centric microservices.\n\nMultiple Brokers: FastStream provides a unified API to work across multiple message brokers (Kafka, RabbitMQ support)\n\nPydantic Validation: Leverage Pydantic's validation capabilities to serialize and validates incoming messages\n\nAutomatic Docs: Stay ahead with automatic AsyncAPI documentation.\n\nIntuitive: full typed editor support makes your development experience smooth, catching errors before they reach runtime\n\nPowerful Dependency Injection System: Manage your service dependencies efficiently with FastStream's built-in DI system.\n\nTestable: supports in-memory tests, making your CI/CD pipeline faster and more reliable\n\nExtendable: use extensions for lifespans, custom serialization and middlewares\n\nIntegrations: FastStream is fully compatible with any HTTP framework you want (FastAPI especially)\n\nBuilt for Automatic Code Generation: FastStream is optimized for automatic code generation using advanced models like GPT and Llama\n\nThat's FastStream in a nutshell\u2014easy, efficient, and powerful. Whether you're just starting with streaming microservices or looking to scale, FastStream has got you covered.\n\n===Role:user===\n\nMessage:\n\nYou should provide a response of 0, 1, 2, or 3, and nothing else, based on the following rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastStream or contains violence, self-harm, harassment/threatening, or hate/threatening information, respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream but primarily provides general information about FastStream and what it is, respond with 1.\n\nIf it is NOT possible to infer the topic name or there is no explanation about the business logic in the ==== APP DESCRIPTION: ==== section, respond with 2. This is crucial.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastStream, provides instructions on which topic the messages should be consumed/produced, and includes at least one defined topic, respond with 3.\n\nHere are few examples for your understanding:\n\n\n==== EXAMPLE APP DESCRIPTION ====\nGenerate a new FastStream app, which has a producer function and a consumer function \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nIn App description 1, the user has not defined the message structure or the topic name to publish/subscribe. As a result, you should respond with 2. \n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nCreate a FastStream application.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\ncreate FastStream app where message has user_data attribute.\n==== YOUR RESPONSE ====\n2\n\n==== EXAMPLE APP DESCRIPTION ====\nFastStream app with for consuming messages from the hello topic\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWrite a FastStream application with with one consumer function and two producer functions. The consumer function should receive the a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker==== Response 5 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nDevelop a new FastStream application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.==== Response 6 ====\n==== YOUR RESPONSE ====\n3\n\n==== EXAMPLE APP DESCRIPTION ====\nWho are you\n==== YOUR RESPONSE ====\n0\n\n==== EXAMPLE APP DESCRIPTION ====\nWhat is the latest vesion of FastStream\n==== YOUR RESPONSE ====\n1\n\nPlease respond only with numbers 0, 1, 2 or 3 (WITH NO ADDITIONAL TEXT!)\n\n==== APP DESCRIPTION: ====\n\n\n\n===Role:user===\n\nMessage:\napp description\n==== YOUR RESPONSE ====\n\n \u2714 Application description validated.\n</code></pre> <p>source</p>"},{"location":"CLI/#generate_fastkafka_app","title":"generate_fastkafka_app","text":"<pre><code> generate_fastkafka_app\n                         (description:Optional[str]=&lt;typer.models.Argument\n                         Info object at 0x7f8c85eea0a0&gt;,\n                         input_path:str=&lt;typer.models.OptionInfo object at\n                         0x7f8c85eeaf70&gt;,\n                         output_path:str=&lt;typer.models.OptionInfo object\n                         at 0x7f8c85eeaee0&gt;, model:faststream_gen._code_ge\n                         nerator.constants.OpenAIModel=&lt;typer.models.Optio\n                         nInfo object at 0x7f8c85eeaa00&gt;,\n                         verbose:bool=&lt;typer.models.OptionInfo object at\n                         0x7f8c85eea460&gt;,\n                         save_log_files:bool=&lt;typer.models.OptionInfo\n                         object at 0x7f8c85eeabe0&gt;)\n</code></pre> <p>Effortlessly create a new FastStream project based on the app description.</p> <pre><code>result = runner.invoke(app, [\"generate\", \"--help\"])\n</code></pre> <pre>                                                                                                                   \n Usage: generate [OPTIONS] [DESCRIPTION]                                                                           \n                                                                                                                   \n</pre> <pre> Effortlessly create a new FastStream project based on the app description.                                        \n                                                                                                                   \n</pre> <pre>\u256d\u2500 Arguments \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502   description      [DESCRIPTION]  Summarize your FastStream application in a few sentences!                     \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                   Include details about messages, topics, servers, and a brief overview of the  \u2502\n\u2502                                   intended business logic.                                                      \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                   The simpler and more specific the app description is, the better the          \u2502\n\u2502                                   generated app will be. Please refer to the below example for inspiration:     \u2502\n\u2502                                                                                                                 \u2502\n\u2502                                   Create a FastStream application using localhost broker for testing and use    \u2502\n\u2502                                   the default port number.  It should consume messages from the \"input_data\"    \u2502\n\u2502                                   topic, where each message is a JSON encoded object containing a single        \u2502\n\u2502                                   attribute: 'data'.  For each consumed message, create a new message object    \u2502\n\u2502                                   and increment the value of the data attribute by 1. Finally, send the         \u2502\n\u2502                                   modified message to the 'output_data' topic.                                  \u2502\n\u2502                                   [default: None]                                                               \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre>\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --input_file          -i      TEXT                       The path to the file with the app desription. This     \u2502\n\u2502                                                          path should be relative to the current working         \u2502\n\u2502                                                          directory.                                             \u2502\n\u2502                                                          If the app description is passed via both a            \u2502\n\u2502                                                          --input_file and a command line argument, the          \u2502\n\u2502                                                          description from the command line will be used to      \u2502\n\u2502                                                          create the application.                                \u2502\n\u2502                                                          [default: None]                                        \u2502\n\u2502 --output_path         -o      TEXT                       The path to the output directory where the generated   \u2502\n\u2502                                                          project files will be saved. This path should be       \u2502\n\u2502                                                          relative to the current working directory.             \u2502\n\u2502                                                          [default: .]                                           \u2502\n\u2502 --model               -m      [gpt-3.5-turbo-16k|gpt-4]  The OpenAI model that will be used to create the       \u2502\n\u2502                                                          FastStream project. For better results, we recommend   \u2502\n\u2502                                                          using 'gpt-4'.                                         \u2502\n\u2502                                                          [default: gpt-3.5-turbo-16k]                           \u2502\n\u2502 --verbose             -v                                 Enable verbose logging by setting the logger level to  \u2502\n\u2502                                                          INFO.                                                  \u2502\n\u2502 --dev                 -d                                 Save the complete logs generated by faststream-gen     \u2502\n\u2502                                                          inside the output_path directory.                      \u2502\n\u2502 --install-completion                                     Install completion for the current shell.              \u2502\n\u2502 --show-completion                                        Show completion for the current shell, to copy it or   \u2502\n\u2502                                                          customize the installation.                            \u2502\n\u2502 --help                                                   Show this message and exit.                            \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre>"},{"location":"Chat/","title":"Chat","text":"<pre><code>from tempfile import TemporaryDirectory\n\nimport pytest\n\nfrom faststream_gen._components.logger import suppress_timestamps\nfrom faststream_gen._code_generator.constants import OpenAIModel\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=20)\nlogger.info(\"ok\")\n</code></pre> <pre><code>[INFO] __main__: ok\n</code></pre> <pre><code>@_retry_with_exponential_backoff()\ndef mock_func():\n    return \"Success\"\n\nactual = mock_func()\nexpected = \"Success\"\n\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>Success\n</code></pre> <pre><code># Test max retries exceeded\n@_retry_with_exponential_backoff(max_retries=1)\ndef mock_func_error():\n    raise openai.error.RateLimitError\n\n\nwith pytest.raises(Exception) as e:\n    mock_func_error()\n\nprint(e.value)\nassert str(e.value) == \"Maximum number of retries (1) exceeded.\"\n</code></pre> <pre><code>[INFO] __main__: Note: OpenAI's API rate limit reached. Command will automatically retry in 2 seconds. For more information visit: https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits\nMaximum number of retries (1) exceeded.\n</code></pre> <pre><code>query = \"What is FastStream?\"\nactual = _get_relevant_document(query)\nprint(actual[:200])\nassert len(actual) &gt; 0\n</code></pre> <pre><code>[INFO] faiss.loader: Loading faiss with AVX2 support.\n[INFO] faiss.loader: Successfully loaded faiss with AVX2 support.\nhide:\n  - navigation\n  - footer\n\nRelease Notes\n\nFastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both\n</code></pre> <p>source</p>"},{"location":"Chat/#customaichat","title":"CustomAIChat","text":"<pre><code> CustomAIChat (model:str, user_prompt:Optional[str]=None,\n               params:Dict[str,float]={'temperature': 0.7},\n               semantic_search_query:Optional[str]=None)\n</code></pre> <p>Custom class for interacting with OpenAI</p> <p>Attributes: model: The OpenAI model to use. If not passed, defaults to gpt-3.5-turbo-16k. system_prompt: Initial system prompt to the AI model. If not passed, defaults to SYSTEM_PROMPT. initial_user_prompt: Initial user prompt to the AI model. params: Parameters to use while initiating the OpenAI chat model. DEFAULT_PARAMS used if not provided.</p> <pre><code>TEST_INITIAL_USER_PROMPT = \"\"\"\nYou should respond with 0, 1 or 2 and nothing else. Below are your rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastKafka or contains violence, self-harm, harassment/threatening or hate/threatening information then you should respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses on what is it and its general information then you should respond with 1. \n\nIf the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses how to use it and instructions to create a new app then you should respond with 2. \n\"\"\"\n\nai = CustomAIChat(user_prompt = TEST_INITIAL_USER_PROMPT, model=OpenAIModel.gpt3.value)\nresponse, usage = ai(\"Name the tallest mountain in the world\")\n\nprint(response)\nprint(usage)\n\nassert response == \"0\"\n</code></pre> <pre><code>[INFO] __main__:\n\nPrompt to the model:\n\n===Role:system===\n\nMessage:\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n===Role:user===\n\nMessage:\n\n\n===Role:user===\n\nMessage:\n\nYou should respond with 0, 1 or 2 and nothing else. Below are your rules:\n\n==== RULES: ====\n\nIf the ==== APP DESCRIPTION: ==== section is not related to FastKafka or contains violence, self-harm, harassment/threatening or hate/threatening information then you should respond with 0.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses on what is it and its general information then you should respond with 1.\n\nIf the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses how to use it and instructions to create a new app then you should respond with 2.\n\n\n===Role:user===\n\nMessage:\nName the tallest mountain in the world\n==== YOUR RESPONSE ====\n\n0\n{\n  \"prompt_tokens\": 348,\n  \"completion_tokens\": 1,\n  \"total_tokens\": 349\n}\n</code></pre> <p>source</p>"},{"location":"Chat/#validateandfixresponse","title":"ValidateAndFixResponse","text":"<pre><code> ValidateAndFixResponse (generate:Callable[...,Any],\n                         validate:Callable[...,Any],\n                         max_retries:Optional[int]=3)\n</code></pre> <p>Generates and validates response from OpenAI</p> <p>Attributes: generate: A callable object for generating responses. validate: A callable object for validating responses. max_retries: An optional integer specifying the maximum number of attempts to generate and validate a response.</p> <pre><code>with TemporaryDirectory() as d:\n    messages = [{\"role\": \"role\", \"content\": \"content\"}]\n    kwargs = {\"attempt\": 2}\n    for step_name in [\"app\", \"test\"]:\n        _save_log_results(step_name, d, messages, \"response\", \"error_str\", 0, **kwargs)\n\n        step_dir = Path(d) / step_name\n        assert step_dir.exists()\n\n        attempt_dir = step_dir / \"attempt_3\"\n        assert attempt_dir.exists()\n\n        try_dir = attempt_dir / \"try_1\"\n        assert try_dir.exists()\n\n        print(list(Path(try_dir).glob('**/*')))\n        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"input.txt\").exists()\n        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"output.txt\").exists()\n        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"errors.txt\").exists()\n</code></pre> <pre><code>[PosixPath('/tmp/tmp5k9i2c84/app/attempt_3/try_1/errors.txt'), PosixPath('/tmp/tmp5k9i2c84/app/attempt_3/try_1/output.txt'), PosixPath('/tmp/tmp5k9i2c84/app/attempt_3/try_1/input.txt')]\n[PosixPath('/tmp/tmp5k9i2c84/test/attempt_3/try_1/errors.txt'), PosixPath('/tmp/tmp5k9i2c84/test/attempt_3/try_1/output.txt'), PosixPath('/tmp/tmp5k9i2c84/test/attempt_3/try_1/input.txt')]\n</code></pre> <pre><code>response = \"some response\"\nerrors = \"\"\"error 1\nerror 2\nerror 3\n\"\"\"\n\nexpected = \"\"\"\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\nsome response\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nerror 1\nerror 2\nerror 3\n\"\"\"\nactual = _construct_prompt_with_error_msg(response, errors)\nprint(actual)\n\nassert actual == expected\n</code></pre> <pre><code>==== YOUR RESPONSE (WITH ISSUES) ====\n\nsome response\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nerror 1\nerror 2\nerror 3\n</code></pre> <p>source</p>"},{"location":"Chat/#validateandfixresponsefix","title":"ValidateAndFixResponse.fix","text":"<pre><code> ValidateAndFixResponse.fix (prompt:str, total_usage:List[Dict[str,int]],\n                             step_name:str, output_directory:str,\n                             **kwargs:Dict[str,Any])\n</code></pre> <p>Fix the response from OpenAI until no errors remain or maximum number of attempts is reached.</p> <p>Args: prompt: The initial prompt string. kwargs: Additional keyword arguments to be passed to the validation function.</p> <p>Returns: str: The generated response that has passed the validation.</p> <p>Raises: ValueError: If the maximum number of attempts is exceeded and the response has not successfully passed the validation.</p> <pre><code>fixture_initial_prompt = \"some valid prompt\"\nexpected = \"some valid prompt\"\nmax_retries = 3\n\n\nclass FixtureGenerate:\n    def __init__(self, user_prompt):\n        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n\n    def __call__(self, prompt):\n        self.messages.append({\"role\": \"user\", \"content\": prompt})\n        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n        return fixture_initial_prompt, usage\n\ndef fixture_validate(response, output_directory, attempt):\n        return ([], response)\n\nwith TemporaryDirectory() as d:\n    kwargs = {\"attempt\": 0}\n    fixture_generate = FixtureGenerate(fixture_initial_prompt)\n    v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n    actual = v.fix(fixture_initial_prompt, [], STEP_LOG_DIR_NAMES[\"app\"], d, **kwargs)\n    print(actual)\n\n    assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\").exists()\n    assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"input.txt\").exists()\n    assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"output.txt\").exists()\n    assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"errors.txt\").exists()\n\n    with open((Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n        print(f.read())\n</code></pre> <pre><code>[defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 129, 'completion_tokens': 1, 'total_tokens': 130})]\n====system====\n\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n\n====user====\n\nsome valid prompt\n</code></pre> <pre><code>fixture_initial_prompt = \"some invalid prompt\"\nmax_retries = 3\n\n\nclass FixtureGenerate:\n    def __init__(self, user_prompt):\n        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n\n    def __call__(self, prompt):\n        self.messages.append({\"role\": \"user\", \"content\": prompt})\n        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n        return fixture_initial_prompt, usage\n\n\nfixture_generate = FixtureGenerate(fixture_initial_prompt)\n\nwith TemporaryDirectory() as d:\n    def fixture_validate(response, output_path, attempt):\n        return ([\"error 1\", \"error 2\"], response)\n\n    with pytest.raises(ValueError) as e:\n        kwargs = {\"attempt\": 0}\n        v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n        actual = v.fix(fixture_initial_prompt, [], STEP_LOG_DIR_NAMES[\"app\"], d, **kwargs)\n\n    print(f\"{e.value=}\")\n    assert not e.value.args[1]\n\n    for i in range(3):\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"input.txt\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"output.txt\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"errors.txt\").exists()\n\n    with open((Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_2\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n        print(f.read())\n</code></pre> <pre><code>[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\n[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\n[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\ne.value=ValueError([defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390})], False)\n====system====\n\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n\n====user====\n\nsome invalid prompt\n\n\n====user====\n\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\nsome invalid prompt\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nerror 1\nerror 2\n</code></pre> <pre><code>fixture_initial_prompt = \"some invalid prompt\"\nmax_retries = 3\n\n\nclass FixtureGenerate:\n    def __init__(self, user_prompt):\n        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n\n    def __call__(self, prompt):\n        self.messages.append({\"role\": \"user\", \"content\": prompt})\n        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n        return fixture_initial_prompt, usage\n\n\nfixture_generate = FixtureGenerate(fixture_initial_prompt)\n\nwith TemporaryDirectory() as d:\n    def fixture_validate(response, output_path, attempt):\n        return [\"error 1\", \"error 2\"]\n\n    with pytest.raises(ValueError) as e:\n        kwargs = {\"attempt\": 0}\n        v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n        actual = v.fix(fixture_initial_prompt, [], STEP_LOG_DIR_NAMES[\"skeleton\"], d, **kwargs)\n\n    print(e.value)\n    assert not e.value.args[1]\n\n    for i in range(3):\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"input.txt\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"output.txt\").exists()\n        assert (Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"errors.txt\").exists()\n\n    with open((Path(d) / LOGS_DIR_NAME / STEP_LOG_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_2\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n        print(f.read())\n</code></pre> <pre><code>[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\n[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\n[INFO] __main__: Validation failed, trying again...Errors:\nerror 1\nerror 2\n([defaultdict(&lt;class 'int'&gt;, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390})], False)\n====system====\n\n\nYou are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework.\n\nYou are to abide by the following guidelines:\n\n1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n\n2. Some prompts might require you to generate code that contains async functions. For example:\n\nasync def app_setup(context: ContextRepo):\n    raise NotImplementedError()\n\nIn such cases, it is necessary to add the \"import asyncio\" statement at the top of the code.\n\nYou will encounter sections marked as:\n\n==== APP DESCRIPTION: ====\n\nThese sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n\n\n\n====user====\n\nsome invalid prompt\n\n\n====user====\n\n\n\n==== YOUR RESPONSE (WITH ISSUES) ====\n\nsome invalid prompt\n\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n\nerror 1\nerror 2\n</code></pre>"},{"location":"Constants/","title":"Code generation constants","text":""},{"location":"Constants/#model-constants","title":"Model constants","text":"<p>source</p>"},{"location":"Constants/#openaimodel","title":"OpenAIModel","text":"<pre><code> OpenAIModel (value, names=None, module=None, qualname=None, type=None,\n              start=1)\n</code></pre> <p>An enumeration.</p> <pre><code>actual = OpenAIModel.gpt4.value\nprint(actual)\nassert actual == \"gpt-4\"\n</code></pre> <pre><code>gpt-4\n</code></pre>"},{"location":"Constants/#pricing","title":"Pricing","text":""},{"location":"Constants/#error-responses","title":"Error responses","text":""},{"location":"Constants/#fastkafka-docs-archive-url","title":"FastKafka docs archive url","text":""},{"location":"Constants/#faststream-template-archive-url","title":"FastStream template archive url","text":""},{"location":"Embeddings_CLI/","title":"Embeddings CLI","text":"<pre><code>import pytest\n\nfrom typer.testing import CliRunner\n</code></pre> <pre><code>fixture_description = \"\"\"\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    input_path = Path(d) / \"input_path\"\n    input_path.mkdir(parents=True, exist_ok=True)\n    output_path = Path(d) / \"output_path\"\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    api_path = Path(d) / \"input_path\" / \"api\"\n    api_path.mkdir(parents=True, exist_ok=True)\n\n    a_guide_path = Path(d) / \"input_path\" / \"a_guide_path\"\n    a_guide_path.mkdir(parents=True, exist_ok=True)\n\n    with open(f\"{a_guide_path}/a_guide_path.md\", \"w\") as f:\n        f.write(fixture_description)\n\n    with open(f\"{api_path}/api.md\", \"w\") as f:\n        f.write(fixture_description)\n\n    with open(f\"{input_path}/sample.md\", \"w\") as f:\n        f.write(fixture_description)\n\n    with open(f\"{input_path}/sample.txt\", \"w\") as f:\n        f.write(fixture_description)\n\n    docs = _create_documents(input_path)\n\n    print(len(docs))\n    assert len(docs) == 2\n    assert isinstance(docs[0], Document)\n\n    print(docs[0].page_content[:200])\n</code></pre> <pre><code>Below files are included in the embeddings:\n    - sample.md\n    - a_guide_path/a_guide_path.md\n2\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object\n</code></pre> <pre><code>doc_chunks = _split_document_into_chunks(docs, \"\\n\\n\")\nprint(len(doc_chunks))\nassert len(doc_chunks) &gt;= len(docs)\n</code></pre> <pre><code>2\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    db_path = Path(d) /\"faiss_index\"\n    _save_embeddings_db(docs, db_path)\n\n    !ls -la {d}\n    assert (Path(d) / \"faiss_index\" / \"index.faiss\").exists()\n</code></pre> <pre><code>total 12\ndrwx------ 3 harish harish 4096 Oct 10 08:17 .\ndrwxrwxrwt 1 root   root   4096 Oct 10 08:17 ..\ndrwxrwxr-x 2 harish harish 4096 Oct 10 08:17 faiss_index\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    some_dir = Path(f\"{d}/some_dir\")\n    some_dir.mkdir()\n    assert some_dir.exists()\n    !ls -la {d}\n\n    _delete_directory(str(some_dir))\n    assert not some_dir.exists()\n\n    non_existing_dir = Path(f\"{d}/non_existing_dir\")\n    _delete_directory(str(non_existing_dir))\n    !ls -la {d}\n</code></pre> <pre><code>total 12\ndrwx------ 3 harish harish 4096 Oct 10 08:17 .\ndrwxrwxrwt 1 root   root   4096 Oct 10 08:17 ..\ndrwxrwxr-x 2 harish harish 4096 Oct 10 08:17 some_dir\ntotal 8\ndrwx------ 2 harish harish 4096 Oct 10 08:17 .\ndrwxrwxrwt 1 root   root   4096 Oct 10 08:17 ..\n</code></pre> <pre><code>fixture = \"\"\"\ndef expand_markdown(input_markdown_path, output_markdown_path):\n    pass\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    docs_dir = Path(d) / \"docs\" / \"docs\" / \"en\"\n    docs_dir.mkdir(parents=True, exist_ok=True)\n\n    fixture_md_file = docs_dir / \"sample.md\"\n\n    with open(fixture_md_file, \"w\") as f:\n        f.write(\"# Hello\")\n\n    fixture_expand_markdown_file = Path(d) / \"docs\" / \"expand_markdown.py\"\n    with open(fixture_expand_markdown_file, \"w\") as f:\n        f.write(fixture)\n\n    _expand_faststream_docs(Path(d))\n    assert (Path(d) / FASTSTREAM_DOCS_DIR_SUFFIX).exists()\n\n    !ls -la {d}/{FASTSTREAM_DOCS_DIR_SUFFIX}\n    assert (Path(d) / FASTSTREAM_DOCS_DIR_SUFFIX/ \"sample.md\").exists()\n</code></pre> <pre><code>total 12\ndrwxrwxr-x 2 harish harish 4096 Oct 10 08:17 .\ndrwx------ 4 harish harish 4096 Oct 10 08:17 ..\n-rw-rw-r-- 1 harish harish    7 Oct 10 08:17 sample.md\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    root_dir = Path(d) / \"faststream-main\"\n    root_dir.mkdir(parents=True, exist_ok=True)\n\n    docs_dir = root_dir / \"docs\" / \"docs\" / \"en\"\n    docs_dir.mkdir(parents=True, exist_ok=True)\n\n    with open(f\"{docs_dir}/sample.md\", \"w\") as f:\n        f.write(\"# Hello\")\n\n    fixture_expand_markdown_file = root_dir / \"docs\" / \"expand_markdown.py\"\n    with open(fixture_expand_markdown_file, \"w\") as f:\n        f.write(fixture)\n\n    output_path = root_dir / \"output_path\"\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    _generate_docs_db(Path(d), output_path)\n\n    assert (output_path / \"index.faiss\").exists()\n</code></pre> <pre><code>\u280b Creating embeddings for the docs...\nBelow files are included in the embeddings:\n    - sample.md\n\u2839 Creating embeddings for the docs...  \u2714 Docs embeddings created and saved to: /tmp/tmpwjfc8_fo/faststream-main/output_path\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    required_files = ['description.txt', 'app_skeleton.py']\n\n    with open(f\"{d}/description.txt\", \"w\") as f:\n        f.write(\"description.txt\")\n\n    with open(f\"{d}/app_skeleton.py\", \"w\") as f:\n        f.write(\"app_skeleton.py\")\n\n\n    actual = _check_all_files_exist(Path(d), required_files)\n    print(actual)\n    assert actual\n</code></pre> <pre><code>True\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n\n    with open(f\"{d}/description.txt\", \"w\") as f:\n        f.write(\"description.txt\")\n\n    with open(f\"{d}/app_skeleton.py\", \"w\") as f:\n        f.write(\"app_skeleton.py\")\n\n\n    actual = _check_all_files_exist(Path(d), required_files)\n    print(actual)\n    assert not actual\n</code></pre> <pre><code>False\n</code></pre> <pre><code>fixture_description = \"\"\"\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\"\"\"\n\ndef _create_example_structure(directory: Path, required_files: List[str]):\n    for file_name in required_files:\n        if file_name == \"description.txt\":\n            with open(directory / file_name, \"w\") as f:\n                f.write(fixture_description)\n        else:\n            with open(directory / file_name, \"w\") as f:\n                f.write(file_name)\n\nwith TemporaryDirectory() as d:\n    required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n\n    example_1 = Path(d) / \"example_1\"\n    example_1.mkdir(parents=True, exist_ok=True)\n\n    _create_example_structure(example_1, required_files)\n\n    for directory in Path(d).iterdir():\n        _append_file_contents(directory, Path(d), required_files)\n\n    with open(f\"{d}/{FASTSTREAM_TMP_DIR_PREFIX}/example_1.txt\", \"r\") as f:\n        actual = f.read()\n\n    print(actual)\n    expected = f\"\"\"==== description.txt starts ====\n{fixture_description}\n==== description.txt ends ====\n==== app_skeleton.py starts ====\napp_skeleton.py\n==== app_skeleton.py ends ====\n==== app.py starts ====\napp.py\n==== app.py ends ====\n==== test_app.py starts ====\ntest_app.py\n==== test_app.py ends ====\n\"\"\"\n\n    assert actual == expected\n</code></pre> <pre><code>==== description.txt starts ====\n\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\n==== description.txt ends ====\n==== app_skeleton.py starts ====\napp_skeleton.py\n==== app_skeleton.py ends ====\n==== app.py starts ====\napp.py\n==== app.py ends ====\n==== test_app.py starts ====\ntest_app.py\n==== test_app.py ends ====\n</code></pre> <pre><code>required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n\nwith TemporaryDirectory() as d:\n    example_1 = Path(d) / \"example_1\"\n    example_1.mkdir(parents=True, exist_ok=True)\n    _create_example_structure(example_1, required_files)\n\n    output_path = Path(d) / \"output_path\"\n    output_path.mkdir(parents=True, exist_ok=True)\n\n    _generate_examples_db(Path(d), output_path)\n\n    assert (output_path / \"index.faiss\").exists()\n</code></pre> <pre><code>\u280b Creating embeddings for the examples...\nRequired files are missing. Skipping directory: /tmp/tmprbobxbd0/output_path\n\nBelow files are included in the embeddings:\n    - example_1.txt\n \u2714 Examples embeddings created and saved to: /tmp/tmprbobxbd0/output_path\n</code></pre> <p>source</p>"},{"location":"Embeddings_CLI/#generate","title":"generate","text":"<pre><code> generate (db_path:str=&lt;typer.models.OptionInfo object at 0x7fa333795400&gt;)\n</code></pre> <pre><code>runner = CliRunner()\nresult = runner.invoke(app, [\"generate\", \"--help\"])\n</code></pre> <pre>                                                                                                                   \n Usage: generate [OPTIONS]                                                                                         \n                                                                                                                   \n</pre> <pre> Download the docs and examples from FastStream repo, generate embeddings, and save them in a vector database.     \n                                                                                                                   \n</pre> <pre>\u256d\u2500 Options \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 --db_path             -p      TEXT  The path to save the vector database.                                       \u2502\n\u2502                                     [default: /work/fastkafka-gen/faststream_gen/package_data]                  \u2502\n\u2502 --install-completion                Install completion for the current shell.                                   \u2502\n\u2502 --show-completion                   Show completion for the current shell, to copy it or customize the          \u2502\n\u2502                                     installation.                                                               \u2502\n\u2502 --help                              Show this message and exit.                                                 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</pre> <pre><code>with TemporaryDirectory() as d:\n    db_path = f\"{d}\"\n    result = runner.invoke(app, [\"-p\", db_path])\n\n    print(result.output)\n    assert result.exit_code == 0\n    assert (Path(d) / \"docs\" / \"index.faiss\").exists()\n    assert (Path(d) / \"examples\" / \"index.faiss\").exists()\n</code></pre> <pre><code>Downloading documentation and examples for semantic search.\n\u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...\nBelow files are included in the embeddings:\n    - index.md\n    - release.md\n    - kafka/ack.md\n    - kafka/index.md\n    - kafka/message.md\n    - kafka/Publisher/batch_publisher.md\n    - kafka/Publisher/index.md\n    - kafka/Publisher/using_a_key.md\n    - kafka/Subscriber/batch_subscriber.md\n    - kafka/Subscriber/index.md\n    - getting-started/logging.md\n    - getting-started/index.md\n    - getting-started/dependencies/sub.md\n    - getting-started/dependencies/global.md\n    - getting-started/dependencies/yield.md\n    - getting-started/dependencies/class.md\n    - getting-started/dependencies/index.md\n    - getting-started/dependencies/testing.md\n    - getting-started/context/fields.md\n    - getting-started/context/extra.md\n    - getting-started/context/existed.md\n    - getting-started/context/index.md\n    - getting-started/context/custom.md\n    - getting-started/cli/index.md\n    - getting-started/subscription/pydantic.md\n    - getting-started/subscription/index.md\n    - getting-started/subscription/annotation.md\n    - getting-started/subscription/filtering.md\n    - getting-started/subscription/test.md\n    - getting-started/asyncapi/export.md\n    - getting-started/asyncapi/hosting.md\n    - getting-started/asyncapi/custom.md\n    - getting-started/integrations/fastapi/index.md\n    - getting-started/integrations/frameworks/index.md\n    - getting-started/serialization/decoder.md\n    - getting-started/serialization/parser.md\n    - getting-started/serialization/index.md\n    - getting-started/serialization/examples.md\n    - getting-started/config/index.md\n    - getting-started/middlewares/index.md\n    - getting-started/publishing/object.md\n    - getting-started/publishing/decorator.md\n    - getting-started/publishing/direct.md\n    - getting-started/publishing/index.md\n    - getting-started/publishing/broker.md\n    - getting-started/publishing/test.md\n    - getting-started/routers/index.md\n    - getting-started/template/index.md\n    - getting-started/contributing/CONTRIBUTING.md\n    - getting-started/contributing/docs.md\n    - getting-started/lifespan/index.md\n    - getting-started/lifespan/test.md\n    - getting-started/lifespan/hooks.md\n    - nats/index.md\n    - nats/rpc.md\n    - nats/message.md\n    - nats/publishing/index.md\n    - nats/examples/direct.md\n    - nats/examples/pattern.md\n    - nats/jetstream/object.md\n    - nats/jetstream/ack.md\n    - nats/jetstream/key-value.md\n    - nats/jetstream/index.md\n    - rabbit/ack.md\n    - rabbit/publishing.md\n    - rabbit/index.md\n    - rabbit/declare.md\n    - rabbit/rpc.md\n    - rabbit/message.md\n    - rabbit/examples/headers.md\n    - rabbit/examples/direct.md\n    - rabbit/examples/stream.md\n    - rabbit/examples/index.md\n    - rabbit/examples/topic.md\n    - rabbit/examples/fanout.md\n                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                      \u2827 Creating embeddings for the docs...                                      \u2807 Creating embeddings for the docs...                                      \u280f Creating embeddings for the docs...                                      \u280b Creating embeddings for the docs...                                      \u2819 Creating embeddings for the docs...                                      \u2839 Creating embeddings for the docs...                                      \u2838 Creating embeddings for the docs...                                      \u283c Creating embeddings for the docs...                                      \u2834 Creating embeddings for the docs...                                      \u2826 Creating embeddings for the docs...                                       \u2714 Docs embeddings created and saved to: /tmp/tmp70b1gjwi/docs \n\u280b Creating embeddings for the examples...\nRequired files are missing. Skipping directory: /tmp/tmpcprm018z/extrated_path/faststream-gen-main/search/examples/__init__.py\n\nBelow files are included in the embeddings:\n    - example_add_and_publish_with_key.txt\n    - example_new_employee.txt\n    - example_infinity_publishing.txt\n    - example_calculate_mean_temperature.txt\n    - example_execute_trade.txt\n    - example_course_updates.txt\n    - example_student_query.txt\n    - example_investment_updates.txt\n    - example_log_msgs_with_plaintext_security.txt\n    - example_forward_to_multiple_topics.txt\n    - example_social_media_post.txt\n    - example_forward_with_security.txt\n    - example_publish_with_key.txt\n    - example_pets.txt\n    - example_add_and_publish_with_key2.txt\n    - example_product_reviews.txt\n    - example_consume_publish_with_key.txt\n    - example_forward_to_another_topic.txt\n    - example_scram256_security.txt\n    - example_weather_updates.txt\n    - example_plants.txt\n    - example_scram512_security.txt\n    - example_scrape_weather.txt\n                                          \u2819 Creating embeddings for the examples...                                          \u2839 Creating embeddings for the examples...                                          \u2838 Creating embeddings for the examples...                                          \u283c Creating embeddings for the examples...                                          \u2834 Creating embeddings for the examples...                                          \u2826 Creating embeddings for the examples...                                          \u2827 Creating embeddings for the examples...                                          \u2807 Creating embeddings for the examples...                                          \u280f Creating embeddings for the examples...                                          \u280b Creating embeddings for the examples...                                          \u2819 Creating embeddings for the examples...                                          \u2839 Creating embeddings for the examples...                                          \u2838 Creating embeddings for the examples...                                          \u283c Creating embeddings for the examples...                                          \u2834 Creating embeddings for the examples...                                           \u2714 Examples embeddings created and saved to: /tmp/tmp70b1gjwi/examples\n\nSuccessfully generated all the embeddings and saved to: /tmp/tmp70b1gjwi\n</code></pre>"},{"location":"Helper/","title":"Helper","text":"<pre><code>import sys\nfrom unittest.mock import patch\n\nfrom faststream_gen._code_generator.constants import FASTSTREAM_DOCS_DIR_SUFFIX, FASTSTREAM_REPO_ZIP_URL, OpenAIModel, FASTSTREAM_ROOT_DIR_NAME\n\nimport pytest\nimport openai\n</code></pre> <pre><code>suppress_timestamps()\nlogger = get_logger(__name__, level=20)\nlogger.info(\"ok\")\n</code></pre> <pre><code>[INFO] __main__: ok\n</code></pre> <p>source</p>"},{"location":"Helper/#set_cwd","title":"set_cwd","text":"<pre><code> set_cwd (cwd_path:Union[pathlib.Path,str])\n</code></pre> <p>Set the current working directory for the duration of the context manager.</p> <p>Args: cwd_path: The path to the new working directory.</p> <p>Note</p> <p>The above docstring is autogenerated by docstring-gen library (https://github.com/airtai/docstring-gen)</p> <pre><code>with TemporaryDirectory() as d:\n    with set_cwd(d):\n        assert (\n            Path(os.getcwd()) == Path(d).resolve()\n        ), f\"{os.getcwd()}, {Path(d).resolve()}\"\n</code></pre> <p>source</p>"},{"location":"Helper/#set_logger_level","title":"set_logger_level","text":"<pre><code> set_logger_level (func:Callable[...,Any])\n</code></pre> <p>Decorator to set the logger level based on verbosity.</p> <p>Args: func: The function to be decorated.</p> <p>Returns: The decorated function.</p> <pre><code>@set_logger_level\ndef _test_logger():\n    logger.debug(\"INFO\")\n    logger.info(\"WARNING\")\n\n\n_test_logger()\ndisplay(logger.getEffectiveLevel())\nassert logger.getEffectiveLevel() == logging.WARNING\n</code></pre> <pre><code>30\n</code></pre> <pre><code>@set_logger_level\ndef _test_logger(**kwargs):\n    logger.debug(\"INFO\")\n    logger.info(\"WARNING\")\n\n\n_test_logger(verbose=True)\ndisplay(logger.getEffectiveLevel())\nassert logger.getEffectiveLevel() == logging.INFO\n</code></pre> <pre><code>[INFO] __main__: WARNING\n\n20\n</code></pre> <p>source</p>"},{"location":"Helper/#retry_on_error","title":"retry_on_error","text":"<pre><code> retry_on_error (max_retries:int=3, delay:int=1)\n</code></pre> Type Default Details max_retries int 3 delay int 1 type: ignore <pre><code>@retry_on_error(max_retries=3)\ndef my_function(attempt):\n    # Code that may raise an exception\n    raise ValueError([], False)\n\n\nactual = my_function()\nprint(actual)\nexpected = ([], False) \nassert actual == expected\n</code></pre> <pre><code>[INFO] __main__: Attempt 0 failed. Restarting step.\n[INFO] __main__: Attempt 1 failed. Restarting step.\n[INFO] __main__: Attempt 2 failed. Restarting step.\n([], False)\n</code></pre> <pre><code>@retry_on_error(max_retries=3)\ndef my_function(attempt):\n    # Code that may raise an exception\n    return \"hi\"\n\n# Call the decorated function\nactual = my_function()\nprint(actual)\n\nassert actual == \"hi\"\n</code></pre> <pre><code>hi\n</code></pre> <p>source</p>"},{"location":"Helper/#ensure_openai_api_key_set","title":"ensure_openai_api_key_set","text":"<pre><code> ensure_openai_api_key_set ()\n</code></pre> <p>Ensure the \u2018OPENAI_API_KEY\u2019 environment variable is set and is not empty.</p> <p>Raises: KeyError: If the \u2018OPENAI_API_KEY\u2019 environment variable is not found. ValueError: If the \u2018OPENAI_API_KEY\u2019 environment variable is found but its value is empty.</p> <pre><code>with patch.dict(os.environ, {\"OPENAI_API_KEY\": \"\"}):\n    with pytest.raises(ValueError) as e:\n        ensure_openai_api_key_set()\n\nprint(e.value)\nassert str(e.value) == OPENAI_KEY_EMPTY_ERROR\n</code></pre> <pre><code>Error: OPENAI_API_KEY cannot be empty. Please set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again.\nYou can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n</code></pre> <pre><code>with patch.dict(os.environ, {}, clear=True):\n    with pytest.raises(KeyError) as e:\n        ensure_openai_api_key_set()\n\nprint(e.value)\nassert str(e.value) == f\"'{OPENAI_KEY_NOT_SET_ERROR}'\"\n</code></pre> <pre><code>'Error: OPENAI_API_KEY not found in environment variables. Set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.'\n</code></pre> <pre><code>with patch.dict(os.environ, {\"OPENAI_API_KEY\": \"INVALID_KEY\"}):\n    ensure_openai_api_key_set()\n</code></pre> <p>source</p>"},{"location":"Helper/#add_tokens_usage","title":"add_tokens_usage","text":"<pre><code> add_tokens_usage (usage_list:List[Dict[str,int]])\n</code></pre> <p>Add list of OpenAI \u201cusage\u201d dictionaries by categories defined in TOKEN_TYPES (prompt_tokens, completion_tokens and total_tokens).</p> <p>Args: usage_list: List of OpenAI \u201cusage\u201d dictionaries</p> <p>Returns: Dict[str, int]: Dictionary where the keys are TOKEN_TYPES and their values are the sum of OpenAI \u201cusage\u201d dictionaries</p> <pre><code>usage = {\n    \"prompt_tokens\": 129,\n    \"completion_tokens\": 1,\n    \"total_tokens\": 130\n  }\nassert add_tokens_usage([usage, usage]) == {\n    \"prompt_tokens\": 258,\n    \"completion_tokens\": 2,\n    \"total_tokens\": 260\n}\n</code></pre> <pre><code>usage = {\n    \"prompt_tokens\": 129,\n    \"completion_tokens\": 1,\n    \"total_tokens\": 130\n  }\nassert add_tokens_usage([defaultdict(int), usage]) == {\n    \"prompt_tokens\": 129,\n    \"completion_tokens\": 1,\n    \"total_tokens\": 130\n}\n</code></pre> <pre><code>fixture = [\n    \"\"\"\n==== description.txt starts ====\ndescription.txt\n==== description.txt ends ====\n==== app_skeleton.py starts ====\napp_skeleton.py\n==== app_skeleton.py ends ====\n==== app.py starts ====\napp.py\n==== app.py ends ====\n==== test_app.py starts ====\ntest_app.py\n==== test_app.py ends ====\n\"\"\"\n]\nexpected = {\n    \"description_to_skeleton\": \"\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\napp_skeleton.py\\n\",\n    \"skeleton_to_app_and_test\": \"\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== EXAMPLE APP SKELETON ====\\n\\napp_skeleton.py\\n\\n==== YOUR RESPONSE ====\\n\\n### application.py ###\\n\\napp.py\\n\\n### test.py ###\\n\\ntest_app.py\\n\",\n}\n\nactual = _format_examples(fixture)\nprint(actual)\n\nassert actual == expected\n</code></pre> <pre><code>{'description_to_skeleton': '\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\napp_skeleton.py\\n', 'skeleton_to_app_and_test': '\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== EXAMPLE APP SKELETON ====\\n\\napp_skeleton.py\\n\\n==== YOUR RESPONSE ====\\n\\n### application.py ###\\n\\napp.py\\n\\n### test.py ###\\n\\ntest_app.py\\n'}\n</code></pre> <p>source</p>"},{"location":"Helper/#get_relevant_prompt_examples","title":"get_relevant_prompt_examples","text":"<pre><code> get_relevant_prompt_examples (query:str)\n</code></pre> <p>Load the vector database and retrieve the most relevant examples based on the given query for each step.</p> <p>Args: query: The query for relevance-based document retrieval.</p> <p>Returns: The dictionary of the most relevant examples for each step.</p> <pre><code>query = \"\"\"\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\"\"\"\n\nactual = get_relevant_prompt_examples(query)\n\n\n\nassert \"==== EXAMPLE APP DESCRIPTION ====\" in actual[\"description_to_skeleton\"]\nassert \"==== app_skeleton.py starts ====\" not in actual[\"description_to_skeleton\"]\nprint(actual[\"description_to_skeleton\"])\n</code></pre> <pre><code>[INFO] faiss.loader: Loading faiss with AVX2 support.\n[INFO] faiss.loader: Successfully loaded faiss with AVX2 support.\n\n==== EXAMPLE APP DESCRIPTION ====\n\nDevelop a FastStream application using localhost kafka broker.\nThe app should consume messages from the input_data topic.\nThe input message is a JSON encoded object including two attributes:\n    - x: float\n    - y: float\n    - time: datetime\n\ninput_data topic should use partition key.\nWhile consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\nThe same partition key should be used in the input_data and output_data topic.\n\n\n\n==== YOUR RESPONSE ====\n\n\nfrom datetime import datetime\n\nfrom pydantic import BaseModel, Field\n\nfrom faststream import Context, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass Point(BaseModel):\n    x: float = Field(\n        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n    )\n    y: float = Field(\n        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n    )\n    time: datetime = Field(\n        ...,\n        examples=[\"2020-04-23 10:20:30.400000\"],\n        description=\"The timestamp of the record\",\n    )\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nto_output_data = broker.publisher(\"output_data\")\n\n\n@broker.subscriber(\"input_data\")\nasync def on_input_data(\n    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\n) -&gt; None:\n    \"\"\"\n    Processes a message from the 'input_data' topic.\n    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n    The same partition key should be used in the input_data and output_data topic.\n\n    Instructions:\n    1. Consume a message from 'input_data' topic.\n    2. Create a new message object (do not directly modify the original).\n    3. Increment msg x and y attributes with 1.\n    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\n    \"\"\"\n    raise NotImplementedError()\n\n\n==== EXAMPLE APP DESCRIPTION ====\n\nDevelop a FastStream application using localhost kafka broker.\nThe app should consume messages from the input_data topic.\nThe input message is a JSON encoded object including two attributes:\n    - x: float\n    - y: float\n\nWhile consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\nUse messages attribute x as a partition key when publishing to output_data topic.\n\n\n\n==== YOUR RESPONSE ====\n\n\nfrom pydantic import BaseModel, Field\n\nfrom faststream import FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass Point(BaseModel):\n    x: float = Field(\n        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n    )\n    y: float = Field(\n        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n    )\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nto_output_data = broker.publisher(\"output_data\")\n\n\n@broker.subscriber(\"input_data\")\nasync def on_input_data(msg: Point, logger: Logger) -&gt; None:\n    \"\"\"\n    Processes a message from the 'input_data' topic.\n    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n    Publish that message to the output_data topic\n    Use messages attribute x as a partition key when publishing to output_data topic.\n\n    Instructions:\n    1. Consume a message from 'input_data' topic.\n    2. Create a new message object (do not directly modify the original).\n    3. Increment msg x and y attributes with 1.\n    4. Publish that message to the output_data topic (Use messages attribute x as a partition key).\n    \"\"\"\n    raise NotImplementedError()\n\n\n==== EXAMPLE APP DESCRIPTION ====\n\nDevelop a FastStream application using localhost kafka broker.\nThe app should consume messages from the input_data topic.\nThe input message is a JSON encoded object including two attributes:\n    - x: float\n    - y: float\n    - time: datetime\n\ninput_data topic should use partition key.\n\nKeep all the previous messages in the memory.\nWhile consuming the message, add all x elements from the memory (x_sum) and all y from the memory (y_sum) and publish the message with x_sum and y_sum to the output_data topic.\nThe same partition key should be used in the input_data and output_data topic.\n\n\n\n==== YOUR RESPONSE ====\n\n\nfrom datetime import datetime\nfrom typing import List\n\nfrom pydantic import BaseModel, Field\n\nfrom faststream import Context, ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass Point(BaseModel):\n    x: float = Field(\n        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n    )\n    y: float = Field(\n        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n    )\n    time: datetime = Field(\n        ...,\n        examples=[\"2020-04-23 10:20:30.400000\"],\n        description=\"The timestamp of the record\",\n    )\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nto_output_data = broker.publisher(\"output_data\")\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    \"\"\"\n    Set all necessary global variables inside ContextRepo object:\n        Set message_history for storing all input messages\n    \"\"\"\n    raise NotImplementedError()\n\n\n@broker.subscriber(\"input_data\")\nasync def on_input_data(\n    msg: Point,\n    logger: Logger,\n    message_history: List[Point] = Context(),\n    key: bytes = Context(\"message.raw_message.key\"),\n) -&gt; None:\n    \"\"\"\n    Processes a message from the 'input_data' topic.\n    Add all x elements from the memory (x_sum) and all y from the memory (y_sum) and publish the message with x_sum and y_sum to the output_data topic.\n    The same partition key should be used in the input_data and output_data topic.\n\n    Instructions:\n    1. Consume a message from 'input_data' topic.\n    2. Create a new message object (do not directly modify the original).\n    3. Add all x elements from the memory (x_sum) and all y from the memory (y_sum)\n    4. Publish the message with x_sum and y_sum to the output_data topic. (The same partition key should be used in the input_data and output_data topic).\n    \"\"\"\n    raise NotImplementedError()\n</code></pre> <p>source</p>"},{"location":"Helper/#strip_white_spaces","title":"strip_white_spaces","text":"<pre><code> strip_white_spaces (description:str)\n</code></pre> <p>Remove and strip excess whitespaces from a given description</p> <p>Args: description: The description string to be processed.</p> <p>Returns: The cleaned description string.</p> <pre><code>fixture = \"\"\"\n    I have   a                  lot\n                of whitespaces\n\n\n\"\"\"\n\nexpected = \"I have a lot of whitespaces\"\nactual = strip_white_spaces(fixture)\nprint(actual)\nassert actual == expected\n</code></pre> <pre><code>I have a lot of whitespaces\n</code></pre> <p>source</p>"},{"location":"Helper/#write_file_contents","title":"write_file_contents","text":"<pre><code> write_file_contents (output_file:str, contents:str)\n</code></pre> <p>Write the given contents to the specified output file.</p> <p>Args: output_file: The path to the output file where the contents will be written. contents: The contents to be written to the output file.</p> <p>Raises: OSError: If there is an issue while attempting to save the file.</p> <pre><code>contents = \"\"\"\nprint(\"Hello World\")\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    output_path = f\"{str(d)}/grand-parent/parent/child\"\n    output_file = f\"{output_path}/application.py\"\n\n    write_file_contents(output_file, contents)\n\n    with open(output_file, 'r', encoding=\"utf-8\") as f:\n        actual = f.read()\n    print(f\"{output_file}\\n\\n{actual}\")\n\nassert actual == contents\n</code></pre> <pre><code>/tmp/tmp3i7gtvzn/grand-parent/parent/child/application.py\n\n\nprint(\"Hello World\")\n</code></pre> <p>source</p>"},{"location":"Helper/#read_file_contents","title":"read_file_contents","text":"<pre><code> read_file_contents (output_file:str)\n</code></pre> <p>Read and return the contents from the specified file.</p> <p>Args: output_file: The path to the file to be read.</p> <p>Returns: The contents of the file as string.</p> <p>Raises: FileNotFoundError: If the specified file does not exist.</p> <pre><code>contents = \"\"\"\nprint(\"Hello World\")\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    output_path = f\"{str(d)}/grand-parent/parent/child\"\n    output_file = f\"{output_path}/application.py\"\n\n    write_file_contents(output_file, contents)\n\n    actual = read_file_contents(output_file)\n    print(f\"{output_file}\\n\\n{actual}\")\n\nassert actual == contents\n</code></pre> <pre><code>/tmp/tmpa4z2fli7/grand-parent/parent/child/application.py\n\n\nprint(\"Hello World\")\n</code></pre> <pre><code>contents = \"\"\"\nprint(\"Hello World\")\n\"\"\"\n\nwith pytest.raises(FileNotFoundError) as e:\n    with TemporaryDirectory() as d:\n        output_path = f\"{str(d)}/grand-parent/parent/child\"\n        output_file = f\"{output_path}/application.py\"\n\n        actual = read_file_contents(output_file)\n\nprint(str(e))\n</code></pre> <pre><code>&lt;ExceptionInfo FileNotFoundError(\"Error: The file '/tmp/tmp2zdz501b/grand-parent/parent/child/application.py' does not exist. Please ensure that the specified 'output_path' is valid and that you have the necessary permissions to access it.\") tblen=2&gt;\n</code></pre> <p>source</p>"},{"location":"Helper/#mock_openai_create","title":"mock_openai_create","text":"<pre><code> mock_openai_create (test_response:str)\n</code></pre> <pre><code>test_response = \"This is a mock response\"\n\nwith mock_openai_create(test_response):\n    response = openai.ChatCompletion.create()\n    ret_val = response['choices'][0]['message']['content']\n    print(ret_val)\n    assert ret_val == test_response\n</code></pre> <pre><code>This is a mock response\n</code></pre> <pre><code>response = _fetch_content(\"https://fastkafka.airt.ai/\")\nprint(response.content[:200])\nassert len(response.content) &gt; 0\n</code></pre> <pre><code>b'&lt;!doctype html&gt;\\n&lt;html lang=\"en\" dir=\"ltr\" class=\"plugin-pages plugin-id-default\"&gt;\\n&lt;head&gt;\\n&lt;meta charset=\"UTF-8\"&gt;\\n&lt;meta name=\"generator\" content=\"Docusaurus v2.4.0\"&gt;\\n&lt;title data-rh=\"true\"&gt;Effortless Kaf'\n</code></pre> <p>source</p>"},{"location":"Helper/#download_and_extract_github_repo","title":"download_and_extract_github_repo","text":"<pre><code> download_and_extract_github_repo (url:str)\n</code></pre> <pre><code>with download_and_extract_github_repo(FASTSTREAM_REPO_ZIP_URL) as extracted_path:\n    files = [p.stem for p in list(Path(extracted_path/FASTSTREAM_ROOT_DIR_NAME).glob(\"*\"))]\n    print(files)\n    assert \"pyproject\" in files\n</code></pre> <pre><code>['README', 'faststream', '.pre-commit-config', 'CONTRIBUTING', '.github', 'CODE_OF_CONDUCT', 'pyproject', 'docs', 'scripts', 'SECURITY', 'examples', 'LICENSE', 'tests', '.gitignore', '.secrets']\n</code></pre> <p>source</p>"},{"location":"Helper/#validate_python_code","title":"validate_python_code","text":"<pre><code> validate_python_code (file_name:str, **kwargs:Dict[str,Any])\n</code></pre> <p>Validate and report errors in the provided Python code.</p> <p>Args: file_name: Python file to validate</p> <p>Returns: A list of error messages encountered during validation. If no errors occur, an empty list is returned.</p> <pre><code>fixture = \"\"\"\nimport os\ndef say_hello():\n    print(\"hello\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / \"application.py\"\n    write_file_contents(str(app_file), fixture)\n\n    actual = validate_python_code(app_file)\n    expected = []\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture = \"\"\"\nimport os\nimport invalid_module\ndef say_hello():\n    print(\"hello\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / \"application.py\"\n    write_file_contents(str(app_file), fixture)\n\n\n    actual = validate_python_code(app_file)\n    expected = [\"ModuleNotFoundError: No module named 'invalid_module'\"]\n\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[\"ModuleNotFoundError: No module named 'invalid_module'\"]\n</code></pre> <pre><code>fixture = \"\"\"\nimport os\ndef say_hello()\n    print(\"hello\")\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / \"application.py\"\n    write_file_contents(str(app_file), fixture)\n\n\n    actual = validate_python_code(app_file)\n\n    expected = (\n        [\"SyntaxError: invalid syntax (application.py, line 3)\"]\n        if sys.version_info &lt; (3, 10)\n        else [\"SyntaxError: expected ':' (application.py, line 3)\"]\n    )\n\n    print(actual)\n    assert (\n        actual == expected\n    ), f\"actual = {actual} - expected = {expected} - sys.version_info = {sys.version_info}\"\n</code></pre> <pre><code>[\"SyntaxError: expected ':' (application.py, line 3)\"]\n</code></pre>"},{"location":"Integration_Test_Generator/","title":"Integration Test Generator","text":"<pre><code>import pytest\n\nfrom faststream_gen._components.logger import suppress_timestamps\n</code></pre> <pre><code>fixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_pass():\n    assert True\n\"\"\"\n\nfixture_pytoml_file = \"\"\"\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"app\"\nversion = \"0.0.1\"\ndependencies = [ \"faststream[kafka, docs]&gt;=0.1.5\", \"pydantic\", \"ssl\", \"requests\",]\n\n[project.optional-dependencies]\nlint = [ \"black==23.9.1\",]\nstatic-analysis = [ \"types-PyYAML\",]\ntesting = [ \"faststream[kafka, testing]&gt;=0.1.5\", \"pytest\",]\ndev = [ \"app[lint,static-analysis,testing]\",]\n\n[tool.pytest.ini_options]\nfilterwarnings = [ \"ignore::DeprecationWarning\",]\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_pytoml_file)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    actual = _setup_venv_and_run_tests(d)\n    print(actual)\n    assert actual == []\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\nimport unknown_package\ndef test_always_fails():\n    assert False\n\"\"\"\n\nfixture_pytoml_file = \"\"\"\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n\n[project]\nname = \"app\"\nversion = \"0.0.1\"\ndependencies = [ \"faststream[kafka, docs]&gt;=0.1.5\", \"pydantic\", \"ssl\", \"requests\",]\n\n[project.optional-dependencies]\nlint = [ \"black==23.9.1\",]\nstatic-analysis = [ \"types-PyYAML\",]\ntesting = [ \"faststream[kafka, testing]&gt;=0.1.5\", \"pytest\",]\ndev = [ \"app[lint,static-analysis,testing]\",]\n\n[tool.pytest.ini_options]\nfilterwarnings = [ \"ignore::DeprecationWarning\",]\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_pytoml_file)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    actual = _setup_venv_and_run_tests(d)\n    print(actual[0])\n    assert actual != []\n    print(\"OK\")\n</code></pre> <pre><code>============================= test session starts ==============================\nplatform linux -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0\nrootdir: /tmp/tmplojftuue\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, asyncio-0.21.1\nasyncio: mode=Mode.STRICT\ncollected 0 items / 1 error\n\n==================================== ERRORS ====================================\n__________________ ERROR collecting tests/test_application.py __________________\nImportError while importing test module '/tmp/tmplojftuue/tests/test_application.py'.\nHint: make sure your test modules/packages have valid Python names.\nTraceback:\n/usr/lib/python3.11/importlib/__init__.py:126: in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\ntests/test_application.py:2: in &lt;module&gt;\n    import unknown_package\nE   ModuleNotFoundError: No module named 'unknown_package'\n=========================== short test summary info ============================\nERROR tests/test_application.py\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n=============================== 1 error in 0.07s ===============================\nOK\n</code></pre> <pre><code>response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic, ssl, requests\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nactual = _split_app_and_test_req(response)\nprint(actual)\nexpected = ('pydantic, ssl, requests', 'pytest')\nassert actual == expected\n</code></pre> <pre><code>('pydantic, ssl, requests', 'pytest')\n</code></pre> <pre><code>response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic, ssl, requests\"\n\n==== TEST REQUIREMENT ====\n\"\"\"\n\nactual = _split_app_and_test_req(response)\nprint(actual)\nexpected = ('pydantic, ssl, requests', '')\nassert actual == expected\n</code></pre> <pre><code>('pydantic, ssl, requests', '')\n</code></pre> <pre><code>fixture_requirements = \"\"\"[build-system]\nrequires = [\"hatchling\"]\n\n[project]\nname = \"app\"\nversion = \"0.0.1\"\n\ndependencies = [\n    \"faststream[kafka, docs]&gt;=0.1.5\",\n]\n\n[project.optional-dependencies]\nlint = [\n    \"black==23.9.1\",\n]\n\nstatic-analysis = [\n    \"types-PyYAML\",\n]\n\ntesting = [\n    \"faststream[kafka, testing]&gt;=0.1.5\",\n]\n\ndev = [\"app[lint,static-analysis,testing]\"]\n\n[tool.pytest.ini_options]\nfilterwarnings =[\"ignore::DeprecationWarning\"]\n\"\"\"\n\napp_req = \"pydantic, ssl, requests\"\ntest_req = \"pytest\"\n\nexpected = \"\"\"[build-system]\nrequires = [ \"hatchling\",]\n\n[project]\nname = \"app\"\nversion = \"0.0.1\"\ndependencies = [ \"faststream[kafka, docs]&gt;=0.1.5\", \"pydantic\", \"ssl\", \"requests\",]\n\n[project.optional-dependencies]\nlint = [ \"black==23.9.1\",]\nstatic-analysis = [ \"types-PyYAML\",]\ntesting = [ \"faststream[kafka, testing]&gt;=0.1.5\",]\ndev = [ \"app[lint,static-analysis,testing]\",]\n\n[tool.pytest.ini_options]\nfilterwarnings = [ \"ignore::DeprecationWarning\",]\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(toml_file, fixture_requirements)\n\n    _update_toml_file(d, app_req, test_req)\n\n    actual = read_file_contents(toml_file)\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[build-system]\nrequires = [ \"hatchling\",]\n\n[project]\nname = \"app\"\nversion = \"0.0.1\"\ndependencies = [ \"faststream[kafka, docs]&gt;=0.1.5\", \"pydantic\", \"ssl\", \"requests\",]\n\n[project.optional-dependencies]\nlint = [ \"black==23.9.1\",]\nstatic-analysis = [ \"types-PyYAML\",]\ntesting = [ \"faststream[kafka, testing]&gt;=0.1.5\",]\ndev = [ \"app[lint,static-analysis,testing]\",]\n\n[tool.pytest.ini_options]\nfilterwarnings = [ \"ignore::DeprecationWarning\",]\n</code></pre> <pre><code>fixture_response = \"\"\"\n\"pydantic, ssl, requests\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    expected = ['Please add ==== APP REQUIREMENT ==== and ==== TEST REQUIREMENT ==== in your response']\n    actual = _validate_response(fixture_response, d)\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>['Please add ==== APP REQUIREMENT ==== and ==== TEST REQUIREMENT ==== in your response']\n</code></pre> <pre><code>fixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_pass():\n    assert True\n\"\"\"\n\nfixture_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    expected = []\n    actual = _validate_response(fixture_response, d)\n    print(actual)\n    assert actual == expected\n</code></pre> <pre><code>[]\n</code></pre> <pre><code>fixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_fail():\n    assert False\n\"\"\"\n\nfixture_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    actual = _validate_response(fixture_response, d)\n    print(actual[0])\n    assert \"=================================== FAILURES ===================================\" in actual[0]\n    print(\"OK\")\n</code></pre> <pre><code>============================= test session starts ==============================\nplatform linux -- Python 3.11.4, pytest-7.4.2, pluggy-1.3.0\nrootdir: /tmp/tmpl0aw7_87\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, asyncio-0.21.1\nasyncio: mode=Mode.STRICT\ncollected 1 item\n\ntests/test_application.py F                                              [100%]\n\n=================================== FAILURES ===================================\n_______________________________ test_always_fail _______________________________\ntests/test_application.py:3: in test_always_fail\n    assert False\nE   assert False\n=========================== short test summary info ============================\nFAILED tests/test_application.py::test_always_fail - assert False\n============================== 1 failed in 0.04s ===============================\nOK\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some valid prompt\"\napp_skeleton = \"some app skeleton\"\ntotal_usage = []\n\ntest_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nfixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_fail():\n    assert False\n\"\"\"\n\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    with mock_openai_create(test_response):\n        total_usage, is_valid_req_code = _generate(\n            model, prompt, app_skeleton, total_usage, d\n        )\n\n    print(is_valid_req_code)\n\n    assert not is_valid_req_code\n    assert isinstance(is_valid_req_code, bool)\n</code></pre> <pre><code>False\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\nprompt = \"Some valid prompt\"\napp_skeleton = \"some app skeleton\"\ntotal_usage = []\n\ntest_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nfixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_pass():\n    assert True\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    with mock_openai_create(test_response):\n        total_usage, is_valid_req_code = _generate(\n            model, prompt, app_skeleton, total_usage, d\n        )\n\n    print(is_valid_req_code)\n\n    assert is_valid_req_code\n    assert isinstance(is_valid_req_code, bool)\n</code></pre> <pre><code>True\n</code></pre> <p>source</p>"},{"location":"Integration_Test_Generator/#fix_requirements_and_run_tests","title":"fix_requirements_and_run_tests","text":"<pre><code> fix_requirements_and_run_tests (output_directory:str, model:str,\n                                 total_usage:List[Dict[str,int]])\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\ntotal_usage = []\n\ntest_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nfixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_pass():\n    assert True\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    with mock_openai_create(test_response):\n        total_usage, is_requirements_file_valid = fix_requirements_and_run_tests(d, model, [])\n\n    print(is_requirements_file_valid)\n\n    assert is_requirements_file_valid\n    assert isinstance(is_requirements_file_valid, bool)\n</code></pre> <pre><code>\u2839 Running integration tests...  \u2714 Integration tests were successfully completed. \nTrue\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre> <pre><code>model = OpenAIModel.gpt3.value\ntotal_usage = []\n\ntest_response = \"\"\"\n==== APP REQUIREMENT ====\n\"pydantic\"\n\n==== TEST REQUIREMENT ====\n\"pytest\"\n\"\"\"\n\nfixture_app_code = \"\"\"\nprint(\"Hi\")\n\"\"\"\n\nfixture_test_code = \"\"\"\ndef test_always_pass():\n    assert False\n\"\"\"\n\nwith TemporaryDirectory() as d:\n    app_file = Path(d) / APPLICATION_FILE_PATH\n    test_file = Path(d) / TEST_FILE_PATH\n    toml_file = Path(d) / TOML_FILE_NAME\n    write_file_contents(app_file, fixture_app_code)\n    write_file_contents(test_file, fixture_test_code)\n    write_file_contents(toml_file, fixture_requirements)\n\n    test_init_file_path = test_file.parent / \"__init__.py\"\n    test_init_file_path.touch()\n\n    app_init_file_path = app_file.parent / \"__init__.py\"\n    app_init_file_path.touch()\n\n    with mock_openai_create(test_response):\n        total_usage, is_requirements_file_valid = fix_requirements_and_run_tests(d, model, [])\n\n    print(is_requirements_file_valid)\n\n    assert not is_requirements_file_valid\n    assert isinstance(is_requirements_file_valid, bool)\n</code></pre> <pre><code>\u2839 Running integration tests...  \u2718 Error: Integration tests failed. \nFalse\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:228: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(value) if value else value\n</code></pre>"},{"location":"Logger/","title":"Logger","text":"<p>source</p>"},{"location":"Logger/#get_default_logger_configuration","title":"get_default_logger_configuration","text":"<pre><code> get_default_logger_configuration (level:int=20)\n</code></pre> <p>Return the common configurations for the logger</p> <p>Args: level: Logger level to set</p> <p>Returns: A dict with default logger configuration</p> <p>source</p>"},{"location":"Logger/#suppress_timestamps","title":"suppress_timestamps","text":"<pre><code> suppress_timestamps (flag:bool=True)\n</code></pre> <p>Suppress logger timestamp</p> <p>Args: flag: If not set, then the default value True will be used to suppress the timestamp from the logger messages</p> <p>Example on how to use get_default_logger_configuration function</p> <pre><code># collapse_output\n\nget_default_logger_configuration()\n</code></pre> <pre><code>{'version': 1,\n 'disable_existing_loggers': False,\n 'formatters': {'standard': {'format': '%(asctime)s.%(msecs)03d [%(levelname)s] %(name)s: %(message)s',\n   'datefmt': '%y-%m-%d %H:%M:%S'}},\n 'handlers': {'default': {'level': 20,\n   'formatter': 'standard',\n   'class': 'logging.StreamHandler',\n   'stream': 'ext://sys.stdout'}},\n 'loggers': {'': {'handlers': ['default'], 'level': 20}}}\n</code></pre> <p>source</p>"},{"location":"Logger/#get_logger","title":"get_logger","text":"<pre><code> get_logger (name:str, level:int=20, add_spaces:bool=True)\n</code></pre> <p>Return the logger class with default logging configuration.</p> <p>Args: name: Pass the name variable as name while calling level: Used to configure logging, default value <code>logging.INFO</code> logs info messages and up. add_spaces:</p> <p>Returns: The logging.Logger class with default/custom logging configuration</p> <pre><code>logger = get_logger(__name__)\nlogger.info(\"hello\")\nlogger = get_logger(__name__)\nlogger.info(\"hello\")\n\n\ndef f():\n    logger.info(\"hello\")\n\n\nf()\n</code></pre> <pre><code>23-09-25 10:14:24.492 [INFO] __main__: hello\n23-09-25 10:14:24.493 [INFO] __main__: hello\n23-09-25 10:14:24.493 [INFO] __main__: hello\n</code></pre> <p>Example on how to use get_logger function</p> <pre><code># collapse_output\n\nlogger = get_logger(__name__)\n\nlogger.debug(\"Debug\")\nlogger.info(\"info\")\nlogger.warning(\"Warning\")\nlogger.error(\"Error\")\nlogger.critical(\"Critical\")\n</code></pre> <pre><code>23-09-25 10:14:24.499 [INFO] __main__: info\n23-09-25 10:14:24.500 [WARNING] __main__: Warning\n23-09-25 10:14:24.500 [ERROR] __main__: Error\n23-09-25 10:14:24.500 [CRITICAL] __main__: Critical\n</code></pre> <pre><code># collapse_output\n\nsuppress_timestamps()\nlogger = get_logger(__name__)\n\nlogger.debug(\"Debug\")\nlogger.info(\"info\")\nlogger.warning(\"Warning\")\nlogger.error(\"Error\")\nlogger.critical(\"Critical\")\n</code></pre> <pre><code>[INFO] __main__: info\n[WARNING] __main__: Warning\n[ERROR] __main__: Error\n[CRITICAL] __main__: Critical\n</code></pre> <p>source</p>"},{"location":"Logger/#set_level","title":"set_level","text":"<pre><code> set_level (level:int)\n</code></pre> <p>Set logger level</p> <p>Args: level: Logger level to set</p> <pre><code>level = logging.ERROR\n\nset_level(level)\n\n# Checking if the logger is set back to logging.INFO in dev mode\nprint(logger.getEffectiveLevel())\nassert logger.getEffectiveLevel() == level\n\nlogger.debug(\"This is a debug message\")\nlogger.info(\"This is an info\")\nlogger.warning(\"This is a warning\")\nlogger.error(\"This is an error\")\n</code></pre> <pre><code>40\n[ERROR] __main__: This is an error\n</code></pre> <pre><code># Reset log level back to INFO\nlevel = logging.INFO\n\nset_level(level)\nlogger.info(\"something\")\n</code></pre> <pre><code>[INFO] __main__: something\n</code></pre> <pre><code>type(logging.DEBUG)\n</code></pre> <pre><code>int\n</code></pre>"},{"location":"New_Project_Generator/","title":"New Project Generator","text":"<pre><code>from tempfile import TemporaryDirectory\n\nfrom faststream_gen._code_generator.helper import read_file_contents\n</code></pre> <p>source</p>"},{"location":"New_Project_Generator/#create_project","title":"create_project","text":"<pre><code> create_project (output_path:str)\n</code></pre> <pre><code>with TemporaryDirectory() as d:\n    create_project(d)\n    files = [p.stem for p in list(Path(f\"{d}\").glob(\"*\"))]\n    print(files)\n    assert \"README\" in files\n\n    app_contents = read_file_contents(f\"{d}/{APPLICATION_FILE_PATH}\")\n    print(app_contents)\n    assert app_contents == \"\"\n\n    test_contents = read_file_contents(f\"{d}/{TEST_FILE_PATH}\")\n    assert test_contents == \"\"\n\n    script_files_permission = [os.stat(f).st_mode for f in list((Path(d) / \"scripts\").glob(\"*.sh\"))]\n    print(set(script_files_permission))\n    assert set(script_files_permission) == {33277}, script_files_permission\n</code></pre> <pre><code>\u2839 Creating a new FastStream project...  \u2714 New FastStream project created.     \n['README', '.github', 'pyproject', 'Dockerfile', 'scripts', 'LICENSE', 'tests', 'app', '.gitignore']\n\n{33277}\n\n/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n  self._color = self._set_color(color) if color else color\n</code></pre>"},{"location":"PackageData/","title":"PackageData","text":"<p>source</p>"},{"location":"PackageData/#get_root_data_path","title":"get_root_data_path","text":"<pre><code> get_root_data_path ()\n</code></pre> <p>Returns path to package_data in lib</p> <p>Example: ``` python from nbdev_mkdocs._package_data import get_root_data_path</p> <pre><code>mkdocs_template_path = get_root_data_path() / \"mkdocs_template.yml\"\nprint(f\"Path is: {mkdocs_template_path.resolve()}\")\nassert mkdocs_template_path.exists()\n\n```\n</code></pre> <p>Note</p> <p>The above docstring is autogenerated by docstring-gen library (https://github.com/airtai/docstring-gen)</p> <pre><code>get_root_data_path.__doc__\n</code></pre> <pre><code>'Returns path to package_data in lib\\n\\n    Example:\\n        ``` python\\n        from nbdev_mkdocs._package_data import get_root_data_path\\n\\n        mkdocs_template_path = get_root_data_path() / \"mkdocs_template.yml\"\\n        print(f\"Path is: {mkdocs_template_path.resolve()}\")\\n        assert mkdocs_template_path.exists()\\n\\n        ```\\n\\n    !!! note\\n\\n        The above docstring is autogenerated by docstring-gen library (https://github.com/airtai/docstring-gen)\\n    '\n</code></pre>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Code generator for FastStream</li> <li>Tutorials<ul> <li>Cryptocurrency analysis with FastStream</li> </ul> </li> <li>CLI<ul> <li>faststream_gen</li> </ul> </li> <li>Releases</li> </ul>"},{"location":"Tutorial/Cryptocurrency_Tutorial/","title":"Cryptocurrency analysis with FastStream","text":"<p>In this tutorial, we will walk you through the process of using the <code>faststream-gen</code> Python library to retrieve cryptocurrency prices in real time and calculate their moving average. To accomplish that, we will generate following two FastStream applications:</p> <ol> <li> <p>A microservice retrieving current cryptocurrency prices from an     external     web     service and publishing retrieved data to a Kafka topic.</p> </li> <li> <p>A microservice consuming such messages, calculating the moving     average price for each cryptocurrency and publishing it to another     Kafka topic.</p> </li> </ol> <p>You can watch a short version of the tutorial in the video below:</p> <p>Let\u2019s get started!</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#installation","title":"Installation","text":"<p>To complete this tutorial, you will need the following software and Python library:</p> <ol> <li> <p>Python     (version 3.8 and upward)</p> </li> <li> <p>a valid     OPENAI     API key</p> </li> <li> <p>[optional] github     account and installed     git command</p> </li> </ol> <p>It is recommended to use a virtual environment for your Python projects. Virtual environments are a common and effective Python development technique that helps to keep dependencies required by different projects separate by creating isolated Python environments for them.</p> <p>In this tutorial, we will be using Python\u2019s venv module to create a virtual environment.</p> <p>First, create a root directory for this tutorial. Navigate to the desired location and create a new directory called <code>faststream_gen_tutorial</code> and enter it.</p> <pre><code>mkdir faststream_gen_tutorial\ncd faststream_gen_tutorial\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#creating-and-activating-a-new-python-virtual-environment","title":"Creating and activating a new Python virtual environment","text":"<p>Create a new virtual environment using  venv:</p> <pre><code>python3 -m venv venv\n</code></pre> <p>Next, activate your new virtual environment:</p> <pre><code>source venv/bin/activate\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#installing-the-packages","title":"Installing the packages","text":"<p>Upgrade pip if needed and install <code>faststream-gen</code> package:</p> <pre><code>pip install --upgrade pip &amp;&amp; pip install faststream-gen\n</code></pre> <p>Check that the installation was successful by running the following command:</p> <pre><code>faststream_gen --help\n</code></pre> <p>You should see the full list of options of the command in the output.</p> <p>Now you have successfully set up the environment and installed the <code>faststream-gen</code> package.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#setting-up-openai-api-key","title":"Setting up OpenAI API key","text":"<p><code>faststream-gen</code> uses OpenAI API and you need to export your API key in environment variable <code>OPENAI_API_KEY</code>. If you use bash or compatible shell, you can do that with the following command:</p> <pre><code>export OPENAI_API_KEY=\"sk-your-openai-api-key\"\n</code></pre> <p>If you don\u2019t already have <code>OPENAI_API_KEY</code>, you can create one here.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#generating-faststream-applications","title":"Generating FastStream applications","text":""},{"location":"Tutorial/Cryptocurrency_Tutorial/#retrieving-and-publishing-crypto-prices","title":"Retrieving and publishing crypto prices","text":"<p>Now, we will create an application which retrieves information about current cryptocurrency prices from an external web service and publishes messages to a Kafka topic. In order to achieve this, we need to provide a high-level description of the application in plain English containing only the necessary information needed by a knowledgeable Python developer familiar with FastStream framework to implement it. This should include details such as the message schema, instructions on external API-s and web service, and guidance on selecting the appropriate topic and partition keys.</p> <p>Below is an example of such description used in this particular case. Notice that we did not specify steps needed to actually implement, we specified what the service should do, but not how to do it.</p> <pre><code>Create a FastStream application which will retrieve the current cryptocurrency\nprice and publish it to new_crypto_price topic. \n\nThe application should retrieve the data every 2 seconds.\n\nA message which will be produced is JSON with the two attributes:\n- price: non-negative float (current price of cryptocurrency in USD)\n- crypto_currency: string (the cryptocurrency e.g. BTC, ETH...)\n\nThe current price of Bitcoin can be retrieved by a simple GET request to:\n    - https://api.coinbase.com/v2/prices/BTC-USD/spot\n\nThe current price of Ethereum can be retrieved by a simple GET request to:\n    - https://api.coinbase.com/v2/prices/ETH-USD/spot\n\nThe response of this GET request is a JSON and you can get information about\nthe crypto_currency in:\n    response['data']['base']\n\nand the information about the price in:\n    response['data']['amount']\n\nUse utf-8 encoded crypto_currency attribute as a partition key when publishing\nthe message to new_crypto_price topic.\n</code></pre> <p>Let\u2019s generate a new <code>FastStream</code> project inside the <code>retrieve-publish-crypto</code> directory. First, copy the previous description and paste it into a file called <code>description_retrieve_publish.txt</code>.</p> <p>Next, run the following command (parameter <code>-i</code> specifies the file path for the app description file, while the parameter <code>-o</code> specifies the directory where the generated project files will be saved):</p> <pre><code>faststream_gen -i description_retrieve_publish.txt -o retrieve-publish-crypto\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n \u2714 Application description validated. \n \u2714 FastStream app skeleton code generated. \n \u2714 The app and the tests are generated. \n \u2714 New FastStream project created. \n \u2714 Integration tests were successfully completed. \n Tokens used: 36938\n Total Cost (USD): $0.11436\n\u2728  All files were successfully generated!\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#failed-generation","title":"Failed generation","text":"<p>The generation process is not bullet proof and it could fail with a meesage like this:</p> <pre><code>\u2728  Generating a new FastStream application!\n \u2714 Application description validated. \n \u2714 New FastStream project created. \n \u2714 FastStream app skeleton code generated. \n \u2718 Error: Failed to generate a valid application and test code. \n \u2718 Error: Integration tests failed.\n Tokens used: 79384\n Total Cost (USD): $0.24567\n\n\nApologies, we couldn't generate a working application and test code from your application description.\n\nPlease run the following command to start manual debugging:\n\ncd retrieve_without_logs &amp;&amp; pytest\n\nFor in-depth debugging, check the retrieve-publish-crypto/_faststream_gen_logs directory for complete logs, including individual step information.\n</code></pre> <p>There can be a number of reasons for that, the most common being:</p> <ul> <li> <p>The specification you provided was not sufficiently detailed to   generate the application. In such cases, you could try to add more   detailed instructions and try again.</p> </li> <li> <p>The task is too difficult for default GPT-3.5 model to handle and you   could try to use GPT-4 instead:</p> </li> </ul> <pre><code>faststream_gen --model gpt-4 -i description_retrieve_publish.txt -o retrieve-publish-crypto\n</code></pre> <ul> <li>You were unlucky and you just need to execute the command again. Large   language models are stohastic in their nature and they always give   different answers to the same questions. There are retry mechanisms in   the engine, but sometimes they are not enough and just rerunning the   command can mediate the problem.</li> </ul> <p>If none of the above strategies work, check the already generated files and look what the potential problem could be. You can also finish the implementation or tests yourself.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#successful-generation","title":"Successful generation","text":"<p>If successful, the command will generate <code>FastStream</code> project with the following structure:</p> <pre><code>retrieve-publish-crypto\n\u251c\u2500\u2500 .github\n\u2502   \u2514\u2500\u2500 workflows\n\u2502       \u251c\u2500\u2500 build_docker.yml\n\u2502       \u251c\u2500\u2500 deploy_docs.yml\n\u2502       \u2514\u2500\u2500 test.yml\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 app\n\u2502   \u2514\u2500\u2500 application.py\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 scripts\n\u2502   \u251c\u2500\u2500 build_docker.sh\n\u2502   \u251c\u2500\u2500 lint.sh\n\u2502   \u251c\u2500\u2500 services.yml\n\u2502   \u251c\u2500\u2500 start_kafka_broker_locally.sh\n\u2502   \u251c\u2500\u2500 static-analysis.sh\n\u2502   \u251c\u2500\u2500 stop_kafka_broker_locally.sh\n\u2502   \u2514\u2500\u2500 subscribe_to_kafka_broker_locally.sh\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 test_application.py\n</code></pre> <p>The generated application is located in the <code>app/</code> directory, while the tests are located in the <code>tests/</code> directory. It is important to keep in mind that these files are generated by LLM and may vary with each generation.</p> <p><code>app/application.py</code>:</p> <pre><code>import asyncio\nimport json\nfrom datetime import datetime\n\nimport aiohttp\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(\n        ..., examples=[50000.0], description=\"Current price of cryptocurrency in USD\"\n    )\n    crypto_currency: str = Field(\n        ..., examples=[\"BTC\"], description=\"The cryptocurrency\"\n    )\n\npublisher = broker.publisher(\"new_crypto_price\")\n\nasync def fetch_crypto_price(\n    url: str, crypto_currency: str, logger: Logger, context: ContextRepo, time_interval: int = 2\n) -&gt; None:\n    # Always use context: ContextRepo for storing app_is_running variable\n    while context.get(\"app_is_running\"):\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url) as response:\n                if response.status == 200:\n                    data = await response.json()\n                    price = data[\"data\"][\"amount\"]\n                    new_crypto_price = CryptoPrice(\n                        price=price, crypto_currency=crypto_currency\n                    )\n                    await publisher.publish(\n                        new_crypto_price,\n                        key=crypto_currency.encode(\"utf-8\"),\n                    )\n                else:\n                    logger.warning(\n                        f\"Failed API request {url} at time {datetime.now()}\"\n                    )\n\n        await asyncio.sleep(time_interval)\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    context.set_global(\"app_is_running\", True)\n\n\n@app.on_shutdown\nasync def shutdown(context: ContextRepo):\n    context.set_global(\"app_is_running\", False)\n\n    # Get all the running tasks and wait them to finish\n    fetch_tasks = context.get(\"fetch_tasks\")\n    await asyncio.gather(*fetch_tasks)\n\n\n@app.after_startup\nasync def publish_crypto_price(logger: Logger, context: ContextRepo):\n    logger.info(\"Starting publishing:\")\n\n    cryptocurrencies = [(\"Bitcoin\", \"BTC\"), (\"Ethereum\", \"ETH\")]\n    fetch_tasks = [\n        asyncio.create_task(\n            fetch_crypto_price(\n                f\"https://api.coinbase.com/v2/prices/{crypto_currency}-USD/spot\",\n                crypto_currency,\n                logger,\n                context,\n            )\n        )\n        for _, crypto_currency in cryptocurrencies\n    ]\n    # you need to save asyncio tasks so you can wait them to finish at app shutdown (the function with @app.on_shutdown function)\n    context.set_global(\"fetch_tasks\", fetch_tasks)\n</code></pre> <p><code>tests/test_application.py</code>:</p> <pre><code>import pytest\n\nfrom faststream import Context, TestApp\nfrom faststream.kafka import TestKafkaBroker\n\nfrom app.application import CryptoPrice, app, broker\n\n\n@broker.subscriber(\"new_crypto_price\")\nasync def on_new_crypto_price(\n    msg: CryptoPrice, key: bytes = Context(\"message.raw_message.key\")\n):\n    pass\n\n\n@pytest.mark.asyncio\nasync def test_fetch_crypto_price():\n    async with TestKafkaBroker(broker):\n        async with TestApp(app):\n            await on_new_crypto_price.wait_call(2)\n            on_new_crypto_price.mock.assert_called()\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#creating-a-new-python-virtual-environment","title":"Creating a new Python virtual environment","text":"<p>All the required dependencies to run the newly generated FastStream project are located within the <code>pyproject.toml</code> file.</p> <p>Create and activate a new virtual environment inside the <code>retrieve-publish-crypto</code> directory by using  venv:</p> <pre><code>cd retrieve-publish-crypto\npython3 -m venv venv\nsource venv/bin/activate\n</code></pre> <p>Upgrade pip if needed and install the development dependencies:</p> <pre><code>pip install --upgrade pip &amp;&amp; pip install -e .[dev]\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#testing-the-application","title":"Testing the application","text":"<p>In order to verify functional correctness of the application, it is recommended to execute the generated unit and integration test by running the <code>pytest</code> command.</p> <pre><code>pytest\n</code></pre> <pre><code>============================= test session starts ==============================\nplatform linux -- Python 3.10.8, pytest-7.4.2, pluggy-1.3.0\nrootdir: /workspaces/faststream-gen/docs_src/tutorial/retrieve-publish-crypto\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, asyncio-0.21.1\nasyncio: mode=strict\ncollected 1 item\n\ntests/test_application.py .                                              [100%]\n\n============================== 1 passed in 2.98s ===============================\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#previewing-asyncapi-docs","title":"Previewing AsyncAPI Docs","text":"<p>To preview AsyncAPI Docs for the application, execute the following command:</p> <pre><code>faststream docs serve app.application:app\n</code></pre> <pre><code>INFO:     Started server process [3575270]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n</code></pre> <p>You can now access the AsyncAPI Docs by opening localhost:8000 in your browser.</p> <p></p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#starting-localhost-kafka-broker","title":"Starting localhost Kafka broker","text":"<p>To run the <code>FastStream</code> application locally, ensure that you have a running Kafka broker. You can start a Kafka Docker container by executing the <code>start_kafka_broker_locally.sh</code> shell script:</p> <pre><code>./scripts/start_kafka_broker_locally.sh\n</code></pre> <pre><code>[+] Running 2/2\n \u283f Network scripts_default  Created                                                                                                             0.1s\n \u283f Container bitnami_kafka  Started \n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#starting-the-application","title":"Starting the application","text":"<p>To start the application, execute the following command:</p> <pre><code>faststream run app.application:app\n</code></pre> <pre><code>2023-09-15 13:41:21,948 INFO     - FastStream app starting...\n2023-09-15 13:41:22,144 INFO     -      |            - Starting publishing:\n2023-09-15 13:41:22,144 INFO     - FastStream app started successfully! To exit press CTRL+C\nTopic new_crypto_price not found in cluster metadata\n</code></pre> <p>Ensure that the app remains running, it is needed for the subsequent steps.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#calculating-the-moving-average","title":"Calculating the moving average","text":"<p>Let\u2019s develop an application that calculates the average price of the three most recent messages received from the <code>new_crypto_price</code> topic for each cryptocurrency. Subsequently, we will publish the computed average price to the <code>price_mean</code> topic.</p> <p>Here is the full description of the desired application:</p> <pre><code>Create a FastStream application for consuming messages\nfrom the new_crypto_price topic. \n\nThis topic needs to use a partition key.\n\nnew_crypto_price messages use JSON with two attributes \n(create class CryptoPrice with these attributes):\n- price: non-negative float (it represents the current price of the crypto)\n- crypto_currency: string (it represents the cryptocurrency e.g. BTC, ETH...)\n\nThe application should save each message to a dictionary (global variable) \n- partition key should be used as a dictionary key \n  and value should be a List of prices.\n\nKeep only the last 100 messages in the dictionary.\n\nIf there are fewer than 3 messages for a given partition key,\ndo not publish any messages.\n\nOtherwise, Calculate the price mean of the last 3 messages\nfor the given partition key.\n\nPublish the price mean to the price_mean topic and use \nthe same partition key that the new_crypto_price topic is using.\n</code></pre> <p>Please open a new terminal and navigate to the root directory of this tutorial, which is called <code>faststream_gen_tutorial</code>. Once you are inside the <code>faststream_gen_tutorial</code> folder, please activate the virtual environment.</p> <pre><code>cd path_to/faststream_gen_tutorial\n</code></pre> <pre><code>source venv/bin/activate\n</code></pre> <p>To create a <code>faststream</code> application inside the <code>calculate-mean-app</code> directory, first copy the previous description and paste it into the <code>description_calculate_mean.txt</code> file.</p> <p>Next, run the following command:</p> <pre><code>faststream_gen -i description_calculate_mean.txt -o calculate-mean-app\n</code></pre> <pre><code>\u2728  Generating a new FastStream application!\n \u2714 Application description validated. \n \u2714 FastStream app skeleton code generated. \n \u2714 The app and the tests are generated. \n \u2714 New FastStream project created. \n \u2714 Integration tests were successfully completed. \n Tokens used: 13367\n Total Cost (USD): $0.04147\n\u2728  All files were successfully generated!\n</code></pre> <p>If successful, the command will generate <code>calculate-mean-app</code> directory with <code>app/application.py</code> and <code>tests/test_application.py</code> inside. If not, just rerun the command again until it succeds.</p> <p><code>app/application.py</code>:</p> <pre><code>from typing import Dict, List\n\nfrom pydantic import BaseModel, Field, NonNegativeFloat\n\nfrom faststream import Context, ContextRepo, FastStream, Logger\nfrom faststream.kafka import KafkaBroker\n\n\nclass CryptoPrice(BaseModel):\n    price: NonNegativeFloat = Field(\n        ..., examples=[50000], description=\"Current price of the cryptocurrency\"\n    )\n    crypto_currency: str = Field(\n        ..., examples=[\"BTC\"], description=\"Cryptocurrency symbol\"\n    )\n\n\nbroker = KafkaBroker(\"localhost:9092\")\napp = FastStream(broker)\n\n\npublisher = broker.publisher(\"price_mean\")\n\n\n@app.on_startup\nasync def app_setup(context: ContextRepo):\n    message_history: Dict[str, List[float]] = {}\n    context.set_global(\"message_history\", message_history)\n\n\n@broker.subscriber(\"new_crypto_price\")\nasync def on_new_crypto_price(\n    msg: CryptoPrice,\n    logger: Logger,\n    message_history: Dict[str, List[float]] = Context(),\n    key: bytes = Context(\"message.raw_message.key\"),\n) -&gt; None:\n    logger.info(f\"New crypto price {msg=}\")\n\n    crypto_key = key.decode(\"utf-8\")\n    if crypto_key not in message_history:\n        message_history[crypto_key] = []\n\n    message_history[crypto_key].append(msg.price)\n\n    if len(message_history[crypto_key]) &gt; 100:\n        message_history[crypto_key] = message_history[crypto_key][-100:]\n\n    if len(message_history[crypto_key]) &gt;= 3:\n        price_mean = sum(message_history[crypto_key][-3:]) / 3\n        await publisher.publish(price_mean, key=key)\n</code></pre> <p><code>tests/test_application.py</code>:</p> <pre><code>import pytest\n\nfrom faststream import Context, TestApp\nfrom faststream.kafka import TestKafkaBroker\n\nfrom app.application import CryptoPrice, app, broker, on_new_crypto_price\n\n\n@broker.subscriber(\"price_mean\")\nasync def on_price_mean(msg: float, key: bytes = Context(\"message.raw_message.key\")):\n    pass\n\n\n@pytest.mark.asyncio\nasync def test_app():\n    async with TestKafkaBroker(broker):\n        async with TestApp(app):\n            await broker.publish(\n                CryptoPrice(price=50000, crypto_currency=\"BTC\"),\n                \"new_crypto_price\",\n                key=b\"BTC\",\n            )\n            on_new_crypto_price.mock.assert_called_with(\n                dict(CryptoPrice(price=50000, crypto_currency=\"BTC\"))\n            )\n            on_price_mean.mock.assert_not_called()\n\n            await broker.publish(\n                CryptoPrice(price=60000, crypto_currency=\"BTC\"),\n                \"new_crypto_price\",\n                key=b\"BTC\",\n            )\n            on_new_crypto_price.mock.assert_called_with(\n                dict(CryptoPrice(price=60000, crypto_currency=\"BTC\"))\n            )\n            on_price_mean.mock.assert_not_called()\n\n            await broker.publish(\n                CryptoPrice(price=70000, crypto_currency=\"BTC\"),\n                \"new_crypto_price\",\n                key=b\"BTC\",\n            )\n            on_new_crypto_price.mock.assert_called_with(\n                dict(CryptoPrice(price=70000, crypto_currency=\"BTC\"))\n            )\n            on_price_mean.mock.assert_called_with(60000.0)\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#creating-a-new-python-virtual-environment_1","title":"Creating a new Python virtual environment","text":"<p>All the required dependencies to run the newly generated FastStream project are located within the <code>pyproject.toml</code> file. Create a new virtual environment and install the development dependencies for the project.</p> <p>Create and activate a new virtual environment inside the <code>calculate-mean-app</code> directory by using  venv:</p> <pre><code>cd calculate-mean-app\npython3 -m venv venv\nsource venv/bin/activate\n</code></pre> <p>Upgrade pip if needed and install the development dependencies:</p> <pre><code>pip install --upgrade pip &amp;&amp; pip install -e .[dev]\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#testing-the-application_1","title":"Testing the application","text":"<p>In order to verify functional correctness of the application, it is recommended to execute the generated unit and integration test by running the <code>pytest</code> command.</p> <pre><code>pytest\n</code></pre> <pre><code>============================= test session starts ==============================\nplatform linux -- Python 3.10.8, pytest-7.4.2, pluggy-1.3.0\nrootdir: /workspaces/faststream-gen/docs_src/tutorial/calculate-mean-app\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, asyncio-0.21.1\nasyncio: mode=strict\ncollected 1 item\n\ntests/test_application.py .                                              [100%]\n\n============================== 1 passed in 0.64s ===============================\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#previewing-asyncapi-docs_1","title":"Previewing AsyncAPI Docs","text":"<p>To preview AsyncAPI Docs for the application, execute the following command:</p> <pre><code>faststream docs serve app.application:app\n</code></pre> <pre><code>INFO:     Started server process [3596205]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\nINFO:     Uvicorn running on http://localhost:8000 (Press CTRL+C to quit)\n</code></pre> <p>You can now access the AsyncAPI Docs by opening localhost:8000 in your browser.</p> <p></p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#starting-the-application_1","title":"Starting the application","text":"<p>To start the application, execute the following command:</p> <pre><code>faststream run app.application:app\n</code></pre> <pre><code>2023-10-04 09:31:18,926 INFO     - FastStream app starting...\n2023-10-04 09:31:18,948 INFO     - new_crypto_price |            - `OnNewCryptoPrice` waiting for messages\nTopic new_crypto_price not found in cluster metadata\n2023-10-04 09:31:19,069 INFO     - FastStream app started successfully! To exit, press CTRL+C\n2023-10-04 09:31:40,876 INFO     - new_crypto_price | 0-16964047 - Received\n2023-10-04 09:31:40,878 INFO     - new_crypto_price | 0-16964047 - New crypto price msg=CryptoPrice(price=27414.085, crypto_currency='BTC')\n2023-10-04 09:31:40,878 INFO     - new_crypto_price | 0-16964047 - Processed\n2023-10-04 09:31:40,878 INFO     - new_crypto_price | 1-16964047 - Received\n2023-10-04 09:31:40,879 INFO     - new_crypto_price | 1-16964047 - New crypto price msg=CryptoPrice(price=1642.425, crypto_currency='ETH')\n2023-10-04 09:31:40,879 INFO     - new_crypto_price | 1-16964047 - Processed\n2023-10-04 09:31:43,053 INFO     - new_crypto_price | 2-16964047 - Received\n2023-10-04 09:31:43,054 INFO     - new_crypto_price | 2-16964047 - New crypto price msg=CryptoPrice(price=27414.085, crypto_currency='BTC')\n2023-10-04 09:31:43,054 INFO     - new_crypto_price | 2-16964047 - Processed\n2023-10-04 09:31:43,054 INFO     - new_crypto_price | 3-16964047 - Received\n2023-10-04 09:31:43,055 INFO     - new_crypto_price | 3-16964047 - New crypto price msg=CryptoPrice(price=1642.425, crypto_currency='ETH')\n...\n</code></pre> <p>You can see in the terminal that the application is reading the messages from the <code>new_crypto_price</code> topic. Ensure that the app remains running as it is needed for the next step.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#subscribing-directly-to-local-kafka-broker-topic","title":"Subscribing directly to local Kafka broker topic","text":"<p>Open the new terminal, navigate to the <code>calculate-mean-app</code> directory.</p> <p>To check if the <code>calculate-mean-app</code> is publishing messages to the <code>price_mean</code> topic, run the following command:</p> <pre><code>./scripts/subscribe_to_kafka_broker_locally.sh price_mean\n</code></pre> <pre><code>BTC     26405.745\nETH     1621.3733333333332\nBTC     26404.865\nETH     1621.375\nBTC     26404.865\n...\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#stopping-kafka-broker","title":"Stopping Kafka broker","text":"<p>To stop the Kafka broker after analyzing the mean price of cryptocurrencies, you can execute the following command:</p> <pre><code>./scripts/stop_kafka_broker_locally.sh\n</code></pre> <pre><code>[+] Running 2/2\n \u283f Container bitnami_kafka  Removed                                                                            1.2s\n \u283f Network scripts_default  Removed \n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#optional-github-integration","title":"[Optional] GitHub integration","text":"<p>To successfully complete this optional tutorial chapter, make sure you have a GitHub account and the Git command installed. Additionally, ensure that your authentication for GitHub is properly set.</p> <p>We need to create two GitHub repositories, one for the <code>FastStream</code> project in the <code>retrieve-publish-crypto</code> directory and another for the <code>FastStream</code> project in the <code>calculate-mean-app</code> directory. In this chapter, we will upload the <code>FastStream</code> project to GitHub, which includes the <code>retrieve-publish-crypto</code> project. We will also provide an explanation of the generated CI workflows.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#adding-locally-hosted-code-to-github","title":"Adding locally hosted code to GitHub","text":"<p>To create a GitHub repository, click on the following link. For the <code>Repository name</code>, use <code>retrieve-publish-crypto</code> and click on <code>Create repository</code>.</p> <p></p> <p>Please open your development environment and go to the <code>retrieve-publish-crypto</code> directory that was generated in the previous steps.</p> <pre><code>cd path_to/faststream_gen_tutorial/retrieve-publish-crypto\n</code></pre> <p>Next, execute the following commands:</p> <pre><code>git init\ngit add .\ngit commit -m \"Retrieve and publish crypto prices application implemented\"\ngit branch -M main\n</code></pre> <p>If you are using HTTPS authentication execute (replace the <code>git_username</code> in the URL with your own GitHub username):</p> <p><code>git remote add origin https://github.com/git_username/retrieve-publish-crypto.git</code></p> <p>If you are using SSH authentication execute (replace the <code>git_username</code> in the URL with your own GitHub username):</p> <p><code>git remote add origin git@github.com:git_username/retrieve-publish-crypto.git</code></p> <p>To update the remote branch with local commits, execute:</p> <pre><code>git push -u origin main\n</code></pre>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#continuous-integration-with-github-actions","title":"Continuous integration with GitHub Actions","text":"<p>Once the changes are pushed, CI pipeline will run the tests again, create and publish the documentation and build Docker container with the application.</p> <p>To verify the passing status of the CI, open your web browser, go to the newly created GitHub repository, and click on the Actions tab.</p> <p></p> <p>The tests executed with <code>pytest</code> are passing successfully. </p> <p>The Docker image has been successfully built and pushed to the GitHub Container registry under the repository <code>ghcr.io/your_username/retrieve-publish-crypto</code></p> <p></p> <p>The AsyncAPI docs have been successfully generated and deployed to GitHub Pages.</p> <p></p> <p>After the successful execution of the <code>Deploy FastStream AsyncAPI Docs</code> workflow, a new branch named <code>gh-pages</code> will be created. To access the GitHub Pages settings, navigate to the <code>Settings -&gt; Pages</code>, select the <code>gh-pages</code> branch as the designated branch for hosting the GitHub Pages and click on <code>Save</code>.</p> <p> </p> <p>By setting up a branch on GitHub Pages, a new workflow will automatically be triggered within the GitHub Actions. To access this workflow, simply click on the <code>Actions</code> tab and open the <code>pages build and deployment</code> workflow.</p> <p></p> <p>Once all the jobs within the workflow are completed, you can click on the provided URL to conveniently view and explore the AsyncAPI Docs that have been generated for your application.</p> <p></p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#repeat","title":"Repeat","text":"<p>Repeat the same process with <code>calculate-mean-app</code> project.</p>"},{"location":"Tutorial/Cryptocurrency_Tutorial/#next-steps","title":"Next steps","text":"<p>Congratulations! You have successfully completed this tutorial and gained a new set of skills. Now that you have learned how to use <code>faststream-gen</code>, try it out with your own example!</p>"},{"location":"api/faststream_gen/cli/generate_fastkafka_app/","title":"Generate fastkafka app","text":""},{"location":"api/faststream_gen/cli/generate_fastkafka_app/#faststream_gen.cli.generate_fastkafka_app","title":"<code>faststream_gen.cli.generate_fastkafka_app(description: Optional[str] = typer.Argument(None, help='Summarize your FastStream application in a few sentences!\\n\\n\\n\\nInclude details about messages, topics, servers, and a brief overview of the intended business logic.\\n\\n\\n\\nThe simpler and more specific the app description is, the better the generated app will be. Please refer to the below example for inspiration:\\n\\n\\n\\nCreate a FastStream application using localhost broker for testing and use the default port number. \\nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: \\'data\\'. \\nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the \\'output_data\\' topic.\\n\\n'), input_path: str = typer.Option(None, '--input_file', '-i', help='\\n        The path to the file with the app desription. This path should be relative to the current working directory.\\n \\n \\n\\nIf the app description is passed via both a --input_file and a command line argument, the description from the command line will be used to create the application.\\n        '), output_path: str = typer.Option('.', '--output_path', '-o', help='The path to the output directory where the generated project files will be saved. This path should be relative to the current working directory.'), model: OpenAIModel = typer.Option(OpenAIModel.gpt3.value, '--model', '-m', help=f'The OpenAI model that will be used to create the FastStream project. For better results, we recommend using '{OpenAIModel.gpt4.value}'.'), verbose: bool = typer.Option(False, '--verbose', '-v', help='Enable verbose logging by setting the logger level to INFO.'), save_log_files: bool = typer.Option(False, '--dev', '-d', help='Save the complete logs generated by faststream-gen inside the output_path directory.')) -&gt; None</code>","text":"<p>Effortlessly create a new FastStream project based on the app description.</p> Source code in <code>faststream_gen/cli.py</code> <pre><code>@app.command(\n    \"generate\",\n    help=\"Effortlessly create a new FastStream project based on the app description.\",\n)\n@set_logger_level\ndef generate_fastkafka_app(\n    description: Optional[str] = typer.Argument(\n        None,\n        help=\"\"\"Summarize your FastStream application in a few sentences!\n\n\n\\nInclude details about messages, topics, servers, and a brief overview of the intended business logic.\n\n\n\\nThe simpler and more specific the app description is, the better the generated app will be. Please refer to the below example for inspiration:\n\n\n\\nCreate a FastStream application using localhost broker for testing and use the default port number. \nIt should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \nFor each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n\\n\"\"\",\n    ),\n    input_path: str = typer.Option(\n        None,\n        \"--input_file\",\n        \"-i\",\n        help=\"\"\"\n        The path to the file with the app desription. This path should be relative to the current working directory.\n\n        \\n\\nIf the app description is passed via both a --input_file and a command line argument, the description from the command line will be used to create the application.\n        \"\"\",\n    ),\n    output_path: str = typer.Option(\n        \".\",\n        \"--output_path\",\n        \"-o\",\n        help=\"The path to the output directory where the generated project files will be saved. This path should be relative to the current working directory.\",\n    ),\n    model: OpenAIModel = typer.Option(\n        OpenAIModel.gpt3.value,\n        \"--model\",\n        \"-m\",\n        help=f\"The OpenAI model that will be used to create the FastStream project. For better results, we recommend using '{OpenAIModel.gpt4.value}'.\",\n    ),\n    verbose: bool = typer.Option(\n        False,\n        \"--verbose\",\n        \"-v\",\n        help=\"Enable verbose logging by setting the logger level to INFO.\",\n    ),\n    save_log_files: bool = typer.Option(\n        False,\n        \"--dev\",\n        \"-d\",\n        help=\"Save the complete logs generated by faststream-gen inside the output_path directory.\",\n    ),\n) -&gt; None:\n    \"\"\"Effortlessly create a new FastStream project based on the app description.\"\"\"\n    logger.info(\"Project generation started.\")\n    try:\n        tokens_list: List[Dict[str, int]] = []\n        ensure_openai_api_key_set()\n\n        # Step 1: Validate description\n        validated_description, tokens_list = _validate_app_description(\n            description, input_path, model, tokens_list\n        )\n\n        # Step 2: Project creation\n        create_project(output_path)\n\n        # Step 3: Get relevant application examples\n        prompt_examples = get_relevant_prompt_examples(validated_description)\n\n        # Step 4: Generate application skeleton\n        tokens_list, is_valid_skeleton_code = generate_app_skeleton(\n            validated_description,\n            output_path,\n            model.value,\n            tokens_list,\n            prompt_examples[\"description_to_skeleton\"],\n        )\n        if is_valid_skeleton_code:\n            # Step 5: Generate application and test code only if previous step is successful\n            tokens_list, is_valid_app_code = generate_app_and_test(\n                validated_description,\n                model.value,\n                output_path,\n                tokens_list,\n                prompt_examples[\"skeleton_to_app_and_test\"],\n            )\n            if is_valid_app_code:\n                # Step 5: Generate application and test code only if previous step is successful\n                (\n                    tokens_list,\n                    is_requirements_file_valid,\n                ) = fix_requirements_and_run_tests(\n                    output_path, model.value, tokens_list\n                )\n\n        if not is_valid_skeleton_code:\n            is_valid_app_code = False\n            typer.secho(\" \u2718 Error: Failed to generate a valid application and test code.\", fg=typer.colors.RED)\n            typer.secho(\" \u2718 Error: Integration tests failed.\", fg=typer.colors.RED)\n\n        elif not is_valid_app_code:\n            typer.secho(\" \u2718 Error: Integration tests failed.\", fg=typer.colors.RED)\n\n    except (ValueError, KeyError) as e:\n        fg = typer.colors.RED\n        typer.secho(e, err=True, fg=fg)\n        raise typer.Exit(code=1)\n    except Exception as e:\n        fg = typer.colors.RED\n        typer.secho(f\"Unexpected internal error: {e}\", err=True, fg=fg)\n        raise typer.Exit(code=1)\n    finally:\n        total_tokens_usage = add_tokens_usage(tokens_list)\n        price = _calculate_price(total_tokens_usage, model.value)\n\n        fg = typer.colors.CYAN\n        typer.secho(f\" Tokens used: {total_tokens_usage['total_tokens']}\", fg=fg)\n        logger.info(f\"Prompt Tokens: {total_tokens_usage['prompt_tokens']}\")\n        logger.info(f\"Completion Tokens: {total_tokens_usage['completion_tokens']}\")\n        typer.secho(f\" Total Cost (USD): ${round(price, 5)}\", fg=fg)\n\n    if (\n        (not is_valid_skeleton_code)\n        or (not is_valid_app_code)\n        or (not is_requirements_file_valid)\n    ):\n        if output_path == \".\":\n            test_cmd = \"pytest\"\n            logs_dir = LOGS_DIR_NAME\n        else:\n            test_cmd = f\"cd {output_path} &amp;&amp; pytest\"\n            logs_dir = f\"{output_path}/{LOGS_DIR_NAME}\"\n        typer.secho(\n            f\"\"\"\\n\\n{INCOMPLETE_APP_ERROR_MSG}\n\n{test_cmd}\n\nFor in-depth debugging, check the {logs_dir} directory for complete logs, including individual step information.\n\"\"\",\n            fg=typer.colors.RED,\n        )\n    else:\n        if not save_log_files:\n            shutil.rmtree(f\"{output_path}/{LOGS_DIR_NAME}\")\n        typer.secho(\"\u2728  All files were successfully generated!\", fg=fg)\n</code></pre>"},{"location":"cli/faststream_gen/","title":"<code>faststream_gen</code>","text":"<p>Effortlessly create a new FastStream project based on the app description.</p> <p>Usage:</p> <pre><code>$ faststream_gen [OPTIONS] [DESCRIPTION]\n</code></pre> <p>Arguments:</p> <ul> <li><code>[DESCRIPTION]</code>: Summarize your FastStream application in a few sentences!</li> </ul> <p>Include details about messages, topics, servers, and a brief overview of the intended business logic.</p> <p>The simpler and more specific the app description is, the better the generated app will be. Please refer to the below example for inspiration:</p> <p>Create a FastStream application using localhost broker for testing and use the default port number.  It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'.  For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.</p> <p>Options:</p> <ul> <li><code>-i, --input_file TEXT</code>:         The path to the file with the app desription. This path should be relative to the current working directory.</li> </ul> <p>If the app description is passed via both a --input_file and a command line argument, the description from the command line will be used to create the application.</p> <ul> <li><code>-o, --output_path TEXT</code>: The path to the output directory where the generated project files will be saved. This path should be relative to the current working directory.  [default: .]</li> <li><code>-m, --model [gpt-3.5-turbo-16k|gpt-4]</code>: The OpenAI model that will be used to create the FastStream project. For better results, we recommend using 'gpt-4'.  [default: gpt-3.5-turbo-16k]</li> <li><code>-v, --verbose</code>: Enable verbose logging by setting the logger level to INFO.</li> <li><code>-d, --dev</code>: Save the complete logs generated by faststream-gen inside the output_path directory.</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"}]}