{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _code_generator.constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6196d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3de9f5",
   "metadata": {},
   "source": [
    "## Code generation constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "APPLICATION_FILE_PATH = \"app/application.py\"\n",
    "TEST_FILE_PATH = \"tests/test_application.py\"\n",
    "TOML_FILE_NAME = \"pyproject.toml\"\n",
    "LOGS_DIR_NAME = \"_faststream_gen_logs\"\n",
    "\n",
    "STEP_LOG_DIR_NAMES = {\n",
    "    \"skeleton\": \"app-skeleton-generation-logs\",\n",
    "    \"app\": \"app-and-test-generation-logs\",\n",
    "    \"requirements\": \"requirements-generation-logs\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4f3e6d",
   "metadata": {},
   "source": [
    "## Model constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b526dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "MAX_RESTARTS = 3\n",
    "MAX_ASYNC_SPEC_RETRIES = 3\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "class OpenAIModel(str, Enum):\n",
    "    gpt3 = \"gpt-3.5-turbo-16k\"\n",
    "    gpt4 = \"gpt-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48343ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "actual = OpenAIModel.gpt4.value\n",
    "print(actual)\n",
    "assert actual == \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3bb434",
   "metadata": {},
   "source": [
    "## Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "TOKEN_TYPES = [\"prompt_tokens\", \"completion_tokens\", \"total_tokens\"]\n",
    "\n",
    "MODEL_PRICING = {\n",
    "    OpenAIModel.gpt4.value: {\n",
    "        \"input\": 0.03,\n",
    "        \"output\": 0.06\n",
    "    },\n",
    "    OpenAIModel.gpt3.value: {\n",
    "        \"input\": 0.003,\n",
    "        \"output\": 0.004\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82922",
   "metadata": {},
   "source": [
    "## Error responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b64b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "OPENAI_KEY_EMPTY_ERROR = \"Error: OPENAI_API_KEY cannot be empty. Please set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again.\\nYou can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "OPENAI_KEY_NOT_SET_ERROR = \"Error: OPENAI_API_KEY not found in environment variables. Set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "\n",
    "EMPTY_DESCRIPTION_ERROR = \"Error: you need to provide the application description by providing it with the command line argument or by providing it within a textual file wit the --input_file argument.\"\n",
    "\n",
    "\n",
    "\n",
    "INCOMPLETE_DESCRIPTION = \"\"\"Please check if your application description is missing some crucial information:\n",
    "- Description of the messages that will be produced or consumed\n",
    "- At least one topic\n",
    "- The business logic to implement while consuming or producing the messages\n",
    "\"\"\"\n",
    "DESCRIPTION_EXAMPLE = \"\"\"\n",
    "If you're unsure about how to construct the app description, consider the following example for guidance\n",
    "\n",
    "APPLICATION DESCRIPTION EXAMPLE:\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "MAX_NUM_FIXES_MSG = \"Maximum number of retries\"\n",
    "\n",
    "INCOMPLETE_APP_ERROR_MSG = \"\"\"Apologies, we couldn't generate a working application and test code from your application description.\n",
    "\n",
    "Please run the following command to start manual debugging:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fdc29",
   "metadata": {},
   "source": [
    "## FastKafka docs archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f5f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_GEN_REPO_ZIP_URL = \"http://github.com/airtai/faststream-gen/archive/main.zip\"\n",
    "FASTSTREAM_GEN_EXAMPLES_DIR_SUFFIX = \"faststream-gen-main/search/examples\"\n",
    "\n",
    "FASTSTREAM_REPO_ZIP_URL = \"http://github.com/airtai/faststream/archive/main.zip\"\n",
    "FASTSTREAM_ROOT_DIR_NAME = \"faststream-main\"\n",
    "FASTSTREAM_DOCS_DIR_SUFFIX = \".faststream_gen\"\n",
    "FASTSTREAM_EN_DOCS_DIR = \"docs/docs/en\"\n",
    "\n",
    "FASTSTREAM_EXAMPLE_FILES = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "FASTSTREAM_TMP_DIR_PREFIX = \"appended_examples\"\n",
    "FASTSTREAM_DIR_TO_EXCLUDE = \"api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22be41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "STAT_0o775 = ( stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR\n",
    "             | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP\n",
    "             | stat.S_IROTH |                stat.S_IXOTH )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a403855",
   "metadata": {},
   "source": [
    "## FastStream template archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_TEMPLATE_ZIP_URL = \"http://github.com/airtai/faststream-template/archive/main.zip\"\n",
    "FASTSTREAM_TEMPLATE_DIR_SUFFIX = \"faststream-template-main\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
