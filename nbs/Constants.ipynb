{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _code_generator.constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf4fb1",
   "metadata": {},
   "source": [
    "## Model constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "MAX_RESTARTS = 3\n",
    "MAX_ASYNC_SPEC_RETRIES = 3\n",
    "\n",
    "\n",
    "\n",
    "class OpenAIModel(str, Enum):\n",
    "    gpt3 = \"gpt-3.5-turbo-16k\"\n",
    "    gpt4 = \"gpt-4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f906d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "actual = OpenAIModel.gpt4.value\n",
    "print(actual)\n",
    "assert actual == \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41226606",
   "metadata": {},
   "source": [
    "## Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "TOKEN_TYPES = [\"prompt_tokens\", \"completion_tokens\", \"total_tokens\"]\n",
    "\n",
    "MODEL_PRICING = {\n",
    "    OpenAIModel.gpt4.value: {\n",
    "        \"input\": 0.03,\n",
    "        \"output\": 0.06\n",
    "    },\n",
    "    OpenAIModel.gpt3.value: {\n",
    "        \"input\": 0.003,\n",
    "        \"output\": 0.004\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82922",
   "metadata": {},
   "source": [
    "## Error responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b64b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "OPENAI_KEY_EMPTY_ERROR = \"Error: OPENAI_API_KEY cannot be empty. Please set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again.\\nYou can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "OPENAI_KEY_NOT_SET_ERROR = \"Error: OPENAI_API_KEY not found in environment variables. Set a valid OpenAI API key in OPENAI_API_KEY environment variable and try again. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\"\n",
    "\n",
    "EMPTY_DESCRIPTION_ERROR = \"Error: you need to provide the application description by providing it with the command line argument or by providing it within a textual file wit the --input_file argument.\"\n",
    "\n",
    "\n",
    "\n",
    "INCOMPLETE_DESCRIPTION = \"\"\"Please check if your application description is missing some crucial information:\n",
    "- Description of the messages that will be produced or consumed\n",
    "- At least one topic\n",
    "- The business logic to implement while consuming or producing the messages\n",
    "\"\"\"\n",
    "DESCRIPTION_EXAMPLE = \"\"\"\n",
    "If you're unsure about how to construct the app description, consider the following example for guidance\n",
    "\n",
    "APPLICATION DESCRIPTION EXAMPLE:\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "MAX_NUM_FIXES_MSG = \"Maximum number of retries\"\n",
    "\n",
    "INCOMPLETE_APP_ERROR_MSG = \"\"\"Apologies, we couldn't generate a working application and test code from your application description.\n",
    "\n",
    "Please run the following command to start manual debugging:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669422f",
   "metadata": {},
   "source": [
    "## FastKafka docs archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb880705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_REPO_ZIP_URL = \"http://github.com/airtai/faststream/archive/main.zip\"\n",
    "FASTSTREAM_DOCS_DIR_SUFFIX = \"faststream-main/.faststream_gen\"\n",
    "FASTSTREAM_EXAMPLES_DIR_SUFFIX = \"faststream-main/faststream_gen_examples\"\n",
    "FASTSTREAM_EXAMPLE_FILES = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "FASTSTREAM_TMP_DIR_PREFIX = \"appended_examples\"\n",
    "FASTSTREAM_DIR_TO_EXCLUDE = \"api\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c8275",
   "metadata": {},
   "source": [
    "## FastStream template archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e14fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_TEMPLATE_ZIP_URL = \"http://github.com/airtai/faststream-template/archive/main.zip\"\n",
    "FASTSTREAM_TEMPLATE_DIR_SUFFIX = \"faststream-template-main\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
