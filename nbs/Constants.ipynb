{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _code_generator.constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d03be5",
   "metadata": {},
   "source": [
    "## Code generation constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16084f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bb7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DESCRIPTION_FILE_NAME = \"app_description.txt\"\n",
    "APPLICATION_SKELETON_FILE_NAME = \"application_skeleton.py\"\n",
    "ASYNC_API_SPEC_FILE_NAME = \"asyncapi.yml\"\n",
    "APPLICATION_FILE_NAME = \"application.py\"\n",
    "INTEGRATION_TEST_FILE_NAME = \"test.py\"\n",
    "INTERMEDIATE_RESULTS_DIR_NAME = \"_faststream_gen_tmp\"\n",
    "\n",
    "GENERATE_APP_FROM_ASYNCAPI = \"generate_app_from_asyncapi\"\n",
    "GENERATE_APP_FROM_SKELETON = \"generate_app_from_skeleton\"\n",
    "GENERATE_APP_SKELETON = \"generate_app_skeleton\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd81bf4",
   "metadata": {},
   "source": [
    "## Model constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e897799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "DEFAULT_PARAMS = {\n",
    "    \"temperature\": 0.7,\n",
    "}\n",
    "\n",
    "MAX_RETRIES = 5\n",
    "MAX_ASYNC_SPEC_RETRIES = 3\n",
    "\n",
    "\n",
    "\n",
    "class OpenAIModel(str, Enum):\n",
    "    gpt3 = \"gpt-3.5-turbo-16k\"\n",
    "    gpt4 = \"gpt-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db338d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "actual = OpenAIModel.gpt4.value\n",
    "print(actual)\n",
    "assert actual == \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d885ed0",
   "metadata": {},
   "source": [
    "## Pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cf1c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "TOKEN_TYPES = [\"prompt_tokens\", \"completion_tokens\", \"total_tokens\"]\n",
    "\n",
    "MODEL_PRICING = {\n",
    "    OpenAIModel.gpt4.value: {\n",
    "        \"input\": 0.03,\n",
    "        \"output\": 0.06\n",
    "    },\n",
    "    OpenAIModel.gpt3.value: {\n",
    "        \"input\": 0.003,\n",
    "        \"output\": 0.004\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82922",
   "metadata": {},
   "source": [
    "## Error responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b64b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "INCOMPLETE_DESCRIPTION = \"Please check if your application description is missing some crutial information:\\n - Description of the messages which will be produced/consumed\\n - At least one topic\\n - The business logic to implement while consuming/producing the messages\\n\"\n",
    "DESCRIPTION_EXAMPLE = \"\"\"\n",
    "If you're unsure about how to construct the app description, consider the following example for guidance\n",
    "\n",
    "APPLICATION DESCRIPTION EXAMPLE:\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "MAX_NUM_FIXES_MSG = \"Maximum number of retries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5781085",
   "metadata": {},
   "source": [
    "## FastKafka docs archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd37c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_REPO_ZIP_URL = \"http://github.com/airtai/fastkafka/archive/FastStream.zip\"\n",
    "FASTSTREAM_DOCS_DIR_SUFFIX = \"fastkafka-FastStream/.faststream_gen\"\n",
    "FASTSTREAM_EXAMPLES_DIR_SUFFIX = \"fastkafka-FastStream/faststream_gen_examples\"\n",
    "FASTSTREAM_EXAMPLE_FILES = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "FASTSTREAM_TMP_DIR_PREFIX = \"appended_examples\"\n",
    "FASTSTREAM_DIR_TO_EXCLUDE = \"api\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c23d39d",
   "metadata": {},
   "source": [
    "## FastStream template archive url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf895c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "FASTSTREAM_TEMPLATE_ZIP_URL = \"http://github.com/airtai/faststream-gen-template/archive/main.zip\"\n",
    "FASTSTREAM_TEMPLATE_DIR_SUFFIX = \"faststream-gen-template-main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a62ee69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
