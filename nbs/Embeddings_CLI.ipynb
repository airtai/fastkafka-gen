{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61148947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac610120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *\n",
    "import shutil\n",
    "from tempfile import TemporaryDirectory\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader, TextLoader\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from yaspin import yaspin\n",
    "import typer\n",
    "\n",
    "\n",
    "from faststream_gen._code_generator.constants import (\n",
    "    FASTSTREAM_REPO_ZIP_URL,\n",
    "    FASTSTREAM_DOCS_DIR_SUFFIX,\n",
    "    FASTSTREAM_EXAMPLES_DIR_SUFFIX,\n",
    "    FASTSTREAM_EXAMPLE_FILES,\n",
    "    FASTSTREAM_TMP_DIR_PREFIX,\n",
    "    FASTSTREAM_DIR_TO_EXCLUDE\n",
    ")\n",
    "from faststream_gen._components.package_data import get_root_data_path\n",
    "from faststream_gen._code_generator.helper import download_and_extract_faststream_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25510bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typer.testing import CliRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66739f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _create_documents(\n",
    "    extrated_path: Path,\n",
    "    extension: str = \"**/*.md\",\n",
    "    dir_to_exclude: str = FASTSTREAM_DIR_TO_EXCLUDE,\n",
    ") -> List[Document]:\n",
    "    \"\"\"Create a List of Document objects from files.\n",
    "\n",
    "    Args:\n",
    "        extracted_path (Path): The path to the directory containing the files to be\n",
    "            loaded as documents.\n",
    "        extension (str, optional): The file extension pattern to match. Defaults to\n",
    "            \"**/*.md\" to match Markdown files in all subdirectories.\n",
    "        dir_to_exclude (str, optional): Directory to exclude while creating the document object\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of documents created from the loaded files.\n",
    "    \"\"\"\n",
    "    api_directory = extrated_path / dir_to_exclude\n",
    "    if api_directory.exists() and api_directory.is_dir():\n",
    "        shutil.rmtree(api_directory)\n",
    "\n",
    "    loader_cls = TextLoader if extension == \"*.txt\" else UnstructuredMarkdownLoader\n",
    "    loader = DirectoryLoader(str(extrated_path), glob=extension, loader_cls=loader_cls) # type: ignore\n",
    "    docs = loader.load()\n",
    "\n",
    "    typer.echo(\"\\nBelow files are included in the embeddings:\")\n",
    "    typer.echo(\n",
    "        \"\\n\".join(\n",
    "            [\n",
    "                f'    - {d.metadata[\"source\"].replace(f\"{extrated_path}/\", \"\")}'\n",
    "                for d in docs\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760eaf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below files are included in the embeddings:\n",
      "    - sample.md\n",
      "    - a_guide_path/a_guide_path.md\n",
      "2\n",
      "Create a FastStream application using localhost broker for testing and use the default port number. \n",
      "It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object\n"
     ]
    }
   ],
   "source": [
    "fixture_description = \"\"\"\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    input_path = Path(d) / \"input_path\"\n",
    "    input_path.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = Path(d) / \"output_path\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    api_path = Path(d) / \"input_path\" / \"api\"\n",
    "    api_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    a_guide_path = Path(d) / \"input_path\" / \"a_guide_path\"\n",
    "    a_guide_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{a_guide_path}/a_guide_path.md\", \"w\") as f:\n",
    "        f.write(fixture_description)\n",
    "    \n",
    "    with open(f\"{api_path}/api.md\", \"w\") as f:\n",
    "        f.write(fixture_description)\n",
    "    \n",
    "    with open(f\"{input_path}/sample.md\", \"w\") as f:\n",
    "        f.write(fixture_description)\n",
    "        \n",
    "    with open(f\"{input_path}/sample.txt\", \"w\") as f:\n",
    "        f.write(fixture_description)\n",
    "    \n",
    "    docs = _create_documents(input_path)\n",
    "\n",
    "    print(len(docs))\n",
    "    assert len(docs) == 2\n",
    "    assert isinstance(docs[0], Document)\n",
    "\n",
    "    print(docs[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "def _split_document_into_chunks(\n",
    "    documents: List[Document],\n",
    "    separator: str,\n",
    "    chunk_size: int = 500,\n",
    "    chunk_overlap: int = 0,\n",
    ") -> List[Document]:\n",
    "    \"\"\"Split the list of documents into chunks\n",
    "\n",
    "    Args:\n",
    "        documents: List of documents to be split into chunks.\n",
    "        separators: List of separator patterns used for chunking.\n",
    "        chunk_size: The maximum size of each chunk in characters. Defaults to 1500.\n",
    "        chunk_overlap: The overlap between consecutive chunks in characters. Defaults to 150.\n",
    "\n",
    "    Returns:\n",
    "        A list of documents where each document represents a chunk.\n",
    "    \"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separator=separator\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "doc_chunks = _split_document_into_chunks(docs, \"\\n\\n\")\n",
    "print(len(doc_chunks))\n",
    "assert len(doc_chunks) >= len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e02a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "def _save_embeddings_db(doc_chunks: List[Document], db_path: Path) -> None:\n",
    "    \"\"\"Save the embeddings in a FAISS db\n",
    "    \n",
    "    Args:\n",
    "        doc_chunks: A list of documents where each document represents a chunk.\n",
    "        db_path: Path to save the FAISS db.\n",
    "    \"\"\"\n",
    "    db = FAISS.from_documents(doc_chunks, OpenAIEmbeddings())\n",
    "    db.save_local(str(db_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cdb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\r\n",
      "drwx------ 3 harish harish 4096 Sep 14 06:47 .\r\n",
      "drwxrwxrwt 1 root   root   4096 Sep 14 06:47 ..\r\n",
      "drwxrwxr-x 2 harish harish 4096 Sep 14 06:47 faiss_index\r\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    db_path = Path(d) /\"faiss_index\"\n",
    "    _save_embeddings_db(docs, db_path)\n",
    "    \n",
    "    !ls -la {d}\n",
    "    assert (Path(d) / \"faiss_index\" / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _delete_directory(d: str) -> None:\n",
    "    \"\"\"Delete a directory and its contents if it exists.\n",
    "\n",
    "    Args:\n",
    "        directory_path: The path to the directory to be deleted.\n",
    "    \"\"\"\n",
    "    d_path = Path(d)\n",
    "    if d_path.exists():\n",
    "        try:\n",
    "            shutil.rmtree(d_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cb0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12\n",
      "drwx------ 3 harish harish 4096 Sep 14 06:47 .\n",
      "drwxrwxrwt 1 root   root   4096 Sep 14 06:47 ..\n",
      "drwxrwxr-x 2 harish harish 4096 Sep 14 06:47 some_dir\n",
      "total 8\n",
      "drwx------ 2 harish harish 4096 Sep 14 06:47 .\n",
      "drwxrwxrwt 1 root   root   4096 Sep 14 06:47 ..\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    some_dir = Path(f\"{d}/some_dir\")\n",
    "    some_dir.mkdir()\n",
    "    assert some_dir.exists()\n",
    "    !ls -la {d}\n",
    "\n",
    "    _delete_directory(str(some_dir))\n",
    "    assert not some_dir.exists()\n",
    "    \n",
    "    non_existing_dir = Path(f\"{d}/non_existing_dir\")\n",
    "    _delete_directory(str(non_existing_dir))\n",
    "    !ls -la {d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _generate_docs_db(input_path: Path, output_path: Path) -> None:\n",
    "    \"\"\"Generate Document Embeddings Database.\n",
    "\n",
    "    This function creates document embeddings for a collection of documents\n",
    "    located in the specified input directory and saves the embeddings database\n",
    "    to the specified output directory.\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): The path to the directory containing input documents.\n",
    "        output_path (Path): The path to the directory where the embeddings\n",
    "            database will be saved.\n",
    "    \"\"\"\n",
    "    with yaspin(\n",
    "        text=\"Creating embeddings for the docs...\", color=\"cyan\", spinner=\"clock\"\n",
    "    ) as sp:\n",
    "        docs = _create_documents(input_path)\n",
    "        _save_embeddings_db(docs, output_path)\n",
    "\n",
    "        sp.text = \"\"\n",
    "        sp.ok(f\" ✔ Docs embeddings created and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da979f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating embeddings for the docs...\n",
      "Below files are included in the embeddings:\n",
      "    - sample.md\n",
      "⠹ Creating embeddings for the docs... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harish/.local/lib/python3.11/site-packages/yaspin/core.py:119: UserWarning: color, on_color and attrs are not supported when running in jupyter\n",
      "  self._color = self._set_color(color) if color else color\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✔ Docs embeddings created and saved to: /tmp/tmptlgmw25u/output_path \n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    input_path = Path(d) / \"input_path\"\n",
    "    input_path.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = Path(d) / \"output_path\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(f\"{input_path}/sample.md\", \"w\") as f:\n",
    "        f.write(\"# Hello world!\")\n",
    "    \n",
    "    _generate_docs_db(input_path, output_path)\n",
    "    \n",
    "    assert (output_path / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdace36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _check_all_files_exist(d: Path, required_files: List[str]) -> bool:\n",
    "    \"\"\"Check if all required files exist in a directory.\n",
    "\n",
    "    Args:\n",
    "        d (Path): The path to the directory where the existence of files will\n",
    "            be checked.\n",
    "        required_files (List[str]): A list of filenames that should exist in\n",
    "            the directory.\n",
    "\n",
    "    Returns:\n",
    "        True if all required files exist in the directory, False otherwise.\n",
    "    \"\"\"\n",
    "    return all((d / file_name).exists() for file_name in required_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8ea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    required_files = ['description.txt', 'app_skeleton.py']\n",
    "    \n",
    "    with open(f\"{d}/description.txt\", \"w\") as f:\n",
    "        f.write(\"description.txt\")\n",
    "        \n",
    "    with open(f\"{d}/app_skeleton.py\", \"w\") as f:\n",
    "        f.write(\"app_skeleton.py\")\n",
    "        \n",
    "    \n",
    "    actual = _check_all_files_exist(Path(d), required_files)\n",
    "    print(actual)\n",
    "    assert actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "    \n",
    "    with open(f\"{d}/description.txt\", \"w\") as f:\n",
    "        f.write(\"description.txt\")\n",
    "        \n",
    "    with open(f\"{d}/app_skeleton.py\", \"w\") as f:\n",
    "        f.write(\"app_skeleton.py\")\n",
    "        \n",
    "    \n",
    "    actual = _check_all_files_exist(Path(d), required_files)\n",
    "    print(actual)\n",
    "    assert not actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dadd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _append_file_contents(d: Path, parent_d: Path, required_files: List[str]) -> None:\n",
    "    \"\"\"Append contents of specified files to a result file.\n",
    "\n",
    "    This function appends the contents of the specified list of files to a\n",
    "    result file in a designated directory.\n",
    "\n",
    "    Args:\n",
    "        d (Path): The path to the directory containing the files to be appended.\n",
    "        parent_d (Path): The parent directory where the result file will be created.\n",
    "        required_files (List[str]): A list of filenames to be appended.\n",
    "    \"\"\"\n",
    "    appended_examples_dir = parent_d / FASTSTREAM_TMP_DIR_PREFIX\n",
    "    appended_examples_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    result_file_name = appended_examples_dir / f\"{d.name}.txt\"\n",
    "\n",
    "    with result_file_name.open(\"a\") as result_file:\n",
    "        for file_name in required_files:\n",
    "            with (d / file_name).open(\"r\") as file:\n",
    "                result_file.write(\n",
    "                    f\"==== {file_name} starts ====\\n{file.read()}\\n==== {file_name} ends ====\\n\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03281b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== description.txt starts ====\n",
      "\n",
      "Create a FastStream application using localhost broker for testing and use the default port number. \n",
      "It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
      "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
      "\n",
      "==== description.txt ends ====\n",
      "==== app_skeleton.py starts ====\n",
      "app_skeleton.py\n",
      "==== app_skeleton.py ends ====\n",
      "==== app.py starts ====\n",
      "app.py\n",
      "==== app.py ends ====\n",
      "==== test_app.py starts ====\n",
      "test_app.py\n",
      "==== test_app.py ends ====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixture_description = \"\"\"\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "def _create_example_structure(directory: Path, required_files: List[str]):\n",
    "    for file_name in required_files:\n",
    "        if file_name == \"description.txt\":\n",
    "            with open(directory / file_name, \"w\") as f:\n",
    "                f.write(fixture_description)\n",
    "        else:\n",
    "            with open(directory / file_name, \"w\") as f:\n",
    "                f.write(file_name)\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "    \n",
    "    example_1 = Path(d) / \"example_1\"\n",
    "    example_1.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    _create_example_structure(example_1, required_files)\n",
    "        \n",
    "    for directory in Path(d).iterdir():\n",
    "        _append_file_contents(directory, Path(d), required_files)\n",
    "        \n",
    "    with open(f\"{d}/{FASTSTREAM_TMP_DIR_PREFIX}/example_1.txt\", \"r\") as f:\n",
    "        actual = f.read()\n",
    "        \n",
    "    print(actual)\n",
    "    expected = f\"\"\"==== description.txt starts ====\n",
    "{fixture_description}\n",
    "==== description.txt ends ====\n",
    "==== app_skeleton.py starts ====\n",
    "app_skeleton.py\n",
    "==== app_skeleton.py ends ====\n",
    "==== app.py starts ====\n",
    "app.py\n",
    "==== app.py ends ====\n",
    "==== test_app.py starts ====\n",
    "test_app.py\n",
    "==== test_app.py ends ====\n",
    "\"\"\"\n",
    "    \n",
    "    assert actual == expected    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c83ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _format_examples(input_path: Path, required_files: List[str]) -> None:\n",
    "    \"\"\"Format Examples by Appending File Contents.\n",
    "\n",
    "    This function iterates through directories in the specified input path and checks\n",
    "    if all the required files exist in each directory. If the required files are present,\n",
    "    it appends their contents to a result file within the input path. If any of the\n",
    "    required files are missing, it skips the directory and logs a message.\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): The path to the directory containing example directories\n",
    "            with files to be appended.\n",
    "        required_files (List[str]): A list of filenames that must exist in each example\n",
    "            directory.\n",
    "    \"\"\"\n",
    "    for directory in input_path.iterdir():\n",
    "        if directory.is_dir() and _check_all_files_exist(directory, required_files):\n",
    "            _append_file_contents(directory, input_path, required_files)\n",
    "        else:\n",
    "            typer.echo(f\"\\nRequired files are missing. Skipping directory: {directory}\")\n",
    "\n",
    "\n",
    "def _generate_examples_db(\n",
    "    input_path: Path,\n",
    "    output_path: Path,\n",
    "    required_files: List[str] = FASTSTREAM_EXAMPLE_FILES,\n",
    ") -> None:\n",
    "    \"\"\"Generate Example Embeddings Database.\n",
    "\n",
    "    This function creates embeddings for a collection of example documents located in\n",
    "    the specified input directory and saves the embeddings database to the specified\n",
    "    output directory. It appends the contents of specified files in each example\n",
    "    directory, splits the concatenated document into chunks based on specified\n",
    "    separators, and saves the embeddings for each chunk in the output database.\n",
    "\n",
    "    Args:\n",
    "        input_path (Path): The path to the directory containing example documents.\n",
    "        output_path (Path): The path to the directory where the embeddings database\n",
    "            will be saved.\n",
    "        required_files (List[str]): A list of filenames that must exist in each\n",
    "            example directory. Defaults to FASTSTREAM_EXAMPLE_FILES.\n",
    "    \"\"\"\n",
    "    with yaspin(\n",
    "        text=\"Creating embeddings for the examples...\", color=\"cyan\", spinner=\"clock\"\n",
    "    ) as sp:\n",
    "        \n",
    "        _format_examples(input_path, required_files)\n",
    "        docs = _create_documents(\n",
    "            input_path / FASTSTREAM_TMP_DIR_PREFIX, extension=\"*.txt\"\n",
    "        )\n",
    "        doc_chunks = _split_document_into_chunks(\n",
    "            docs, separator=\"==== description.txt ends ====\"\n",
    "        )\n",
    "        _save_embeddings_db(doc_chunks, output_path)\n",
    "\n",
    "        sp.text = \"\"\n",
    "        sp.ok(f\" ✔ Examples embeddings created and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c4bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating embeddings for the examples...\n",
      "Required files are missing. Skipping directory: /tmp/tmpc8tgvqwh/output_path\n",
      "\n",
      "Below files are included in the embeddings:\n",
      "    - example_1.txt\n",
      " ✔ Examples embeddings created and saved to: /tmp/tmpc8tgvqwh/output_path \n"
     ]
    }
   ],
   "source": [
    "required_files = ['description.txt', 'app_skeleton.py', 'app.py', 'test_app.py']\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    example_1 = Path(d) / \"example_1\"\n",
    "    example_1.mkdir(parents=True, exist_ok=True)\n",
    "    _create_example_structure(example_1, required_files)\n",
    "    \n",
    "    output_path = Path(d) / \"output_path\"\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    _generate_examples_db(Path(d), output_path)\n",
    "    \n",
    "    assert (output_path / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d25487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "app = typer.Typer(\n",
    "    short_help=\"Download the zipped FastKafka documentation markdown files, generate embeddings, and save them in a vector database.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89faebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@app.command(\n",
    "    \"generate\",\n",
    "    help=\"Download the docs and examples from FastStream repo, generate embeddings, and save them in a vector database.\",\n",
    ")\n",
    "def generate(\n",
    "    db_path: str = typer.Option(\n",
    "        get_root_data_path(),\n",
    "        \"--db_path\",\n",
    "        \"-p\",\n",
    "        help=\"The path to save the vector database.\",\n",
    "    )\n",
    ") -> None:\n",
    "    typer.echo(\n",
    "        f\"Downloading files docs and examples from FastStream repo and generating embeddings.\"\n",
    "    )\n",
    "\n",
    "    with download_and_extract_faststream_archive(\n",
    "        FASTSTREAM_REPO_ZIP_URL\n",
    "    ) as extracted_path:\n",
    "        try:\n",
    "            _delete_directory(db_path)\n",
    "            _generate_docs_db(\n",
    "                extracted_path / FASTSTREAM_DOCS_DIR_SUFFIX, Path(db_path) / \"docs\"\n",
    "            )\n",
    "            _generate_examples_db(\n",
    "                extracted_path / FASTSTREAM_EXAMPLES_DIR_SUFFIX,\n",
    "                Path(db_path) / \"examples\",\n",
    "            )\n",
    "\n",
    "            typer.echo(\n",
    "                f\"\\nSuccessfully generated all the embeddings and saved to: {db_path}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            fg = typer.colors.RED\n",
    "            typer.secho(f\"Unexpected internal error: {e}\", err=True, fg=fg)\n",
    "            raise typer.Exit(code=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a35b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">                                                                                                                   </span>\n",
       "<span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Usage: </span><span style=\"font-weight: bold\">generate [OPTIONS]                                                                                         </span>\n",
       "<span style=\"font-weight: bold\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m                                                                                                                   \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mgenerate [OPTIONS]\u001b[0m\u001b[1m                                                                                        \u001b[0m\u001b[1m \u001b[0m\n",
       "\u001b[1m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Download the docs and examples from FastStream repo, generate embeddings, and save them in a vector database.     \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       " Download the docs and examples from FastStream repo, generate embeddings, and save them in a vector database.     \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">╭─ Options ───────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--db_path</span>             <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">-p</span>      <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TEXT</span>  The path to save the vector database.                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[default: /work/fastkafka-gen/faststream_gen/package_data]</span>                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--install-completion</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Install completion for the current shell.                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--show-completion</span>             <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Show completion for the current shell, to copy it or customize the          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>                                     installation.                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--help</span>                        <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Show this message and exit.                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m──────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-db_path\u001b[0m             \u001b[1;32m-p\u001b[0m      \u001b[1;33mTEXT\u001b[0m  The path to save the vector database.                                       \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m                                     \u001b[2m[default: /work/fastkafka-gen/faststream_gen/package_data]\u001b[0m                  \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m          \u001b[1;33m    \u001b[0m  Install completion for the current shell.                                   \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m             \u001b[1;33m    \u001b[0m  Show completion for the current shell, to copy it or customize the          \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m                                     installation.                                                               \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                        \u001b[1;33m    \u001b[0m  Show this message and exit.                                                 \u001b[2m│\u001b[0m\n",
       "\u001b[2m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner = CliRunner()\n",
    "result = runner.invoke(app, [\"generate\", \"--help\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552aca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-09-14 06:48:02.072 [WARNING] langchain.text_splitter: Created a chunk of size 619, which is longer than the specified 500\n",
      "23-09-14 06:48:02.073 [WARNING] langchain.text_splitter: Created a chunk of size 505, which is longer than the specified 500\n",
      "23-09-14 06:48:02.074 [WARNING] langchain.text_splitter: Created a chunk of size 1475, which is longer than the specified 500\n",
      "Downloading files docs and examples from FastStream repo and generating embeddings.\n",
      "⠋ Creating embeddings for the docs... \n",
      "Below files are included in the embeddings:\n",
      "    - features.md\n",
      "    - CONTRIBUTING.md\n",
      "    - contact.md\n",
      "    - index.md\n",
      "    - release.md\n",
      "    - kafka/publishing.md\n",
      "    - kafka/batch.md\n",
      "    - kafka/index.md\n",
      "    - kafka/message.md\n",
      "    - kafka/subscription.md\n",
      "    - integrations/index.md\n",
      "    - integrations/fastapi/index.md\n",
      "    - integrations/frameworks/index.md\n",
      "    - getting-started/logging.md\n",
      "    - getting-started/index.md\n",
      "    - getting-started/dependencies/sub.md\n",
      "    - getting-started/dependencies/global.md\n",
      "    - getting-started/dependencies/yield.md\n",
      "    - getting-started/dependencies/class.md\n",
      "    - getting-started/dependencies/index.md\n",
      "    - getting-started/dependencies/testing.md\n",
      "    - getting-started/context/fields.md\n",
      "    - getting-started/context/extra.md\n",
      "    - getting-started/context/existed.md\n",
      "    - getting-started/context/index.md\n",
      "    - getting-started/context/custom.md\n",
      "    - getting-started/cli/index.md\n",
      "    - getting-started/subscription/pydantic.md\n",
      "    - getting-started/subscription/index.md\n",
      "    - getting-started/subscription/annotation.md\n",
      "    - getting-started/subscription/filtering.md\n",
      "    - getting-started/subscription/test.md\n",
      "    - getting-started/asyncapi/gen_serve_asyncapi_docs.md\n",
      "    - getting-started/asyncapi/export.md\n",
      "    - getting-started/asyncapi/hosting.md\n",
      "    - getting-started/asyncapi/index.md\n",
      "    - getting-started/asyncapi/custom.md\n",
      "    - getting-started/integrations/index.md\n",
      "    - getting-started/integrations/fastapi/index.md\n",
      "    - getting-started/integrations/frameworks/index.md\n",
      "    - getting-started/serialization/protobuf.md\n",
      "    - getting-started/serialization/decoder.md\n",
      "    - getting-started/serialization/parser.md\n",
      "    - getting-started/serialization/index.md\n",
      "    - getting-started/serialization/examples.md\n",
      "    - getting-started/config/index.md\n",
      "    - getting-started/middlewares/index.md\n",
      "    - getting-started/publishing/object.md\n",
      "    - getting-started/publishing/decorator.md\n",
      "    - getting-started/publishing/direct.md\n",
      "    - getting-started/publishing/index.md\n",
      "    - getting-started/publishing/broker.md\n",
      "    - getting-started/publishing/test.md\n",
      "    - getting-started/routers/index.md\n",
      "    - getting-started/contributing/CONTRIBUTING.md\n",
      "    - getting-started/contributing/docs.md\n",
      "    - getting-started/lifespan/index.md\n",
      "    - getting-started/lifespan/test.md\n",
      "    - getting-started/lifespan/hooks.md\n",
      "    - guides/gen_serve_asyncapi_docs.md\n",
      "    - contributing/CONTRIBUTING.md\n",
      "    - contributing/docs.md\n",
      "    - rabbit/ack.md\n",
      "    - rabbit/publishing.md\n",
      "    - rabbit/index.md\n",
      "    - rabbit/declare.md\n",
      "    - rabbit/rpc.md\n",
      "    - rabbit/message.md\n",
      "    - rabbit/examples/headers.md\n",
      "    - rabbit/examples/direct.md\n",
      "    - rabbit/examples/stream.md\n",
      "    - rabbit/examples/index.md\n",
      "    - rabbit/examples/topic.md\n",
      "    - rabbit/examples/fanout.md\n",
      " ✔ Docs embeddings created and saved to: /tmp/tmpfkpdkx74/docs \n",
      "⠋ Creating embeddings for the examples...\n",
      "Required files are missing. Skipping directory: /tmp/tmpo17v006p/extrated_path/faststream-main/faststream_gen_examples/__init__.py\n",
      "\n",
      "Below files are included in the embeddings:\n",
      "    - example_new_employee.txt\n",
      "    - example_infinity_publishing.txt\n",
      "    - example_execute_trade.txt\n",
      "    - example_course_updates.txt\n",
      "    - example_student_query.txt\n",
      "    - example_investment_updates.txt\n",
      "    - example_log_msgs_with_plaintext_security.txt\n",
      "    - example_forward_to_multiple_topics.txt\n",
      "    - example_social_media_post.txt\n",
      "    - example_forward_with_security.txt\n",
      "    - example_pets.txt\n",
      "    - example_product_reviews.txt\n",
      "    - example_forward_to_another_topic.txt\n",
      "    - example_scram256_security.txt\n",
      "    - example_weather_updates.txt\n",
      "    - example_plants.txt\n",
      "    - example_scram512_security.txt\n",
      "    - example_scrape_weather.txt\n",
      " ✔ Examples embeddings created and saved to: /tmp/tmpfkpdkx74/examples \n",
      "\n",
      "Successfully generated all the embeddings and saved to: /tmp/tmpfkpdkx74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    db_path = f\"{d}\"\n",
    "    result = runner.invoke(app, [\"-p\", db_path])\n",
    "\n",
    "    print(result.output)\n",
    "    assert result.exit_code == 0\n",
    "    assert (Path(d) / \"docs\" / \"index.faiss\").exists()\n",
    "    assert (Path(d) / \"examples\" / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa637857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
