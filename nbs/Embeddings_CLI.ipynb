{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61148947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac610120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *\n",
    "import shutil\n",
    "import tarfile\n",
    "from tempfile import TemporaryDirectory\n",
    "import requests\n",
    "import functools\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader, DirectoryLoader\n",
    "from langchain.schema.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import typer\n",
    "\n",
    "\n",
    "from faststream_gen._code_generator.constants import FASTKAFKA_DOCS_MD_ARCHIVE_URL\n",
    "from faststream_gen._components.package_data import get_root_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25510bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typer.testing import CliRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _fetch_content(url: str) -> requests.models.Response:\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(\n",
    "            \"Request timed out. Please check your internet connection or try again later.\"\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html lang=\"en\" dir=\"ltr\" class=\"plugin-pages plugin-id-default\">\\n<head>\\n<meta charset=\"UTF-8\">\\n<meta name=\"generator\" content=\"Docusaurus v2.4.0\">\\n<title data-rh=\"true\">Effortless Kaf'\n"
     ]
    }
   ],
   "source": [
    "response = _fetch_content(\"https://fastkafka.airt.ai/\")\n",
    "print(response.content[:200])\n",
    "assert len(response.content) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66739f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _download_and_extract_website_archive(func: Callable) -> Callable:\n",
    "    \"\"\"Download the archive from the given url, extract the contents, and yields the extraction path.\n",
    "\n",
    "    Args:\n",
    "        func: The function to be wrapped.\n",
    "\n",
    "    Returns:\n",
    "        A decorator function that downloads the archive, extracts the contents, and yields the extraction path.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs): # type: ignore\n",
    "        with TemporaryDirectory() as d:            \n",
    "            input_path = Path(f\"{d}/archive.tar.gz\")\n",
    "            extrated_md_files_path = Path(f\"{d}/extrated_md_files_path\")\n",
    "            \n",
    "            response = _fetch_content(FASTKAFKA_DOCS_MD_ARCHIVE_URL)\n",
    "            \n",
    "            with open(input_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            with tarfile.open(input_path, \"r:gz\") as tar: # nosemgrep\n",
    "                # nosemgrep\n",
    "                tar.extractall(path=extrated_md_files_path) # nosec\n",
    "\n",
    "            return func(extrated_md_files_path, *args, **kwargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@_download_and_extract_website_archive\n",
    "def _create_documents(extrated_md_files_path: Path) -> List[Document]:\n",
    "    \"\"\"Create Document objects from markdown files in the given path.\n",
    "\n",
    "    Args:\n",
    "        extracted_md_files_path: Path to the extracted markdown files.\n",
    "\n",
    "    Returns:\n",
    "        A list of Document objects, one for each extracted markdown file.\n",
    "    \"\"\"\n",
    "    loader = DirectoryLoader(\n",
    "        str(extrated_md_files_path), glob=\"**/*.md\", loader_cls=UnstructuredMarkdownLoader\n",
    "    )\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760eaf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "Contributing to FastKafka\n",
      "\n",
      "First off, thanks for taking the time to contribute! ❤️\n",
      "\n",
      "All types of contributions are encouraged and valued. See the Table of Contents for different ways to help and detai\n"
     ]
    }
   ],
   "source": [
    "docs = _create_documents()\n",
    "\n",
    "print(len(docs))\n",
    "assert len(docs) > 0\n",
    "assert isinstance(docs[0], Document)\n",
    "\n",
    "print(docs[0].page_content[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "def _split_document_into_chunks(\n",
    "    documents: List[Document],\n",
    "    # Limiting the max token(input) limit to 8k to be on safer side. 1 token ~= 4 chars in English. We would like to retreive top 2 matches. \n",
    "    # so each matches can only have 8k / 2 = 4k tokens (~ 4 * 4 = 16,000 characters)    \n",
    "    # Note: chunk_size is the maximum allowed characters in each chunk. In reality not all the chunks will have 16k tokens, some will be much less than 16k.\n",
    "    # Reference: https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter\n",
    "    chunk_size: int = 16000,\n",
    "    chunk_overlap: int = 200, # 50 tokens\n",
    "    separators: List[str] = [\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"],\n",
    ") -> List[Document]:\n",
    "    \"\"\"Split the list of documents into chunks\n",
    "\n",
    "    Args:\n",
    "        documents: List of documents to be split into chunks.\n",
    "        chunk_size: The maximum size of each chunk in characters. Defaults to 1500.\n",
    "        chunk_overlap: The overlap between consecutive chunks in characters. Defaults to 150.\n",
    "        separators: List of separator patterns used for chunking. Defaults to [\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"].\n",
    "\n",
    "    Returns:\n",
    "        A list of documents where each document represents a chunk.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=separators\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2aef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "doc_chunks = _split_document_into_chunks(docs)\n",
    "print(len(doc_chunks))\n",
    "assert len(doc_chunks) > len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e02a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "\n",
    "def _save_embeddings_db(doc_chunks: List[Document], db_path: str) -> None:\n",
    "    \"\"\"Save the embeddings in a FAISS db\n",
    "    \n",
    "    Args:\n",
    "        doc_chunks: A list of documents where each document represents a chunk.\n",
    "        db_path: Path to save the FAISS db.\n",
    "    \"\"\"\n",
    "    db = FAISS.from_documents(doc_chunks, OpenAIEmbeddings()) # type: ignore\n",
    "    db.save_local(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617cdb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\r\n",
      "drwx------ 3 harish harish  4096 Sep  6 11:04 .\r\n",
      "drwxrwxrwt 1 root   root   12288 Sep  6 11:04 ..\r\n",
      "drwxrwxr-x 2 harish harish  4096 Sep  6 11:04 faiss_index\r\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    db_path = f\"{d}/faiss_index\"\n",
    "    _save_embeddings_db(doc_chunks, db_path)\n",
    "    \n",
    "    !ls -la {d}\n",
    "    assert (Path(d) / \"faiss_index\" / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1e06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _delete_directory(directory_path: Path) -> None:\n",
    "    \"\"\"Delete a directory and its contents if it exists.\n",
    "\n",
    "    Args:\n",
    "        directory_path: The path to the directory to be deleted.\n",
    "    \"\"\"\n",
    "    if directory_path.exists():\n",
    "        try:\n",
    "            shutil.rmtree(directory_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cb0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20\n",
      "drwx------ 3 harish harish  4096 Sep  6 11:04 .\n",
      "drwxrwxrwt 1 root   root   12288 Sep  6 11:04 ..\n",
      "drwxrwxr-x 2 harish harish  4096 Sep  6 11:04 some_dir\n",
      "total 16\n",
      "drwx------ 2 harish harish  4096 Sep  6 11:04 .\n",
      "drwxrwxrwt 1 root   root   12288 Sep  6 11:04 ..\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    some_dir = Path(f\"{d}/some_dir\")\n",
    "    some_dir.mkdir()\n",
    "    assert some_dir.exists()\n",
    "    !ls -la {d}\n",
    "\n",
    "    _delete_directory(some_dir)\n",
    "    assert not some_dir.exists()\n",
    "    \n",
    "    non_existing_dir = Path(f\"{d}/non_existing_dir\")\n",
    "    _delete_directory(non_existing_dir)\n",
    "    !ls -la {d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _get_default_vector_db_path() -> Path:\n",
    "    return get_root_data_path() / \"docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ca70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/fastkafka-gen/faststream_gen/package_data/docs\n"
     ]
    }
   ],
   "source": [
    "actual = _get_default_vector_db_path()\n",
    "print(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d25487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "app = typer.Typer(\n",
    "    short_help=\"Download the zipped FastKafka documentation markdown files, generate embeddings, and save them in a vector database.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89faebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@app.command(\n",
    "    \"generate\",\n",
    "    help=\"Download the zipped FastKafka documentation markdown files, generate embeddings, and save them in a vector database.\",\n",
    ")\n",
    "def generate(\n",
    "    db_path: str = typer.Option(\n",
    "        _get_default_vector_db_path(), \n",
    "        \"--db_path\",\n",
    "        \"-p\",\n",
    "        help=\"The path to save the vector database.\"\n",
    "    )\n",
    ") -> None:\n",
    "    try:\n",
    "        _delete_directory(Path(db_path))\n",
    "        \n",
    "        typer.echo(f\"Downloading the zipped FastKafka documentation markdown files and generating embeddings.\")\n",
    "        docs = _create_documents()\n",
    "        # Experimenting by commenting out chunking, so each guide will be treated as a single document and will be sent in its entirety along with the prompt.\n",
    "        # doc_chunks = _split_document_into_chunks(docs)\n",
    "        # _save_embeddings_db(doc_chunks, db_path)\n",
    "        _save_embeddings_db(docs, db_path)\n",
    "        \n",
    "        typer.echo(f\"\\nSuccessfully generated the embeddings and saved to: {db_path}\")\n",
    "    except Exception as e:\n",
    "        fg = typer.colors.RED\n",
    "        typer.secho(f\"Unexpected internal error: {e}\", err=True, fg=fg)\n",
    "        raise typer.Exit(code=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a35b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">                                                                                                                   </span>\n",
       "<span style=\"font-weight: bold\"> </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Usage: </span><span style=\"font-weight: bold\">generate [OPTIONS]                                                                                         </span>\n",
       "<span style=\"font-weight: bold\">                                                                                                                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m                                                                                                                   \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1mgenerate [OPTIONS]\u001b[0m\u001b[1m                                                                                        \u001b[0m\u001b[1m \u001b[0m\n",
       "\u001b[1m                                                                                                                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Download the zipped FastKafka documentation markdown files, generate embeddings, and save them in a vector        \n",
       " database.                                                                                                         \n",
       "                                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       " Download the zipped FastKafka documentation markdown files, generate embeddings, and save them in a vector        \n",
       " database.                                                                                                         \n",
       "                                                                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">╭─ Options ───────────────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--db_path</span>             <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">-p</span>      <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">TEXT</span>  The path to save the vector database.                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[default: /work/fastkafka-gen/faststream_gen/package_data/docs]</span>             <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--install-completion</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Install completion for the current shell.                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--show-completion</span>             <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Show completion for the current shell, to copy it or customize the          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>                                     installation.                                                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">--help</span>                        <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    </span>  Show this message and exit.                                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│</span>\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m╭─\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m──────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[2m─╮\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-db_path\u001b[0m             \u001b[1;32m-p\u001b[0m      \u001b[1;33mTEXT\u001b[0m  The path to save the vector database.                                       \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m                                     \u001b[2m[default: /work/fastkafka-gen/faststream_gen/package_data/docs]\u001b[0m             \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m          \u001b[1;33m    \u001b[0m  Install completion for the current shell.                                   \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m             \u001b[1;33m    \u001b[0m  Show completion for the current shell, to copy it or customize the          \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m                                     installation.                                                               \u001b[2m│\u001b[0m\n",
       "\u001b[2m│\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                        \u001b[1;33m    \u001b[0m  Show this message and exit.                                                 \u001b[2m│\u001b[0m\n",
       "\u001b[2m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runner = CliRunner()\n",
    "result = runner.invoke(app, [\"generate\", \"--help\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552aca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the zipped FastKafka documentation markdown files and generating embeddings.\n",
      "\n",
      "Successfully generated the embeddings and saved to: /tmp/tmpeqpun9g4/docs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    db_path = f\"{d}/docs\"\n",
    "    result = runner.invoke(app, [\"-p\", db_path])\n",
    "    \n",
    "    print(result.output)\n",
    "    assert result.exit_code == 0\n",
    "    assert (Path(d) / \"docs\" / \"index.faiss\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa637857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
