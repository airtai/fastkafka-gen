{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530d4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a9f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Create a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use the default port number. It should consume messages from 'receive_name' topic and the message will be a JSON encoded object with only one attribute: user_name. For each consumed message, construct a new message object and append 'Hello ' in front of the name attribute. Finally, publish the consumed message to 'send_greetings' topic.\n",
      "\n",
      "==== EXAMPLE SKELETON CODE ====\n",
      "\n",
      "from typing import *\n",
      "from pydantic import BaseModel, Field\n",
      "from fastkafka import FastKafka\n",
      "\n",
      "\n",
      "class Greetings(BaseModel):\n",
      "    user_name: str = Field(..., description=\"Name of the user.\")\n",
      "\n",
      "kafka_brokers = {\n",
      "    \"localhost\": {\n",
      "        \"url\": \"localhost\",\n",
      "        \"description\": \"local development kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    },\n",
      "    \"staging\": {\n",
      "        \"url\": \"staging.airt.ai\",\n",
      "        \"description\": \"staging kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    },\n",
      "    \"production\": {\n",
      "        \"url\": \"prod.airt.ai\",\n",
      "        \"description\": \"production kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    }\n",
      "}\n",
      "\n",
      "app_description = \"A FastKafka application that consumes messages from the 'receive_name' topic. Each message is a JSON-encoded object with only one attribute: 'user_name'. For each consumed message, the application constructs a new message object and appends 'Hello ' in front of the 'user_name' attribute. Finally, the application publishes the modified message to the 'send_greetings' topic.\"\n",
      "\n",
      "app = FastKafka(\n",
      "    kafka_brokers=kafka_brokers, \n",
      "    description=app_description, \n",
      "    title='Greet users',\n",
      ")\n",
      "\n",
      "\n",
      "consume_description = \"The application consumes messages from the 'receive_name' topic and constructs a new message object with 'Hello ' appended to the 'user_name' attribute.\"\n",
      "@app.consumes(topic=\"receive_name\", description=consume_description)\n",
      "async def on_receive_name(msg: Greetings):\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "publish_description = \"The application publishes the modified messages to the 'send_greetings' topic.\"\n",
      "@app.produces(topic=\"send_greetings\", description=publish_description)\n",
      "async def to_send_greetings(msg: Greetings) -> Greetings:\n",
      "    raise NotImplementedError()\n",
      "\n",
      "==== EXAMPLE APPLICATION CODE ====\n",
      "\n",
      "from typing import *\n",
      "from pydantic import BaseModel, Field\n",
      "from fastkafka import FastKafka\n",
      "\n",
      "\n",
      "class Greetings(BaseModel):\n",
      "    user_name: str = Field(..., description=\"Name of the user.\")\n",
      "\n",
      "kafka_brokers = {\n",
      "    \"localhost\": {\n",
      "        \"url\": \"localhost\",\n",
      "        \"description\": \"local development kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    },\n",
      "    \"staging\": {\n",
      "        \"url\": \"staging.airt.ai\",\n",
      "        \"description\": \"staging kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    },\n",
      "    \"production\": {\n",
      "        \"url\": \"prod.airt.ai\",\n",
      "        \"description\": \"production kafka broker\",\n",
      "        \"port\": 9092,\n",
      "    }\n",
      "}\n",
      "\n",
      "app_description = \"A FastKafka application that consumes messages from the 'receive_name' topic. Each message is a JSON-encoded object with only one attribute: 'user_name'. For each consumed message, the application constructs a new message object and appends 'Hello ' in front of the 'user_name' attribute. Finally, the application publishes the modified message to the 'send_greetings' topic.\"\n",
      "\n",
      "app = FastKafka(\n",
      "    kafka_brokers=kafka_brokers, \n",
      "    description=app_description, \n",
      "    title='Greet users',\n",
      ")\n",
      "\n",
      "\n",
      "consume_description = \"The application consumes messages from the 'receive_name' topic and constructs a new message object with 'Hello ' appended to the 'user_name' attribute.\"\n",
      "@app.consumes(topic=\"receive_name\", description=consume_description)\n",
      "async def on_receive_name(msg: Greetings):\n",
      "    msg = Greetings(user_name=f\"Hello {msg.user_name}\")\n",
      "    await to_send_greetings(msg)\n",
      "\n",
      "\n",
      "publish_description = \"The application publishes the modified messages to the 'send_greetings' topic.\"\n",
      "@app.produces(topic=\"send_greetings\", description=publish_description)\n",
      "async def to_send_greetings(msg: Greetings) -> Greetings:\n",
      "    return msg\n",
      "\n",
      "==== EXAMPLE TEST CODE ====\n",
      "\n",
      "import asyncio\n",
      "from fastkafka.testing import Tester\n",
      "try:\n",
      "    from .application import *\n",
      "except ImportError as e:\n",
      "    from application import *\n",
      "\n",
      "async def async_tests():\n",
      "    async with Tester(app) as tester:\n",
      "        input_msg = Greetings(user_name=\"John\")\n",
      "\n",
      "        # tester produces message to the receive_name topic\n",
      "        await tester.to_receive_name(input_msg)\n",
      "\n",
      "        # assert that app consumed from the receive_name topic and it was called with the accurate argument\n",
      "        await app.awaited_mocks.on_receive_name.assert_called_with(\n",
      "            input_msg, timeout=5\n",
      "        )\n",
      "\n",
      "        # assert that tester consumed from the send_greetings topic and it was called with the accurate argument\n",
      "        await tester.awaited_mocks.on_send_greetings.assert_called_with(\n",
      "            Greetings(user_name=\"Hello John\"), timeout=5\n",
      "        )\n",
      "    print(\"ok\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    loop = asyncio.get_event_loop()\n",
      "    loop.run_until_complete(async_tests())\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"../prompts/examples\", glob=\"**/*.txt\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26955dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=5000,\n",
    "#     chunk_overlap=0,\n",
    "#     separators=[\"==== EXAMPLE SKELETON CODE ====\",\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    "# )\n",
    "# chunks = text_splitter.split_documents(docs)\n",
    "# chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218c860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use the default port number. It should consume messages from 'receive_name' topic and the message will be a JSON encoded object with only one attribute: user_name. For each consumed message, construct a new message object and append 'Hello ' in front of the name attribute. Finally, publish the consumed message to 'send_greetings' topic.\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"==== EXAMPLE SKELETON CODE ====\",\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 20\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "chunks[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d411abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(chunks, OpenAIEmbeddings()) # type: ignore\n",
    "db.save_local(\"../tmp_db/faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89267e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Develop a FastKafka application using localhost broker for testing, staging.example.ai for staging and prod.example.ai for production. It should consume messages from 'course_updates' topic where the message is a JSON encoded object including two attributes: course_name and new_content. If new_content attribute is set, then construct a new message appending 'Updated: ' before the course_name attribute. Finally, publish this message to the 'notify_updates' topic. The application should use SASL_SSL with SCRAM-SHA-512 for authentication.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "db = FAISS.load_local(\"../tmp_db/faiss_index\", OpenAIEmbeddings()) # type: ignore\n",
    "results = db.max_marginal_relevance_search(query, k=3, fetch_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4178b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='==== EXAMPLE APP DESCRIPTION ====\\n\\nDevelop a new FastKafka application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.', metadata={'source': '../prompts/examples/example-3.txt'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a18996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='from typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Order(BaseModel):\\n    name: str = Field(..., description=\"Name of the order.\")\\n    quantity: int = Field(..., description=\"Quantity of the order.\")\\n    location: str = Field(\"Zagreb\", description=\"Location of the order.\")\\n\\nclass InventoryUpdate(BaseModel):\\n    quantity: int = Field(..., description=\"Quantity of the order to update inventory.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production Kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes JSON-encoded objects from the \\'receive_order\\' topic. Each object includes attributes such as \\'name\\' and \\'quantity\\'. Upon consumption, the application enhances the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. The modified message is then forwarded to the \\'place_order\\' topic. Additionally, a message is sent to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute corresponding to the received quantity value. No authentication is required.\"\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Enhance and Forward Order\\',\\n)\\n\\n\\nreceive_order_description = \"Upon consumption, enhance the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. Subsequently, forward the modified message to the \\'place_order\\' topic. Also, send another message to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute that corresponds to the received quantity value.\"\\n@app.consumes(topic=\"receive_order\", description=receive_order_description)\\nasync def on_receive_order(msg: Order):\\n    raise NotImplementedError()\\n\\n\\nplace_order_description = \"Produce the modified messages to the \\'place_order\\' topic.\"\\n@app.produces(topic=\"place_order\", description=place_order_description)\\nasync def to_place_order(msg: Order) -> Order:\\n    raise NotImplementedError()\\n\\n\\nupdate_inventory_description = \"Produce messages with \\'quantity\\' attribute corresponding to the received quantity value to the \\'update_inventory\\' topic.\"\\n@app.produces(topic=\"update_inventory\", description=update_inventory_description)\\nasync def to_update_inventory(quantity: int) -> InventoryUpdate:\\n    raise NotImplementedError()\\n\\n==== EXAMPLE APPLICATION CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Order(BaseModel):\\n    name: str = Field(..., description=\"Name of the order.\")\\n    quantity: int = Field(..., description=\"Quantity of the order.\")\\n    location: str = Field(\"Zagreb\", description=\"Location of the order.\")\\n\\nclass InventoryUpdate(BaseModel):\\n    quantity: int = Field(..., description=\"Quantity of the order to update inventory.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production Kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes JSON-encoded objects from the \\'receive_order\\' topic. Each object includes attributes such as \\'name\\' and \\'quantity\\'. Upon consumption, the application enhances the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. The modified message is then forwarded to the \\'place_order\\' topic. Additionally, a message is sent to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute corresponding to the received quantity value. No authentication is required.\"\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Enhance and Forward Order\\',\\n)\\n\\n\\nreceive_order_description = \"Upon consumption, enhance the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. Subsequently, forward the modified message to the \\'place_order\\' topic. Also, send another message to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute that corresponds to the received quantity value.\"\\n@app.consumes(topic=\"receive_order\", description=receive_order_description)\\nasync def on_receive_order(msg: Order):\\n    msg.location = \"Zagreb\"\\n    await to_place_order(msg)\\n    await to_update_inventory(msg.quantity)\\n\\n\\nplace_order_description = \"Produce the modified messages to the \\'place_order\\' topic.\"\\n@app.produces(topic=\"place_order\", description=place_order_description)\\nasync def to_place_order(msg: Order) -> Order:\\n    return msg\\n\\n\\nupdate_inventory_description = \"Produce messages with \\'quantity\\' attribute corresponding to the received quantity value to the \\'update_inventory\\' topic.\"\\n@app.produces(topic=\"update_inventory\", description=update_inventory_description)\\nasync def to_update_inventory(quantity: int) -> InventoryUpdate:\\n    return InventoryUpdate(quantity=quantity)\\n\\n==== EXAMPLE TEST CODE ====\\n\\nimport asyncio\\nfrom fastkafka.testing import Tester\\n\\n\\ntry:\\n    from .application import *\\nexcept ImportError:\\n    from application import *\\n\\n\\nasync def async_tests():\\n    async with Tester(app) as tester:\\n        # Create a sample order message\\n        input_msg = Order(name=\"Test Order\", quantity=10)\\n\\n        # Publish the order message to the receive_order topic\\n        await tester.to_receive_order(input_msg)\\n\\n        # Assert that the on_receive_order function was called with the correct argument\\n        await app.awaited_mocks.on_receive_order.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        # Assert that the to_place_order function in the tester was called with the correct argument\\n        await tester.awaited_mocks.on_place_order.assert_called_with(\\n            Order(name=\"Test Order\", quantity=10, location=\"Zagreb\"), timeout=5\\n        )\\n\\n        # Assert that the to_update_inventory function in the tester was called with the correct argument\\n        await tester.awaited_mocks.on_update_inventory.assert_called_with(\\n            InventoryUpdate(quantity=10), timeout=5\\n        )\\n\\n    print(\"ok\")\\n\\n\\nif __name__ == \"__main__\":\\n    loop = asyncio.get_event_loop()\\n    loop.run_until_complete(async_tests())', metadata={'source': '../prompts/examples/example-3.txt'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = db.similarity_search(\"\",filter=dict(source=results[2].metadata[\"source\"]))\n",
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9ec5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f7c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72725703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b759b036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4f7323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ef468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use the default port number. It should consume messages from \\'receive_name\\' topic and the message will be a JSON encoded object with only one attribute: user_name. For each consumed message, construct a new message object and append \\'Hello \\' in front of the name attribute. Finally, publish the consumed message to \\'send_greetings\\' topic.\\n\\n==== EXAMPLE SKELETON CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Greetings(BaseModel):\\n    user_name: str = Field(..., description=\"Name of the user.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes messages from the \\'receive_name\\' topic. Each message is a JSON-encoded object with only one attribute: \\'user_name\\'. For each consumed message, the application constructs a new message object and appends \\'Hello \\' in front of the \\'user_name\\' attribute. Finally, the application publishes the modified message to the \\'send_greetings\\' topic.\"\\n\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Greet users\\',\\n)\\n\\n\\nconsume_description = \"The application consumes messages from the \\'receive_name\\' topic and constructs a new message object with \\'Hello \\' appended to the \\'user_name\\' attribute.\"\\n@app.consumes(topic=\"receive_name\", description=consume_description)\\nasync def on_receive_name(msg: Greetings):\\n    raise NotImplementedError()\\n\\n\\npublish_description = \"The application publishes the modified messages to the \\'send_greetings\\' topic.\"\\n@app.produces(topic=\"send_greetings\", description=publish_description)\\nasync def to_send_greetings(msg: Greetings) -> Greetings:\\n    raise NotImplementedError()\\n\\n==== EXAMPLE APPLICATION CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Greetings(BaseModel):\\n    user_name: str = Field(..., description=\"Name of the user.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes messages from the \\'receive_name\\' topic. Each message is a JSON-encoded object with only one attribute: \\'user_name\\'. For each consumed message, the application constructs a new message object and appends \\'Hello \\' in front of the \\'user_name\\' attribute. Finally, the application publishes the modified message to the \\'send_greetings\\' topic.\"\\n\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Greet users\\',\\n)\\n\\n\\nconsume_description = \"The application consumes messages from the \\'receive_name\\' topic and constructs a new message object with \\'Hello \\' appended to the \\'user_name\\' attribute.\"\\n@app.consumes(topic=\"receive_name\", description=consume_description)\\nasync def on_receive_name(msg: Greetings):\\n    msg = Greetings(user_name=f\"Hello {msg.user_name}\")\\n    await to_send_greetings(msg)\\n\\n\\npublish_description = \"The application publishes the modified messages to the \\'send_greetings\\' topic.\"\\n@app.produces(topic=\"send_greetings\", description=publish_description)\\nasync def to_send_greetings(msg: Greetings) -> Greetings:\\n    return msg\\n\\n==== EXAMPLE TEST CODE ====\\n\\nimport asyncio\\nfrom fastkafka.testing import Tester\\ntry:\\n    from .application import *\\nexcept ImportError as e:\\n    from application import *\\n\\nasync def async_tests():\\n    async with Tester(app) as tester:\\n        input_msg = Greetings(user_name=\"John\")\\n\\n        # tester produces message to the receive_name topic\\n        await tester.to_receive_name(input_msg)\\n\\n        # assert that app consumed from the receive_name topic and it was called with the accurate argument\\n        await app.awaited_mocks.on_receive_name.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        # assert that tester consumed from the send_greetings topic and it was called with the accurate argument\\n        await tester.awaited_mocks.on_send_greetings.assert_called_with(\\n            Greetings(user_name=\"Hello John\"), timeout=5\\n        )\\n    print(\"ok\")\\n\\nif __name__ == \"__main__\":\\n    loop = asyncio.get_event_loop()\\n    loop.run_until_complete(async_tests())', metadata={'source': '../prompts/examples/example-4.txt'}),\n",
       " Document(page_content='==== EXAMPLE APP DESCRIPTION ====\\n\\nWrite a fastkafka application with with one consumer function and two producer functions. The consumer function should receive a message posted on \"new_joinee\" topic. The message should contain \"employee_name\", \"age\", \"location\" and \"experience\" attributes. After consuming the consumer function should send the details to the \"project_team\" and \"admin_team\" topics. Use only localhost broker\\n\\n==== EXAMPLE SKELETON CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass NewJoinee(BaseModel):\\n    employee_name: str = Field(..., description=\"Name of the new joinee.\")\\n    age: int = Field(..., description=\"Age of the new joinee.\")\\n    location: str = Field(..., description=\"Location of the new joinee.\")\\n    experience: str = Field(..., description=\"Experience of the new joinee.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application for managing employee details. It consumes messages from the \\'new_joinee\\' topic, which include attributes like \\'employee_name\\', \\'age\\', \\'location\\', and \\'experience\\'. After consuming, the application sends the employee details to the \\'project_team\\' and \\'admin_team\\' topics.\"\\n\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Employee Management\\',\\n)\\n\\n\\nconsume_description = \"Consume employee details from the \\'new_joinee\\' topic and send to \\'project_team\\' and \\'admin_team\\' topics.\"\\n\\n@app.consumes(topic=\"new_joinee\", description=consume_description)\\nasync def on_new_joinee(msg: NewJoinee):\\n    raise NotImplementedError()\\n\\n\\npublish_project_description = \"Publish the consumed employee details to the \\'project_team\\' topic.\"\\n@app.produces(topic=\"project_team\", description=publish_project_description)\\nasync def to_project_team(msg: NewJoinee) -> NewJoinee:\\n    raise NotImplementedError()\\n\\n\\npublish_admin_description = \"Publish the consumed employee details to the \\'admin_team\\' topic.\"\\n@app.produces(topic=\"admin_team\", description=publish_admin_description)\\nasync def to_admin_team(msg: NewJoinee) -> NewJoinee:\\n    raise NotImplementedError()\\n\\n==== EXAMPLE APPLICATION CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass NewJoinee(BaseModel):\\n    employee_name: str = Field(..., description=\"Name of the new joinee.\")\\n    age: int = Field(..., description=\"Age of the new joinee.\")\\n    location: str = Field(..., description=\"Location of the new joinee.\")\\n    experience: str = Field(..., description=\"Experience of the new joinee.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application for managing employee details. It consumes messages from the \\'new_joinee\\' topic, which include attributes like \\'employee_name\\', \\'age\\', \\'location\\', and \\'experience\\'. After consuming, the application sends the employee details to the \\'project_team\\' and \\'admin_team\\' topics.\"\\n\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Employee Management\\',\\n)\\n\\n\\nconsume_description = \"Consume employee details from the \\'new_joinee\\' topic and send to \\'project_team\\' and \\'admin_team\\' topics.\"\\n\\n@app.consumes(topic=\"new_joinee\", description=consume_description)\\nasync def on_new_joinee(msg: NewJoinee):\\n    await to_project_team(msg)\\n    await to_admin_team(msg)\\n\\n\\npublish_project_description = \"Publish the consumed employee details to the \\'project_team\\' topic.\"\\n@app.produces(topic=\"project_team\", description=publish_project_description)\\nasync def to_project_team(msg: NewJoinee) -> NewJoinee:\\n    return msg\\n\\n\\npublish_admin_description = \"Publish the consumed employee details to the \\'admin_team\\' topic.\"\\n@app.produces(topic=\"admin_team\", description=publish_admin_description)\\nasync def to_admin_team(msg: NewJoinee) -> NewJoinee:\\n    return msg\\n\\n==== EXAMPLE TEST CODE ====\\n\\nimport asyncio\\nfrom fastkafka.testing import Tester\\ntry:\\n    from .application import *\\nexcept ImportError as e:\\n    from application import *\\n\\nasync def async_tests():\\n    async with Tester(app) as tester:\\n        input_msg = NewJoinee(\\n            employee_name=\"John Doe\",\\n            age=30,\\n            location=\"New York\",\\n            experience=\"5 years\"\\n        )\\n\\n        await tester.to_new_joinee(input_msg)\\n\\n        await app.awaited_mocks.on_new_joinee.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        await tester.awaited_mocks.on_project_team.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        await tester.awaited_mocks.on_admin_team.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n    print(\"ok\")\\n\\nif __name__ == \"__main__\":\\n    loop = asyncio.get_event_loop()\\n    loop.run_until_complete(async_tests())', metadata={'source': '../prompts/examples/example-2.txt'}),\n",
       " Document(page_content='==== EXAMPLE APP DESCRIPTION ====\\n\\nCreate a FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production. Use default port number. It should consume from \\'store_product\\' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. \\'EUR\\'.\\nFor each consumed message, check if the currency attribute is set to \\'HRK\\'. If it is then change the currency to \\'EUR\\' and divide the price by 7.5, if the currency is not set to \\'HRK\\' don\\'t change the original message. Finally, publish the consumed message to \\'change_currency\\' topic. Use SASL_SSL with SCRAM-SHA-256 for authentication with username and password.\\n\\n==== EXAMPLE SKELETON CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom aiokafka.helpers import create_ssl_context\\nfrom fastkafka import FastKafka\\n\\n\\nclass StoreProduct(BaseModel):\\n    product_name: str = Field(..., description=\"Name of the product.\")\\n    currency: str = Field(..., description=\"The currency.\")\\n    price: float = Field(..., description=\"Price of the product.\")\\n\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging kafka broker\",\\n        \"port\": 9092,\\n        \"protocol\": \"kafka-secure\",\\n        \"security\": {\"type\": \"scramSha256\"},\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production kafka broker\",\\n        \"port\": 9092,\\n        \"protocol\": \"kafka-secure\",\\n        \"security\": {\"type\": \"scramSha256\"},\\n    }\\n}\\n\\nstore_product_app_description = \"A FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production, using default port numbers. It should consume from \\'store_product\\' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. \\'EUR\\'. For each consumed message, check if the currency attribute is set to \\'HRK\\'. If it is then change the currency to \\'EUR\\' and divide the price by 7.5, if the currency is not set to \\'HRK\\' don\\'t change the original message. Finally, publish the consumed message to \\'change_currency\\' topic. Use SASL_SSL with SCRAM-SHA-256 for authentication.\"\\n\\nstore_product_app = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=store_product_app_description, \\n    version=\"0.0.1\", \\n    title=\\'Product currency converter\\',\\n    security_protocol = \"SASL_SSL\",\\n    sasl_mechanism= \"SCRAM-SHA-256\",\\n    sasl_plain_username= \"<username>\",\\n    sasl_plain_password=  \"<password>\", # nosec B106\\n    ssl_context= create_ssl_context(),\\n)\\n\\n\\nstore_product_description = \"For each consumed message, check if the currency attribute is set to \\'HRK\\'. If it is then change the currency to \\'EUR\\' and divide the price by 7.5, if the currency is not set to \\'HRK\\' don\\'t change the original message. Finally, publish the consumed message to \\'change_currency\\' topic.\"\\n\\n@store_product_app.consumes(topic=\"store_product\", description=store_product_description)\\nasync def on_store_product(msg: StoreProduct):\\n    raise NotImplementedError()\\n\\n\\n@store_product_app.produces(topic=\"change_currency\")\\nasync def to_change_currency(msg: StoreProduct) -> StoreProduct:\\n    raise NotImplementedError()\\n\\n==== EXAMPLE APPLICATION CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom aiokafka.helpers import create_ssl_context\\nfrom fastkafka import FastKafka\\n\\n\\nclass StoreProduct(BaseModel):\\n    product_name: str = Field(..., description=\"Name of the product.\")\\n    currency: str = Field(..., description=\"The currency.\")\\n    price: float = Field(..., description=\"Price of the product.\")\\n\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging kafka broker\",\\n        \"port\": 9092,\\n        \"protocol\": \"kafka-secure\",\\n        \"security\": {\"type\": \"scramSha256\"},\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production kafka broker\",\\n        \"port\": 9092,\\n        \"protocol\": \"kafka-secure\",\\n        \"security\": {\"type\": \"scramSha256\"},\\n    }\\n}\\n\\nstore_product_app_description = \"A FastKafka application using localhost broker for testing, staging.airt.ai for staging and prod.airt.ai for production, using default port numbers. It should consume from \\'store_product\\' topic an JSON encoded object with the following three attributes: product_name, currency and price. The format of the currency will be three letter string, e.g. \\'EUR\\'. For each consumed message, check if the currency attribute is set to \\'HRK\\'. If it is then change the currency to \\'EUR\\' and divide the price by 7.5, if the currency is not set to \\'HRK\\' don\\'t change the original message. Finally, publish the consumed message to \\'change_currency\\' topic. Use SASL_SSL with SCRAM-SHA-256 for authentication.\"\\n\\nstore_product_app = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=store_product_app_description, \\n    version=\"0.0.1\", \\n    title=\\'Product currency converter\\',\\n    security_protocol = \"SASL_SSL\",\\n    sasl_mechanism= \"SCRAM-SHA-256\",\\n    sasl_plain_username= \"<username>\",\\n    sasl_plain_password=  \"<password>\", # nosec B106\\n    ssl_context= create_ssl_context(),\\n)\\n\\n\\nstore_product_description = \"For each consumed message, check if the currency attribute is set to \\'HRK\\'. If it is then change the currency to \\'EUR\\' and divide the price by 7.5, if the currency is not set to \\'HRK\\' don\\'t change the original message. Finally, publish the consumed message to \\'change_currency\\' topic.\"\\n\\n@store_product_app.consumes(topic=\"store_product\", description=store_product_description)\\nasync def on_store_product(msg: StoreProduct):\\n    if msg.currency == \"HRK\":\\n       msg = StoreProduct(product_name = msg.product_name, currency=\"EUR\", price = msg.price / 7.5)\\n    await to_change_currency(msg)\\n\\n\\n@store_product_app.produces(topic=\"change_currency\")\\nasync def to_change_currency(msg: StoreProduct) -> StoreProduct:\\n    return msg\\n    \\n==== EXAMPLE TEST CODE ====\\n\\nimport asyncio\\nfrom fastkafka.testing import Tester\\nfrom application import *\\n\\nasync def async_tests():\\n    async with Tester(store_product_app) as tester:\\n        input_msg = StoreProduct(\\n            product_name=\"Mobile Phone\",\\n            currency=\"HRK\",\\n            price=750.0\\n        )\\n\\n        await tester.to_store_product(input_msg)\\n\\n        await store_product_app.awaited_mocks.on_store_product.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        await tester.awaited_mocks.on_change_currency.assert_called_with(\\n            StoreProduct(\\n                product_name=\"Mobile Phone\",\\n                currency=\"EUR\",\\n                price=100.0\\n            ), timeout=5\\n        )\\n    print(\"ok\")\\n\\nif __name__ == \"__main__\":\\n    loop = asyncio.get_event_loop()\\n    loop.run_until_complete(async_tests())\\n', metadata={'source': '../prompts/examples/example-1.txt'}),\n",
       " Document(page_content='==== EXAMPLE APP DESCRIPTION ====\\n\\nDevelop a new FastKafka application that consumes JSON-encoded objects from the \"receive_order\" topic. These objects include attributes like \"name\" and \"quantity.\" Upon consumption, enhance the message by adding a \"location\" attribute set to \"Zagreb.\" Subsequently, forward the modified message to the \"place_order\" topic. After this, send another message to the \"update_inventory\" topic. This message should include a \"quantity\" attribute that corresponds to the received quantity value. No authentication is required.\\n\\n==== EXAMPLE SKELETON CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Order(BaseModel):\\n    name: str = Field(..., description=\"Name of the order.\")\\n    quantity: int = Field(..., description=\"Quantity of the order.\")\\n    location: str = Field(\"Zagreb\", description=\"Location of the order.\")\\n\\nclass InventoryUpdate(BaseModel):\\n    quantity: int = Field(..., description=\"Quantity of the order to update inventory.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production Kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes JSON-encoded objects from the \\'receive_order\\' topic. Each object includes attributes such as \\'name\\' and \\'quantity\\'. Upon consumption, the application enhances the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. The modified message is then forwarded to the \\'place_order\\' topic. Additionally, a message is sent to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute corresponding to the received quantity value. No authentication is required.\"\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Enhance and Forward Order\\',\\n)\\n\\n\\nreceive_order_description = \"Upon consumption, enhance the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. Subsequently, forward the modified message to the \\'place_order\\' topic. Also, send another message to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute that corresponds to the received quantity value.\"\\n@app.consumes(topic=\"receive_order\", description=receive_order_description)\\nasync def on_receive_order(msg: Order):\\n    raise NotImplementedError()\\n\\n\\nplace_order_description = \"Produce the modified messages to the \\'place_order\\' topic.\"\\n@app.produces(topic=\"place_order\", description=place_order_description)\\nasync def to_place_order(msg: Order) -> Order:\\n    raise NotImplementedError()\\n\\n\\nupdate_inventory_description = \"Produce messages with \\'quantity\\' attribute corresponding to the received quantity value to the \\'update_inventory\\' topic.\"\\n@app.produces(topic=\"update_inventory\", description=update_inventory_description)\\nasync def to_update_inventory(quantity: int) -> InventoryUpdate:\\n    raise NotImplementedError()\\n\\n==== EXAMPLE APPLICATION CODE ====\\n\\nfrom typing import *\\nfrom pydantic import BaseModel, Field\\nfrom fastkafka import FastKafka\\n\\n\\nclass Order(BaseModel):\\n    name: str = Field(..., description=\"Name of the order.\")\\n    quantity: int = Field(..., description=\"Quantity of the order.\")\\n    location: str = Field(\"Zagreb\", description=\"Location of the order.\")\\n\\nclass InventoryUpdate(BaseModel):\\n    quantity: int = Field(..., description=\"Quantity of the order to update inventory.\")\\n\\nkafka_brokers = {\\n    \"localhost\": {\\n        \"url\": \"localhost\",\\n        \"description\": \"local development Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"staging\": {\\n        \"url\": \"staging.airt.ai\",\\n        \"description\": \"staging Kafka broker\",\\n        \"port\": 9092,\\n    },\\n    \"production\": {\\n        \"url\": \"prod.airt.ai\",\\n        \"description\": \"production Kafka broker\",\\n        \"port\": 9092,\\n    }\\n}\\n\\napp_description = \"A FastKafka application that consumes JSON-encoded objects from the \\'receive_order\\' topic. Each object includes attributes such as \\'name\\' and \\'quantity\\'. Upon consumption, the application enhances the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. The modified message is then forwarded to the \\'place_order\\' topic. Additionally, a message is sent to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute corresponding to the received quantity value. No authentication is required.\"\\napp = FastKafka(\\n    kafka_brokers=kafka_brokers, \\n    description=app_description, \\n    title=\\'Enhance and Forward Order\\',\\n)\\n\\n\\nreceive_order_description = \"Upon consumption, enhance the message by adding a \\'location\\' attribute set to \\'Zagreb\\'. Subsequently, forward the modified message to the \\'place_order\\' topic. Also, send another message to the \\'update_inventory\\' topic, including a \\'quantity\\' attribute that corresponds to the received quantity value.\"\\n@app.consumes(topic=\"receive_order\", description=receive_order_description)\\nasync def on_receive_order(msg: Order):\\n    msg.location = \"Zagreb\"\\n    await to_place_order(msg)\\n    await to_update_inventory(msg.quantity)\\n\\n\\nplace_order_description = \"Produce the modified messages to the \\'place_order\\' topic.\"\\n@app.produces(topic=\"place_order\", description=place_order_description)\\nasync def to_place_order(msg: Order) -> Order:\\n    return msg\\n\\n\\nupdate_inventory_description = \"Produce messages with \\'quantity\\' attribute corresponding to the received quantity value to the \\'update_inventory\\' topic.\"\\n@app.produces(topic=\"update_inventory\", description=update_inventory_description)\\nasync def to_update_inventory(quantity: int) -> InventoryUpdate:\\n    return InventoryUpdate(quantity=quantity)\\n\\n==== EXAMPLE TEST CODE ====\\n\\nimport asyncio\\nfrom fastkafka.testing import Tester\\n\\n\\ntry:\\n    from .application import *\\nexcept ImportError:\\n    from application import *\\n\\n\\nasync def async_tests():\\n    async with Tester(app) as tester:\\n        # Create a sample order message\\n        input_msg = Order(name=\"Test Order\", quantity=10)\\n\\n        # Publish the order message to the receive_order topic\\n        await tester.to_receive_order(input_msg)\\n\\n        # Assert that the on_receive_order function was called with the correct argument\\n        await app.awaited_mocks.on_receive_order.assert_called_with(\\n            input_msg, timeout=5\\n        )\\n\\n        # Assert that the to_place_order function in the tester was called with the correct argument\\n        await tester.awaited_mocks.on_place_order.assert_called_with(\\n            Order(name=\"Test Order\", quantity=10, location=\"Zagreb\"), timeout=5\\n        )\\n\\n        # Assert that the to_update_inventory function in the tester was called with the correct argument\\n        await tester.awaited_mocks.on_update_inventory.assert_called_with(\\n            InventoryUpdate(quantity=10), timeout=5\\n        )\\n\\n    print(\"ok\")\\n\\n\\nif __name__ == \"__main__\":\\n    loop = asyncio.get_event_loop()\\n    loop.run_until_complete(async_tests())', metadata={'source': '../prompts/examples/example-3.txt'})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"../prompts/examples\", glob=\"**/*.txt\", loader_cls=TextLoader\n",
    ")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93afe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This text splitter is used to create the child documents\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "# The storage layer for the parent documents\n",
    "store = InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=db, \n",
    "    docstore=store, \n",
    "    child_splitter=child_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d311a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b8c94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.get_relevant_documents(\"justice breyer\")\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53295c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
