{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a26be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _code_generator.helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb7431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from typing import *\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import functools\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import openai\n",
    "import typer\n",
    "from fastcore.foundation import patch\n",
    "from langchain.schema.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from faststream_gen._components.logger import get_logger, set_level\n",
    "from faststream_gen._code_generator.prompts import SYSTEM_PROMPT\n",
    "from faststream_gen._code_generator.constants import (\n",
    "    DEFAULT_PARAMS,\n",
    "    MAX_RETRIES,\n",
    "    MAX_RESTARTS,\n",
    "    ASYNC_API_SPEC_FILE_NAME,\n",
    "    APPLICATION_FILE_NAME,\n",
    "    TOKEN_TYPES,\n",
    "    MAX_NUM_FIXES_MSG,\n",
    "    INCOMPLETE_DESCRIPTION,\n",
    "    DESCRIPTION_EXAMPLE,\n",
    "    RESULTS_DIR_NAMES,\n",
    ")\n",
    "from faststream_gen._components.package_data import get_root_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a580a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import sys\n",
    "import unittest.mock\n",
    "\n",
    "from faststream_gen._components.logger import suppress_timestamps\n",
    "from faststream_gen._code_generator.constants import FASTSTREAM_DOCS_DIR_SUFFIX, FASTSTREAM_REPO_ZIP_URL, OpenAIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25822c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__, level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c529a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "suppress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def retry_on_error(max_retries: int = MAX_RESTARTS, delay: int = 1, step_name: str = RESULTS_DIR_NAMES[\"app\"]):  # type: ignore\n",
    "    def decorator(func):  # type: ignore\n",
    "        def wrapper(*args, **kwargs):  # type: ignore\n",
    "            for i in range(max_retries):\n",
    "                try:\n",
    "                    kwargs[\"attempt\"] = i\n",
    "                    return func(*args, **kwargs)\n",
    "                except ValueError as e:\n",
    "                    # Log the error here\n",
    "                    logger.info(f\"Attempt {i} failed. Restarting step.\")\n",
    "                    time.sleep(delay)\n",
    "                    # Capture exception details here\n",
    "                    last_exception = e\n",
    "            if step_name == RESULTS_DIR_NAMES[\"app\"]:\n",
    "                return last_exception.args[0], last_exception.args[1], True\n",
    "            else:\n",
    "                raise ValueError(last_exception)\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd12586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Attempt 0 failed. Restarting step.\n",
      "[INFO] __main__: Attempt 1 failed. Restarting step.\n",
      "[INFO] __main__: Attempt 2 failed. Restarting step.\n",
      "(\"print('hi')\", [], True)\n"
     ]
    }
   ],
   "source": [
    "@retry_on_error(max_retries=3)\n",
    "def my_function(attempt):\n",
    "    # Code that may raise an exception\n",
    "    raise ValueError(\"print('hi')\", [])\n",
    "\n",
    "\n",
    "actual = my_function()\n",
    "print(actual)\n",
    "expected = (\"print('hi')\", [], True) \n",
    "assert actual == expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13caf37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "@retry_on_error(max_retries=3)\n",
    "def my_function(attempt):\n",
    "    # Code that may raise an exception\n",
    "    return \"hi\"\n",
    "\n",
    "# Call the decorated function\n",
    "actual = my_function()\n",
    "print(actual)\n",
    "\n",
    "assert actual == \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00301e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Attempt 0 failed. Restarting step.\n",
      "[INFO] __main__: Attempt 1 failed. Restarting step.\n",
      "[INFO] __main__: Attempt 2 failed. Restarting step.\n",
      "ValueError\n"
     ]
    }
   ],
   "source": [
    "@retry_on_error(step_name=RESULTS_DIR_NAMES[\"skeleton\"])\n",
    "def my_function(attempt):\n",
    "    # Code that may raise an exception\n",
    "    raise ValueError(\"ValueError\")\n",
    "\n",
    "\n",
    "with pytest.raises(ValueError) as e:\n",
    "    my_function()\n",
    "\n",
    "print(str(e.value))\n",
    "assert str(e.value) == \"ValueError\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e13a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "@retry_on_error(max_retries=3, step_name=RESULTS_DIR_NAMES[\"skeleton\"])\n",
    "def my_function(attempt):\n",
    "    # Code that may raise an exception\n",
    "    return \"hi\"\n",
    "\n",
    "# Call the decorated function\n",
    "actual = my_function()\n",
    "print(actual)\n",
    "\n",
    "assert actual == \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _fetch_content(url: str) -> requests.models.Response: # type: ignore\n",
    "    \"\"\"Fetch content from a URL using an HTTP GET request.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to fetch content from.\n",
    "\n",
    "    Returns:\n",
    "        Response: The response object containing the content and HTTP status.\n",
    "\n",
    "    Raises:\n",
    "        requests.exceptions.Timeout: If the request times out.\n",
    "        requests.exceptions.RequestException: If an error occurs during the request.\n",
    "    \"\"\"\n",
    "    attempt = 0\n",
    "    while attempt < 4:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=50)\n",
    "            response.raise_for_status()  # Raises an exception for HTTP errors\n",
    "            return response\n",
    "        except requests.exceptions.Timeout:\n",
    "            if attempt == 3:  # If this was the fourth attempt, raise the Timeout exception\n",
    "                raise requests.exceptions.Timeout(\n",
    "                    \"Request timed out. Please check your internet connection or try again later.\"\n",
    "                )\n",
    "            time.sleep(1)  # Sleep for one second before retrying\n",
    "            attempt += 1\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            raise requests.exceptions.RequestException(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e899c4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html lang=\"en\" dir=\"ltr\" class=\"plugin-pages plugin-id-default\">\\n<head>\\n<meta charset=\"UTF-8\">\\n<meta name=\"generator\" content=\"Docusaurus v2.4.0\">\\n<title data-rh=\"true\">Effortless Kaf'\n"
     ]
    }
   ],
   "source": [
    "response = _fetch_content(\"https://fastkafka.airt.ai/\")\n",
    "print(response.content[:200])\n",
    "assert len(response.content) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def download_and_extract_faststream_archive(url: str) -> Generator[Path, None, None]:\n",
    "    with TemporaryDirectory() as d:\n",
    "        try:\n",
    "            input_path = Path(f\"{d}/archive.zip\")\n",
    "            extrated_path = Path(f\"{d}/extrated_path\")\n",
    "            extrated_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            response = _fetch_content(url)\n",
    "\n",
    "            with open(input_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            with zipfile.ZipFile(input_path, \"r\") as zip_ref:\n",
    "                for member in zip_ref.namelist():\n",
    "                    zip_ref.extract(member, extrated_path)\n",
    "\n",
    "            yield extrated_path\n",
    "\n",
    "        except Exception as e:\n",
    "            fg = typer.colors.RED\n",
    "            typer.secho(f\"Unexpected internal error: {e}\", err=True, fg=fg)\n",
    "            raise typer.Exit(code=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54aba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['api', 'kafka', 'getting-started', 'index', 'release', 'rabbit']\n"
     ]
    }
   ],
   "source": [
    "with download_and_extract_faststream_archive(FASTSTREAM_REPO_ZIP_URL) as extracted_path:\n",
    "    files = [p.stem for p in list(Path(extracted_path/FASTSTREAM_DOCS_DIR_SUFFIX).glob(\"*\"))]\n",
    "    print(files)\n",
    "    assert \"index\" in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c112cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def write_file_contents(output_file: str, contents: str) -> None:\n",
    "    \"\"\"Write the given contents to the specified output file.\n",
    "\n",
    "    Args:\n",
    "        output_file: The path to the output file where the contents will be written.\n",
    "        contents: The contents to be written to the output file.\n",
    "\n",
    "    Raises:\n",
    "        OSError: If there is an issue while attempting to save the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Path(output_file).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(contents)\n",
    "\n",
    "    except OSError as e:\n",
    "        raise OSError(\n",
    "            f\"Error: Failed to save file at '{output_file}' due to: '{e}'. Please ensure that the specified 'output_path' is valid and that you have the necessary permissions to write files to it.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8631d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpdx2rjvd8/grand-parent/parent/child/application.py\n",
      "\n",
      "\n",
      "print(\"Hello World\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contents = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    output_path = f\"{str(d)}/grand-parent/parent/child\"\n",
    "    output_file = f\"{output_path}/application.py\"\n",
    "    \n",
    "    write_file_contents(output_file, contents)\n",
    "    \n",
    "    with open(output_file, 'r', encoding=\"utf-8\") as f:\n",
    "        actual = f.read()\n",
    "    print(f\"{output_file}\\n\\n{actual}\")\n",
    "\n",
    "assert actual == contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57edc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def read_file_contents(output_file: str) -> str:\n",
    "    \"\"\"Read and return the contents from the specified file.\n",
    "\n",
    "    Args:\n",
    "        output_file: The path to the file to be read.\n",
    "\n",
    "    Returns:\n",
    "        The contents of the file as string.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified file does not exist.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            contents = f.read()\n",
    "        return contents\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Error: The file '{output_file}' does not exist. Please ensure that the specified 'output_path' is valid and that you have the necessary permissions to access it.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmptb773j3_/grand-parent/parent/child/application.py\n",
      "\n",
      "\n",
      "print(\"Hello World\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contents = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    output_path = f\"{str(d)}/grand-parent/parent/child\"\n",
    "    output_file = f\"{output_path}/application.py\"\n",
    "    \n",
    "    write_file_contents(output_file, contents)\n",
    "    \n",
    "    actual = read_file_contents(output_file)\n",
    "    print(f\"{output_file}\\n\\n{actual}\")\n",
    "\n",
    "assert actual == contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f529c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExceptionInfo FileNotFoundError(\"Error: The file '/tmp/tmpu891r3vq/grand-parent/parent/child/application.py' does not exist. Please ensure that the specified 'output_path' is valid and that you have the necessary permissions to access it.\") tblen=2>\n"
     ]
    }
   ],
   "source": [
    "contents = \"\"\"\n",
    "print(\"Hello World\")\n",
    "\"\"\"\n",
    "\n",
    "with pytest.raises(FileNotFoundError) as e:\n",
    "    with TemporaryDirectory() as d:\n",
    "        output_path = f\"{str(d)}/grand-parent/parent/child\"\n",
    "        output_file = f\"{output_path}/application.py\"\n",
    "\n",
    "        actual = read_file_contents(output_file)\n",
    "\n",
    "print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e0491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def validate_python_code(code: str, **kwargs: Dict[str, Any]) -> List[str]:\n",
    "    \"\"\"Validate and report errors in the provided Python code.\n",
    "\n",
    "    Args:\n",
    "        code: The Python code as a string.\n",
    "\n",
    "    Returns:\n",
    "        A list of error messages encountered during validation. If no errors occur, an empty list is returned.\n",
    "    \"\"\"\n",
    "    with TemporaryDirectory() as d:\n",
    "        try:\n",
    "            temp_file = Path(d) / APPLICATION_FILE_NAME\n",
    "            write_file_contents(str(temp_file), code)\n",
    "\n",
    "            # Import the module using importlib\n",
    "            spec = importlib.util.spec_from_file_location(\"tmp_module\", temp_file)\n",
    "            module = importlib.util.module_from_spec(spec)  # type: ignore\n",
    "            spec.loader.exec_module(module)  # type: ignore\n",
    "\n",
    "        except Exception as e:\n",
    "            return [f\"{type(e).__name__}: {e}\"]\n",
    "\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd67467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "fixture = \"\"\"\n",
    "import os\n",
    "def say_hello():\n",
    "    print(\"hello\")\n",
    "\"\"\"\n",
    "\n",
    "actual = validate_python_code(fixture)\n",
    "expected = []\n",
    "\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c440dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"ModuleNotFoundError: No module named 'invalid_module'\"]\n"
     ]
    }
   ],
   "source": [
    "fixture = \"\"\"\n",
    "import os\n",
    "import invalid_module\n",
    "def say_hello():\n",
    "    print(\"hello\")\n",
    "\"\"\"\n",
    "\n",
    "actual = validate_python_code(fixture)\n",
    "expected = [\"ModuleNotFoundError: No module named 'invalid_module'\"]\n",
    "\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db0664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"SyntaxError: expected ':' (application.py, line 3)\"]\n"
     ]
    }
   ],
   "source": [
    "fixture = \"\"\"\n",
    "import os\n",
    "def say_hello()\n",
    "    print(\"hello\")\n",
    "\"\"\"\n",
    "\n",
    "actual = validate_python_code(fixture)\n",
    "expected = (\n",
    "    [\"SyntaxError: invalid syntax (application.py, line 3)\"]\n",
    "    if sys.version_info < (3, 10)\n",
    "    else [\"SyntaxError: expected ':' (application.py, line 3)\"]\n",
    ")\n",
    "\n",
    "print(actual)\n",
    "assert (\n",
    "    actual == expected\n",
    "), f\"actual = {actual} - expected = {expected} - sys.version_info = {sys.version_info}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def set_logger_level(func: Callable[..., Any]) -> Callable[..., Any]:\n",
    "    \"\"\"Decorator to set the logger level based on verbosity.\n",
    "\n",
    "    Args:\n",
    "        func: The function to be decorated.\n",
    "\n",
    "    Returns:\n",
    "        The decorated function.\n",
    "    \"\"\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper_decorator(*args, **kwargs): # type: ignore\n",
    "        if (\"verbose\" in kwargs) and kwargs[\"verbose\"]:\n",
    "            set_level(logging.INFO)\n",
    "        else:\n",
    "            set_level(logging.WARNING)\n",
    "        return func(*args, **kwargs)\n",
    "\n",
    "    return wrapper_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35821f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@set_logger_level\n",
    "def _test_logger():\n",
    "    logger.debug(\"INFO\")\n",
    "    logger.info(\"WARNING\")\n",
    "\n",
    "    \n",
    "_test_logger()\n",
    "display(logger.getEffectiveLevel())\n",
    "assert logger.getEffectiveLevel() == logging.WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ed3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: WARNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@set_logger_level\n",
    "def _test_logger(**kwargs):\n",
    "    logger.debug(\"INFO\")\n",
    "    logger.info(\"WARNING\")\n",
    "\n",
    "    \n",
    "_test_logger(verbose=True)\n",
    "display(logger.getEffectiveLevel())\n",
    "assert logger.getEffectiveLevel() == logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ee713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "# Reference: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb\n",
    "\n",
    "\n",
    "def _retry_with_exponential_backoff(\n",
    "    initial_delay: float = 1,\n",
    "    exponential_base: float = 2,\n",
    "    jitter: bool = True,\n",
    "    max_retries: int = 10,\n",
    "    max_wait: float = 60,\n",
    "    errors: tuple = (\n",
    "        openai.error.RateLimitError,\n",
    "        openai.error.ServiceUnavailableError,\n",
    "        openai.error.APIError,\n",
    "    ),\n",
    ") -> Callable:\n",
    "    \"\"\"Retry a function with exponential backoff.\"\"\"\n",
    "\n",
    "    def decorator(\n",
    "        func: Callable[[str], Tuple[str, str]]\n",
    "    ) -> Callable[[str], Tuple[str, str]]:\n",
    "        def wrapper(*args, **kwargs):  # type: ignore\n",
    "            num_retries = 0\n",
    "            delay = initial_delay\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "\n",
    "                except errors as e:\n",
    "                    num_retries += 1\n",
    "                    if num_retries > max_retries:\n",
    "                        raise Exception(\n",
    "                            f\"Maximum number of retries ({max_retries}) exceeded.\"\n",
    "                        )\n",
    "                    delay = min(\n",
    "                        delay\n",
    "                        * exponential_base\n",
    "                        * (1 + jitter * random.random()),  # nosec\n",
    "                        max_wait,\n",
    "                    )\n",
    "                    logger.info(\n",
    "                        f\"Note: OpenAI's API rate limit reached. Command will automatically retry in {int(delay)} seconds. For more information visit: https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits\",\n",
    "                    )\n",
    "                    time.sleep(delay)\n",
    "\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "\n",
    "        return wrapper\n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e0a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "@_retry_with_exponential_backoff()\n",
    "def mock_func():\n",
    "    return \"Success\"\n",
    "\n",
    "actual = mock_func()\n",
    "expected = \"Success\"\n",
    "\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f323384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Note: OpenAI's API rate limit reached. Command will automatically retry in 3 seconds. For more information visit: https://help.openai.com/en/articles/5955598-is-api-usage-subject-to-any-rate-limits\n",
      "Maximum number of retries (1) exceeded.\n"
     ]
    }
   ],
   "source": [
    "# Test max retries exceeded\n",
    "@_retry_with_exponential_backoff(max_retries=1)\n",
    "def mock_func_error():\n",
    "    raise openai.error.RateLimitError\n",
    "\n",
    "\n",
    "with pytest.raises(Exception) as e:\n",
    "    mock_func_error()\n",
    "\n",
    "print(e.value)\n",
    "assert str(e.value) == \"Maximum number of retries (1) exceeded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _get_relevant_document(query: str) -> str:\n",
    "    \"\"\"Load the vector database and retrieve the most relevant document based on the given query.\n",
    "\n",
    "    Args:\n",
    "        query: The query for relevance-based document retrieval.\n",
    "\n",
    "    Returns:\n",
    "        The content of the most relevant document as a string.\n",
    "    \"\"\"\n",
    "    db_path = get_root_data_path() / \"docs\"\n",
    "    db = FAISS.load_local(db_path, OpenAIEmbeddings()) # type: ignore\n",
    "    results = db.max_marginal_relevance_search(query, k=1, fetch_k=3)\n",
    "    results_str = \"\\n\".join([result.page_content for result in results])\n",
    "    return results_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbe674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] faiss.loader: Loading faiss with AVX2 support.\n",
      "[INFO] faiss.loader: Successfully loaded faiss with AVX2 support.\n",
      "hide:\n",
      "  - navigation\n",
      "  - footer\n",
      "\n",
      "Release Notes\n",
      "\n",
      "FastStream is a new package based on the ideas and experiences gained from FastKafka and Propan. By joining our forces, we picked up the best from both \n"
     ]
    }
   ],
   "source": [
    "query = \"What is FastStream?\"\n",
    "actual = _get_relevant_document(query)\n",
    "print(actual[:200])\n",
    "assert len(actual) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db894e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "examples_delimiter = {\n",
    "    \"description\": {\n",
    "        \"start\": \"==== description.txt starts ====\",\n",
    "        \"end\": \"==== description.txt ends ====\",\n",
    "    },\n",
    "    \"skeleton\": {\n",
    "        \"start\": \"==== app_skeleton.py starts ====\",\n",
    "        \"end\": \"==== app_skeleton.py ends ====\",\n",
    "    },\n",
    "    \"app\": {\n",
    "        \"start\": \"==== app.py starts ====\",\n",
    "        \"end\": \"==== app.py ends ====\",\n",
    "    },\n",
    "    \"test_app\": {\n",
    "        \"start\": \"==== test_app.py starts ====\",\n",
    "        \"end\": \"==== test_app.py ends ====\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "def _split_text(text: str, delimiter: Dict[str, str]) -> str:\n",
    "    return text.split(delimiter[\"start\"])[-1].split(delimiter[\"end\"])[0]\n",
    "\n",
    "\n",
    "def _format_examples(parent_docs_str: List[str]) -> Dict[str, str]:\n",
    "    \"\"\"Format and extract examples from parent document.\n",
    "\n",
    "    Args:\n",
    "        parent_docs_str (List[str]): A list of parent document strings containing example sections.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List[str]]: A dictionary with sections as keys and lists of formatted examples as values.\n",
    "    \"\"\"\n",
    "    ret_val = {\"description_to_skeleton\": \"\", \"skeleton_to_app_and_test\": \"\"}\n",
    "    for d in parent_docs_str:\n",
    "        description = _split_text(d, examples_delimiter[\"description\"])\n",
    "        skeleton = _split_text(d, examples_delimiter[\"skeleton\"])\n",
    "        app = _split_text(d, examples_delimiter[\"app\"])\n",
    "        test_app = _split_text(d, examples_delimiter[\"test_app\"])\n",
    "\n",
    "        ret_val[\n",
    "            \"description_to_skeleton\"\n",
    "        ] += f\"\\n==== EXAMPLE APP DESCRIPTION ====\\n{description}\\n\\n==== YOUR RESPONSE ====\\n\\n{skeleton}\"\n",
    "        ret_val[\n",
    "            \"skeleton_to_app_and_test\"\n",
    "        ] += f\"\\n==== EXAMPLE APP DESCRIPTION ====\\n{description}\\n\\n==== EXAMPLE APP SKELETON ====\\n{skeleton}\\n==== YOUR RESPONSE ====\\n\\n### application.py ###\\n{app}\\n### test.py ###\\n{test_app}\"\n",
    "\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38db974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description_to_skeleton': '\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\napp_skeleton.py\\n', 'skeleton_to_app_and_test': '\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== EXAMPLE APP SKELETON ====\\n\\napp_skeleton.py\\n\\n==== YOUR RESPONSE ====\\n\\n### application.py ###\\n\\napp.py\\n\\n### test.py ###\\n\\ntest_app.py\\n'}\n"
     ]
    }
   ],
   "source": [
    "fixture = [\n",
    "    \"\"\"\n",
    "==== description.txt starts ====\n",
    "description.txt\n",
    "==== description.txt ends ====\n",
    "==== app_skeleton.py starts ====\n",
    "app_skeleton.py\n",
    "==== app_skeleton.py ends ====\n",
    "==== app.py starts ====\n",
    "app.py\n",
    "==== app.py ends ====\n",
    "==== test_app.py starts ====\n",
    "test_app.py\n",
    "==== test_app.py ends ====\n",
    "\"\"\"\n",
    "]\n",
    "expected = {\n",
    "    \"description_to_skeleton\": \"\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== YOUR RESPONSE ====\\n\\n\\napp_skeleton.py\\n\",\n",
    "    \"skeleton_to_app_and_test\": \"\\n==== EXAMPLE APP DESCRIPTION ====\\n\\ndescription.txt\\n\\n\\n==== EXAMPLE APP SKELETON ====\\n\\napp_skeleton.py\\n\\n==== YOUR RESPONSE ====\\n\\n### application.py ###\\n\\napp.py\\n\\n### test.py ###\\n\\ntest_app.py\\n\",\n",
    "}\n",
    "\n",
    "actual = _format_examples(fixture)\n",
    "print(actual)\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def get_relevant_prompt_examples(query: str) -> Dict[str, str]:\n",
    "    \"\"\"Load the vector database and retrieve the most relevant examples based on the given query for each step.\n",
    "\n",
    "    Args:\n",
    "        query: The query for relevance-based document retrieval.\n",
    "\n",
    "    Returns:\n",
    "        The dictionary of the most relevant examples for each step.\n",
    "    \"\"\"\n",
    "    db_path = get_root_data_path() / \"examples\"\n",
    "    db = FAISS.load_local(db_path, OpenAIEmbeddings()) # type: ignore\n",
    "    results = db.similarity_search(query, k=3, fetch_k=5)\n",
    "    results_page_content = [r.page_content for r in results]\n",
    "    prompt_examples = _format_examples(results_page_content)\n",
    "    return prompt_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da0abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application using localhost kafka broker.\n",
      "The app should consume messages from the input_data topic.\n",
      "The input message is a JSON encoded object including two attributes:\n",
      "    - x: float\n",
      "    - y: float\n",
      "    - time: datetime\n",
      "\n",
      "input_data topic should use partition key.\n",
      "While consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\n",
      "The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "from faststream import Context, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Point(BaseModel):\n",
      "    x: float = Field(\n",
      "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
      "    )\n",
      "    y: float = Field(\n",
      "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
      "    )\n",
      "    time: datetime = Field(\n",
      "        ...,\n",
      "        examples=[\"2020-04-23 10:20:30.400000\"],\n",
      "        description=\"The timestamp of the record\",\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_output_data = broker.publisher(\"output_data\")\n",
      "\n",
      "\n",
      "@broker.subscriber(\"input_data\")\n",
      "async def on_input_data(\n",
      "    msg: Point, logger: Logger, key: bytes = Context(\"message.raw_message.key\")\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'input_data' topic.\n",
      "    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n",
      "    The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'input_data' topic.\n",
      "    2. Create a new message object (do not directly modify the original).\n",
      "    3. Increment msg x and y attributes with 1.\n",
      "    4. Publish that message to the output_data topic (The same partition key should be used in the input_data and output_data topic).\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application using localhost kafka broker.\n",
      "The app should consume messages from the input_data topic.\n",
      "The input message is a JSON encoded object including two attributes:\n",
      "    - x: float\n",
      "    - y: float\n",
      "\n",
      "While consuming the message, increment x and y attributes by 1 and publish that message to the output_data topic.\n",
      "Use messages attribute x as a partition key when publishing to output_data topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "from faststream import FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Point(BaseModel):\n",
      "    x: float = Field(\n",
      "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
      "    )\n",
      "    y: float = Field(\n",
      "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_output_data = broker.publisher(\"output_data\")\n",
      "\n",
      "\n",
      "@broker.subscriber(\"input_data\")\n",
      "async def on_input_data(msg: Point, logger: Logger) -> None:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'input_data' topic.\n",
      "    Increment msg x and y attributes with 1 and publish that message to the output_data topic.\n",
      "    Publish that message to the output_data topic\n",
      "    Use messages attribute x as a partition key when publishing to output_data topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'input_data' topic.\n",
      "    2. Create a new message object (do not directly modify the original).\n",
      "    3. Increment msg x and y attributes with 1.\n",
      "    4. Publish that message to the output_data topic (Use messages attribute x as a partition key).\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "==== EXAMPLE APP DESCRIPTION ====\n",
      "\n",
      "Develop a FastStream application using localhost kafka broker.\n",
      "The app should consume messages from the input_data topic.\n",
      "The input message is a JSON encoded object including two attributes:\n",
      "    - x: float\n",
      "    - y: float\n",
      "    - time: datetime\n",
      "\n",
      "input_data topic should use partition key.\n",
      "\n",
      "Keep all the previous messages in the memory.\n",
      "While consuming the message, add all x elements from the memory (x_sum) and all y from the memory (y_sum) and publish the message with x_sum and y_sum to the output_data topic.\n",
      "The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "\n",
      "from datetime import datetime\n",
      "from typing import List\n",
      "\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "from faststream import Context, ContextRepo, FastStream, Logger\n",
      "from faststream.kafka import KafkaBroker\n",
      "\n",
      "\n",
      "class Point(BaseModel):\n",
      "    x: float = Field(\n",
      "        ..., examples=[0.5], description=\"The X Coordinate in the coordinate system\"\n",
      "    )\n",
      "    y: float = Field(\n",
      "        ..., examples=[0.5], description=\"The Y Coordinate in the coordinate system\"\n",
      "    )\n",
      "    time: datetime = Field(\n",
      "        ...,\n",
      "        examples=[\"2020-04-23 10:20:30.400000\"],\n",
      "        description=\"The timestamp of the record\",\n",
      "    )\n",
      "\n",
      "\n",
      "broker = KafkaBroker(\"localhost:9092\")\n",
      "app = FastStream(broker)\n",
      "\n",
      "\n",
      "to_output_data = broker.publisher(\"output_data\")\n",
      "\n",
      "\n",
      "@app.on_startup\n",
      "async def app_setup(context: ContextRepo):\n",
      "    \"\"\"\n",
      "    Set all necessary global variables inside ContextRepo object:\n",
      "        Set message_history for storing all input messages\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n",
      "@broker.subscriber(\"input_data\")\n",
      "async def on_input_data(\n",
      "    msg: Point,\n",
      "    logger: Logger,\n",
      "    message_history: List[Point] = Context(),\n",
      "    key: bytes = Context(\"message.raw_message.key\"),\n",
      ") -> None:\n",
      "    \"\"\"\n",
      "    Processes a message from the 'input_data' topic.\n",
      "    Add all x elements from the memory (x_sum) and all y from the memory (y_sum) and publish the message with x_sum and y_sum to the output_data topic.\n",
      "    The same partition key should be used in the input_data and output_data topic.\n",
      "\n",
      "    Instructions:\n",
      "    1. Consume a message from 'input_data' topic.\n",
      "    2. Create a new message object (do not directly modify the original).\n",
      "    3. Add all x elements from the memory (x_sum) and all y from the memory (y_sum)\n",
      "    4. Publish the message with x_sum and y_sum to the output_data topic. (The same partition key should be used in the input_data and output_data topic).\n",
      "    \"\"\"\n",
      "    raise NotImplementedError()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Create a FastStream application using localhost broker for testing and use the default port number. \n",
    "It should consume messages from the \"input_data\" topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
    "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
    "\"\"\"\n",
    "\n",
    "actual = get_relevant_prompt_examples(query)\n",
    "\n",
    "\n",
    "\n",
    "assert \"==== EXAMPLE APP DESCRIPTION ====\" in actual[\"description_to_skeleton\"]\n",
    "assert \"==== app_skeleton.py starts ====\" not in actual[\"description_to_skeleton\"]\n",
    "print(actual[\"description_to_skeleton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc8b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class CustomAIChat:\n",
    "    \"\"\"Custom class for interacting with OpenAI\n",
    "\n",
    "    Attributes:\n",
    "        model: The OpenAI model to use. If not passed, defaults to gpt-3.5-turbo-16k.\n",
    "        system_prompt: Initial system prompt to the AI model. If not passed, defaults to SYSTEM_PROMPT.\n",
    "        initial_user_prompt: Initial user prompt to the AI model.\n",
    "        params: Parameters to use while initiating the OpenAI chat model. DEFAULT_PARAMS used if not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str,\n",
    "        user_prompt: Optional[str] = None,\n",
    "        params: Dict[str, float] = DEFAULT_PARAMS,\n",
    "        semantic_search_query: Optional[str] = None,\n",
    "    ):\n",
    "        \"\"\"Instantiates a new CustomAIChat object.\n",
    "\n",
    "        Args:\n",
    "            model: The OpenAI model to use. If not passed, defaults to gpt-3.5-turbo-16k.\n",
    "            user_prompt: The user prompt to the AI model.\n",
    "            params: Parameters to use while initiating the OpenAI chat model. DEFAULT_PARAMS used if not provided.\n",
    "            semantic_search_query: A query string to fetch relevant documents from the database\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.messages = [\n",
    "            {\"role\": role, \"content\": content}\n",
    "            for role, content in [\n",
    "                (\"system\", SYSTEM_PROMPT),\n",
    "                (\"user\", self._get_doc(semantic_search_query)),\n",
    "                (\"user\", user_prompt),\n",
    "            ]\n",
    "            if content is not None\n",
    "        ]\n",
    "        self.params = params\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc(semantic_search_query: Optional[str] = None) -> str:\n",
    "        if semantic_search_query is None:\n",
    "            return \"\"\n",
    "        return _get_relevant_document(semantic_search_query)\n",
    "    \n",
    "    @_retry_with_exponential_backoff()\n",
    "    def __call__(self, user_prompt: str) -> Tuple[str, Dict[str, int]]:\n",
    "        \"\"\"Call OpenAI API chat completion endpoint and generate a response.\n",
    "\n",
    "        Args:\n",
    "            user_prompt: A string containing user's input prompt.\n",
    "\n",
    "        Returns:\n",
    "            A tuple with AI's response message content and the total number of tokens used while generating the response.\n",
    "        \"\"\"\n",
    "        self.messages.append(\n",
    "            {\"role\": \"user\", \"content\": f\"{user_prompt}\\n==== YOUR RESPONSE ====\\n\"}\n",
    "        )\n",
    "        prompt_str = \"\\n\\n\".join([f\"===Role:{m['role']}===\\n\\nMessage:\\n{m['content']}\" for m in self.messages])\n",
    "        logger.info(f\"\\n\\nPrompt to the model: \\n\\n{prompt_str}\")\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=self.params[\"temperature\"],\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            response[\"choices\"][0][\"message\"][\"content\"],\n",
    "            response[\"usage\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: \n",
      "\n",
      "Prompt to the model: \n",
      "\n",
      "===Role:system===\n",
      "\n",
      "Message:\n",
      "\n",
      "You are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework. \n",
      "\n",
      "You are to abide by the following guidelines:\n",
      "\n",
      "1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n",
      "\n",
      "2. Some prompts might require you to generate code that contains async functions. For example:\n",
      "\n",
      "async def app_setup(context: ContextRepo):\n",
      "    raise NotImplementedError()\n",
      "\n",
      "In such cases, it is necessary to add the \"import asyncio\" statement at the top of the code. \n",
      "\n",
      "You will encounter sections marked as:\n",
      "\n",
      "==== APP DESCRIPTION: ====\n",
      "\n",
      "These sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n",
      "\n",
      "\n",
      "===Role:user===\n",
      "\n",
      "Message:\n",
      "\n",
      "\n",
      "===Role:user===\n",
      "\n",
      "Message:\n",
      "\n",
      "You should respond with 0, 1 or 2 and nothing else. Below are your rules:\n",
      "\n",
      "==== RULES: ====\n",
      "\n",
      "If the ==== APP DESCRIPTION: ==== section is not related to FastKafka or contains violence, self-harm, harassment/threatening or hate/threatening information then you should respond with 0.\n",
      "\n",
      "If the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses on what is it and its general information then you should respond with 1. \n",
      "\n",
      "If the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses how to use it and instructions to create a new app then you should respond with 2. \n",
      "\n",
      "\n",
      "===Role:user===\n",
      "\n",
      "Message:\n",
      "Name the tallest mountain in the world\n",
      "==== YOUR RESPONSE ====\n",
      "\n",
      "0\n",
      "{\n",
      "  \"prompt_tokens\": 348,\n",
      "  \"completion_tokens\": 1,\n",
      "  \"total_tokens\": 349\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "TEST_INITIAL_USER_PROMPT = \"\"\"\n",
    "You should respond with 0, 1 or 2 and nothing else. Below are your rules:\n",
    "\n",
    "==== RULES: ====\n",
    "\n",
    "If the ==== APP DESCRIPTION: ==== section is not related to FastKafka or contains violence, self-harm, harassment/threatening or hate/threatening information then you should respond with 0.\n",
    "\n",
    "If the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses on what is it and its general information then you should respond with 1. \n",
    "\n",
    "If the ==== APP DESCRIPTION: ==== section is related to FastKafka but focuses how to use it and instructions to create a new app then you should respond with 2. \n",
    "\"\"\"\n",
    "\n",
    "ai = CustomAIChat(user_prompt = TEST_INITIAL_USER_PROMPT, model=OpenAIModel.gpt3.value)\n",
    "response, usage = ai(\"Name the tallest mountain in the world\")\n",
    "\n",
    "print(response)\n",
    "print(usage)\n",
    "\n",
    "assert response == \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a2d87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27da2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b90ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _construct_prompt_with_error_msg(\n",
    "    response: str,\n",
    "    errors: str,\n",
    ") -> str:\n",
    "    \"\"\"Construct prompt message along with the error message.\n",
    "\n",
    "    Args:\n",
    "        prompt: The original prompt string.\n",
    "        response: The invalid response string from OpenAI.\n",
    "        errors: The errors which needs to be fixed in the invalid response.\n",
    "\n",
    "    Returns:\n",
    "        A string combining the original prompt, invalid response, and the error message.\n",
    "    \"\"\"\n",
    "    prompt_with_errors = (\n",
    "        f\"\\n\\n==== YOUR RESPONSE (WITH ISSUES) ====\\n\\n{response}\"\n",
    "        + f\"\\n\\nRead the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\\n\\n{errors}\"\n",
    "    )\n",
    "    return prompt_with_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b93a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==== YOUR RESPONSE (WITH ISSUES) ====\n",
      "\n",
      "some response\n",
      "\n",
      "Read the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n",
      "\n",
      "error 1\n",
      "error 2\n",
      "error 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = \"some response\"\n",
    "errors = \"\"\"error 1\n",
    "error 2\n",
    "error 3\n",
    "\"\"\"\n",
    "\n",
    "expected = \"\"\"\n",
    "\n",
    "==== YOUR RESPONSE (WITH ISSUES) ====\n",
    "\n",
    "some response\n",
    "\n",
    "Read the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n",
    "\n",
    "error 1\n",
    "error 2\n",
    "error 3\n",
    "\"\"\"\n",
    "actual = _construct_prompt_with_error_msg(response, errors)\n",
    "print(actual)\n",
    "\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fc36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class ValidateAndFixResponse:\n",
    "    \"\"\"Generates and validates response from OpenAI\n",
    "\n",
    "    Attributes:\n",
    "        generate: A callable object for generating responses.\n",
    "        validate: A callable object for validating responses.\n",
    "        max_retries: An optional integer specifying the maximum number of attempts to generate and validate a response.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        generate: Callable[..., Any],\n",
    "        validate: Callable[..., Any],\n",
    "        max_retries: Optional[int] = MAX_RETRIES,\n",
    "    ):\n",
    "        self.generate = generate\n",
    "        self.validate = validate\n",
    "        self.max_retries = max_retries\n",
    "\n",
    "    def fix(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        total_usage: List[Dict[str, int]],\n",
    "        step_name: Optional[str] = None,\n",
    "        intermediate_results_path: Optional[str] = None,\n",
    "        **kwargs: Dict[str, Any],\n",
    "    ) -> Tuple[str, List[Dict[str, int]]]:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba664129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def add_tokens_usage(usage_list: List[Dict[str, int]]) -> Dict[str, int]:\n",
    "    \"\"\"Add list of OpenAI \"usage\" dictionaries by categories defined in TOKEN_TYPES (prompt_tokens, completion_tokens and total_tokens).\n",
    "\n",
    "    Args:\n",
    "        usage_list: List of OpenAI \"usage\" dictionaries\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, int]: Dictionary where the keys are TOKEN_TYPES and their values are the sum of OpenAI \"usage\" dictionaries\n",
    "    \"\"\"\n",
    "    added_tokens: Dict[str, int] = defaultdict(int)\n",
    "    for usage in usage_list:\n",
    "        for token_type in TOKEN_TYPES:\n",
    "            added_tokens[token_type] += usage[token_type]\n",
    "            \n",
    "    return added_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = {\n",
    "    \"prompt_tokens\": 129,\n",
    "    \"completion_tokens\": 1,\n",
    "    \"total_tokens\": 130\n",
    "  }\n",
    "assert add_tokens_usage([usage, usage]) == {\n",
    "    \"prompt_tokens\": 258,\n",
    "    \"completion_tokens\": 2,\n",
    "    \"total_tokens\": 260\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa1de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = {\n",
    "    \"prompt_tokens\": 129,\n",
    "    \"completion_tokens\": 1,\n",
    "    \"total_tokens\": 130\n",
    "  }\n",
    "assert add_tokens_usage([defaultdict(int), usage]) == {\n",
    "    \"prompt_tokens\": 129,\n",
    "    \"completion_tokens\": 1,\n",
    "    \"total_tokens\": 130\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d44967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _save_results(\n",
    "    step_name: Optional[str],\n",
    "    intermediate_results_path: Optional[str],\n",
    "    messages: List[Dict[str, str]],\n",
    "    response: str,\n",
    "    error_str: str,\n",
    "    retry_cnt: int,\n",
    "    **kwargs: Dict[str, int],\n",
    ") -> None:\n",
    "    if intermediate_results_path is not None and \"attempt\" in kwargs:\n",
    "        step_dir = Path(intermediate_results_path) / step_name  # type: ignore\n",
    "        step_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        attempt_dir = step_dir / f'attempt_{kwargs[\"attempt\"] + 1}'  # type: ignore\n",
    "        attempt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        try_dir = attempt_dir / f\"try_{retry_cnt+1}\"\n",
    "        try_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        formatted_msg = \"\\n\".join(\n",
    "            [f\"===={m['role']}====\\n\\n{m['content']}\\n\\n\" for m in messages]\n",
    "        )\n",
    "\n",
    "        with open((try_dir / \"input.txt\"), \"w\", encoding=\"utf-8\") as f_input, open(\n",
    "            (try_dir / \"output.txt\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as f_output, open(\n",
    "            (try_dir / \"errors.txt\"), \"w\", encoding=\"utf-8\"\n",
    "        ) as f_errors:\n",
    "            f_input.write(formatted_msg)\n",
    "            f_output.write(response)\n",
    "            f_errors.write(error_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d8ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/tmp/tmpwy7k3fil/app/attempt_3/try_1/errors.txt'), PosixPath('/tmp/tmpwy7k3fil/app/attempt_3/try_1/output.txt'), PosixPath('/tmp/tmpwy7k3fil/app/attempt_3/try_1/input.txt')]\n",
      "[PosixPath('/tmp/tmpwy7k3fil/test/attempt_3/try_1/errors.txt'), PosixPath('/tmp/tmpwy7k3fil/test/attempt_3/try_1/output.txt'), PosixPath('/tmp/tmpwy7k3fil/test/attempt_3/try_1/input.txt')]\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    messages = [{\"role\": \"role\", \"content\": \"content\"}]\n",
    "    kwargs = {\"attempt\": 2}\n",
    "    for step_name in [\"app\", \"test\"]:\n",
    "        _save_results(step_name, d, messages, \"response\", \"error_str\", 0, **kwargs)\n",
    "\n",
    "        step_dir = Path(d) / step_name\n",
    "        assert step_dir.exists()\n",
    "\n",
    "        attempt_dir = step_dir / \"attempt_3\"\n",
    "        assert attempt_dir.exists()\n",
    "\n",
    "        try_dir = attempt_dir / \"try_1\"\n",
    "        assert try_dir.exists()\n",
    "\n",
    "        print(list(Path(try_dir).glob('**/*')))\n",
    "        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"input.txt\").exists()\n",
    "        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"output.txt\").exists()\n",
    "        assert (Path(d) / step_dir / \"attempt_3\" / f\"try_1\" / \"errors.txt\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09edc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "with TemporaryDirectory() as d:\n",
    "    messages = [{\"role\": \"role\", \"content\": \"content\"}]\n",
    "    kwargs = {\n",
    "        \n",
    "    }\n",
    "    _save_results(\"app\", d, messages, \"response\", \"error_str\", 1, **kwargs)\n",
    "    actual = list(Path(d).glob('**/*'))\n",
    "    expected = []\n",
    "    print(actual)\n",
    "    assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbefa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "@patch  # type: ignore\n",
    "def fix(\n",
    "    self: ValidateAndFixResponse,\n",
    "    prompt: str,\n",
    "    total_usage: List[Dict[str, int]],\n",
    "    step_name: Optional[str] = None,\n",
    "    intermediate_results_path: Optional[str] = None,\n",
    "    **kwargs: Dict[str, Any],\n",
    ") -> Tuple[str, List[Dict[str, int]]]:\n",
    "    \"\"\"Fix the response from OpenAI until no errors remain or maximum number of attempts is reached.\n",
    "\n",
    "    Args:\n",
    "        prompt: The initial prompt string.\n",
    "        kwargs: Additional keyword arguments to be passed to the validation function.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response that has passed the validation.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the maximum number of attempts is exceeded and the response has not successfully passed the validation.\n",
    "    \"\"\"\n",
    "    total_tokens_usage: Dict[str, int] = defaultdict(int)\n",
    "    for i in range(self.max_retries):  # type: ignore\n",
    "        response, usage = self.generate(prompt)\n",
    "        total_tokens_usage = add_tokens_usage([total_tokens_usage, usage])\n",
    "        errors = self.validate(response, **kwargs)\n",
    "        error_str = \"\\n\".join(errors)\n",
    "        _save_results(\n",
    "            step_name,\n",
    "            intermediate_results_path,\n",
    "            self.generate.messages,  # type: ignore\n",
    "            response,\n",
    "            error_str,\n",
    "            i,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if len(errors) == 0:\n",
    "            total_usage.append(total_tokens_usage)\n",
    "            return response, total_usage\n",
    "\n",
    "        self.generate.messages[-1][\"content\"] = self.generate.messages[-1][ # type: ignore\n",
    "            \"content\"\n",
    "        ].rsplit(\"==== YOUR RESPONSE ====\", 1)[0]\n",
    "        prompt = _construct_prompt_with_error_msg(response, error_str)\n",
    "        logger.info(f\"Validation failed, trying again...Errors:\\n{error_str}\")\n",
    "\n",
    "    total_usage.append(total_tokens_usage)\n",
    "    if step_name == RESULTS_DIR_NAMES[\"app\"]:\n",
    "        raise ValueError(response, total_usage)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"✘ Error: {MAX_NUM_FIXES_MSG} ({self.max_retries}) exceeded. Unable to fix the following issues. Please try again...\\n{error_str}\\n\\n{INCOMPLETE_DESCRIPTION}\\n{DESCRIPTION_EXAMPLE}\\n\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f88ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====system====\n",
      "\n",
      "\n",
      "You are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework. \n",
      "\n",
      "You are to abide by the following guidelines:\n",
      "\n",
      "1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n",
      "\n",
      "2. Some prompts might require you to generate code that contains async functions. For example:\n",
      "\n",
      "async def app_setup(context: ContextRepo):\n",
      "    raise NotImplementedError()\n",
      "\n",
      "In such cases, it is necessary to add the \"import asyncio\" statement at the top of the code. \n",
      "\n",
      "You will encounter sections marked as:\n",
      "\n",
      "==== APP DESCRIPTION: ====\n",
      "\n",
      "These sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n",
      "\n",
      "\n",
      "\n",
      "====user====\n",
      "\n",
      "some valid prompt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixture_initial_prompt = \"some valid prompt\"\n",
    "expected = \"some valid prompt\"\n",
    "max_retries = 3\n",
    "\n",
    "\n",
    "class FixtureGenerate:\n",
    "    def __init__(self, user_prompt):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "\n",
    "    def __call__(self, prompt):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n",
    "        return fixture_initial_prompt, usage\n",
    "    \n",
    "def fixture_validate(response, attempt):\n",
    "        return []\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    kwargs = {\"attempt\": 0}\n",
    "    fixture_generate = FixtureGenerate(fixture_initial_prompt)\n",
    "    v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n",
    "    actual = v.fix(fixture_initial_prompt, [], RESULTS_DIR_NAMES[\"app\"], d, **kwargs)\n",
    "\n",
    "    assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\").exists()\n",
    "    assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"input.txt\").exists()\n",
    "    assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"output.txt\").exists()\n",
    "    assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"errors.txt\").exists()\n",
    "\n",
    "    with open((Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_1\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbaf85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "('some invalid prompt', [defaultdict(<class 'int'>, {'prompt_tokens': 387, 'completion_tokens': 3, 'total_tokens': 390})])\n",
      "====system====\n",
      "\n",
      "\n",
      "You are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework. \n",
      "\n",
      "You are to abide by the following guidelines:\n",
      "\n",
      "1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n",
      "\n",
      "2. Some prompts might require you to generate code that contains async functions. For example:\n",
      "\n",
      "async def app_setup(context: ContextRepo):\n",
      "    raise NotImplementedError()\n",
      "\n",
      "In such cases, it is necessary to add the \"import asyncio\" statement at the top of the code. \n",
      "\n",
      "You will encounter sections marked as:\n",
      "\n",
      "==== APP DESCRIPTION: ====\n",
      "\n",
      "These sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n",
      "\n",
      "\n",
      "\n",
      "====user====\n",
      "\n",
      "some invalid prompt\n",
      "\n",
      "\n",
      "====user====\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE (WITH ISSUES) ====\n",
      "\n",
      "some invalid prompt\n",
      "\n",
      "Read the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n",
      "\n",
      "error 1\n",
      "error 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixture_initial_prompt = \"some invalid prompt\"\n",
    "max_retries = 3\n",
    "\n",
    "\n",
    "class FixtureGenerate:\n",
    "    def __init__(self, user_prompt):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "\n",
    "    def __call__(self, prompt):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n",
    "        return fixture_initial_prompt, usage\n",
    "\n",
    "\n",
    "fixture_generate = FixtureGenerate(fixture_initial_prompt)\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    def fixture_validate(response, attempt):\n",
    "        return [\"error 1\", \"error 2\"]\n",
    "\n",
    "    expected = 'some invalid prompt'\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        kwargs = {\"attempt\": 0}\n",
    "        v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n",
    "        actual = v.fix(fixture_initial_prompt, [], RESULTS_DIR_NAMES[\"app\"], d, **kwargs)\n",
    "    \n",
    "    print(e.value)\n",
    "    assert expected in e.value.args[0]\n",
    "\n",
    "    for i in range(3):\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"input.txt\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"output.txt\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_{i+1}\" / \"errors.txt\").exists()\n",
    "        \n",
    "    with open((Path(d) / RESULTS_DIR_NAMES[\"app\"] / \"attempt_1\" / f\"try_2\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867b68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "[INFO] __main__: Validation failed, trying again...Errors:\n",
      "error 1\n",
      "error 2\n",
      "✘ Error: Maximum number of retries (3) exceeded. Unable to fix the following issues. Please try again...\n",
      "error 1\n",
      "error 2\n",
      "\n",
      "Please check if your application description is missing some crutial information:\n",
      " - Description of the messages which will be produced/consumed\n",
      " - At least one topic\n",
      " - The business logic to implement while consuming/producing the messages\n",
      "\n",
      "\n",
      "If you're unsure about how to construct the app description, consider the following example for guidance\n",
      "\n",
      "APPLICATION DESCRIPTION EXAMPLE:\n",
      "Create a FastStream application using localhost broker for testing and use the default port number. \n",
      "It should consume messages from the 'input_data' topic, where each message is a JSON encoded object containing a single attribute: 'data'. \n",
      "For each consumed message, create a new message object and increment the value of the data attribute by 1. Finally, send the modified message to the 'output_data' topic.\n",
      "\n",
      "\n",
      "\n",
      "total 12\n",
      "drwx------ 3 harish harish 4096 Sep 26 11:10 .\n",
      "drwxrwxrwt 1 root   root   4096 Sep 26 11:10 ..\n",
      "drwxrwxr-x 3 harish harish 4096 Sep 26 11:10 app-skeleton-generation-logs\n",
      "====system====\n",
      "\n",
      "\n",
      "You are an expert Python developer, tasked to generate executable Python code as a part of your work with the FastStream framework. \n",
      "\n",
      "You are to abide by the following guidelines:\n",
      "\n",
      "1. You must never enclose the generated Python code with ``` python. It is mandatory that the output is a valid and executable Python code. Please ensure this rule is never broken.\n",
      "\n",
      "2. Some prompts might require you to generate code that contains async functions. For example:\n",
      "\n",
      "async def app_setup(context: ContextRepo):\n",
      "    raise NotImplementedError()\n",
      "\n",
      "In such cases, it is necessary to add the \"import asyncio\" statement at the top of the code. \n",
      "\n",
      "You will encounter sections marked as:\n",
      "\n",
      "==== APP DESCRIPTION: ====\n",
      "\n",
      "These sections contain the description of the FastStream app you need to implement. Treat everything below this line, until the end of the prompt, as the description to follow for the app implementation.\n",
      "\n",
      "\n",
      "\n",
      "====user====\n",
      "\n",
      "some invalid prompt\n",
      "\n",
      "\n",
      "====user====\n",
      "\n",
      "\n",
      "\n",
      "==== YOUR RESPONSE (WITH ISSUES) ====\n",
      "\n",
      "some invalid prompt\n",
      "\n",
      "Read the contents of ==== YOUR RESPONSE (WITH ISSUES) ==== section and fix the below mentioned issues:\n",
      "\n",
      "error 1\n",
      "error 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fixture_initial_prompt = \"some invalid prompt\"\n",
    "max_retries = 3\n",
    "\n",
    "\n",
    "class FixtureGenerate:\n",
    "    def __init__(self, user_prompt):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT}]\n",
    "\n",
    "    def __call__(self, prompt):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        usage = {\"prompt_tokens\": 129, \"completion_tokens\": 1, \"total_tokens\": 130}\n",
    "        return fixture_initial_prompt, usage\n",
    "\n",
    "\n",
    "fixture_generate = FixtureGenerate(fixture_initial_prompt)\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    def fixture_validate(response, attempt):\n",
    "        return [\"error 1\", \"error 2\"]\n",
    "\n",
    "    expected = \"\"\"Maximum number of retries (3) exceeded. Unable to fix the following issues. Please try again...\n",
    "error 1\n",
    "error 2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        kwargs = {\"attempt\": 0}\n",
    "        v = ValidateAndFixResponse(fixture_generate, fixture_validate, max_retries)\n",
    "        actual = v.fix(fixture_initial_prompt, [], RESULTS_DIR_NAMES[\"skeleton\"], d, **kwargs)\n",
    "    \n",
    "    print(e.value)\n",
    "    assert expected in str(e.value)\n",
    "    \n",
    "    !ls -la {d}\n",
    "\n",
    "    for i in range(3):\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"input.txt\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"output.txt\").exists()\n",
    "        assert (Path(d) / RESULTS_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_{i+1}\" / \"errors.txt\").exists()\n",
    "        \n",
    "    with open((Path(d) / RESULTS_DIR_NAMES[\"skeleton\"] / \"attempt_1\" / f\"try_2\" / \"input.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
