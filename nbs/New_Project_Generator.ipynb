{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8860aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp _components.new_project_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb199c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "from typing import *\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "from yaspin import yaspin\n",
    "\n",
    "from faststream_gen._components.logger import get_logger\n",
    "from faststream_gen._code_generator.helper import (\n",
    "    download_and_extract_faststream_archive,\n",
    "    write_file_contents,\n",
    "    read_file_contents,\n",
    "    CustomAIChat,\n",
    "    ValidateAndFixResponse\n",
    ")\n",
    "\n",
    "from faststream_gen._code_generator.constants import (\n",
    "    FASTSTREAM_TEMPLATE_ZIP_URL,\n",
    "    FASTSTREAM_TEMPLATE_DIR_SUFFIX,\n",
    "    INTERMEDIATE_RESULTS_DIR_NAME,\n",
    "    APPLICATION_FILE_NAME,\n",
    "    INTEGRATION_TEST_FILE_NAME\n",
    ")\n",
    "\n",
    "from faststream_gen._code_generator.prompts import REQUIREMENTS_GENERATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750acc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pytest\n",
    "\n",
    "from faststream_gen._components.logger import suppress_timestamps\n",
    "from faststream_gen._code_generator.constants import DESCRIPTION_FILE_NAME, OpenAIModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654172e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] __main__: ok\n"
     ]
    }
   ],
   "source": [
    "suppress_timestamps()\n",
    "logger = get_logger(__name__, level=20)\n",
    "logger.info(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad12a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def _split_requirements(response: str) -> Tuple[str, str]:\n",
    "    app_code, test_code = response.split(\"### requirements.txt ###\")[1].split(\"### dev_requirements.txt ###\")\n",
    "    return app_code, test_code\n",
    "\n",
    "def _validate_response(response: str) -> List[str]:\n",
    "    try:\n",
    "        requirements, dev_requirements = _split_requirements(response)\n",
    "        return []\n",
    "    except (IndexError, ValueError) as e:\n",
    "        return [\n",
    "            \"Please add ### requirements.txt ### and ### dev_requirements.txt ### in your response\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5a13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "fixture_response = \"\"\"\n",
    "### requirements.txt ###\n",
    "pandas\n",
    "\n",
    "### dev_requirements.txt ###\n",
    "pytest\n",
    "\"\"\"\n",
    "\n",
    "expected = []\n",
    "actual = _validate_response(fixture_response)\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Please add ### requirements.txt ### and ### dev_requirements.txt ### in your response']\n"
     ]
    }
   ],
   "source": [
    "fixture_response = \"\"\"\n",
    "### requirements.txt ###\n",
    "pandas\n",
    "\n",
    "### dev_requirements.txt ##\n",
    "pytest\n",
    "\"\"\"\n",
    "\n",
    "expected = ['Please add ### requirements.txt ### and ### dev_requirements.txt ### in your response']\n",
    "actual = _validate_response(fixture_response)\n",
    "print(actual)\n",
    "assert actual == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def _generate_requirements(\n",
    "    d: str, model: str, total_usage: List[Dict[str, int]]\n",
    ") -> Tuple[str, str, List[Dict[str, int]]]:\n",
    "    \n",
    "    app_code = read_file_contents(f\"{d}/app/application.py\")\n",
    "    requirements = read_file_contents(f\"{d}/requirements.txt\")\n",
    "    dev_requirements = read_file_contents(f\"{d}/dev_requirements.txt\")\n",
    "\n",
    "    prompt = (\n",
    "        REQUIREMENTS_GENERATION_PROMPT\n",
    "        + app_code\n",
    "        + \"\\n==== REQUIREMENT ====\\n\"\n",
    "        + requirements\n",
    "        + \"\\n==== DEV REQUIREMENT ====\\n\"\n",
    "        + dev_requirements\n",
    "    )\n",
    "    requirements_generator = CustomAIChat(\n",
    "        model=model,\n",
    "        user_prompt=prompt,\n",
    "    )\n",
    "    requirements_validator = ValidateAndFixResponse(\n",
    "        requirements_generator, _validate_response\n",
    "    )\n",
    "    requirements, total_usage = requirements_validator.fix(\n",
    "        prompt,\n",
    "        total_usage=total_usage,\n",
    "    )\n",
    "\n",
    "    requirements, dev_requirements = _split_requirements(\n",
    "        requirements\n",
    "    )\n",
    "\n",
    "    return requirements, dev_requirements, total_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69729007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "faststream[rabbit, docs]==0.0.1.dev20230912\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faststream[rabbit, testing]==0.0.1.dev20230912\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "fixture = \"\"\"\n",
    "from faststream import FastStream\n",
    "from faststream.rabbit import RabbitBroker\n",
    "\n",
    "broker = RabbitBroker()\n",
    "app = FastStream(broker)\n",
    "\n",
    "\n",
    "@broker.subscriber(\"routing_key\")  # handle messages by routing key\n",
    "async def handle(msg):\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "@app.after_startup\n",
    "async def test_publish():\n",
    "    await broker.publish(\n",
    "        \"message\",\n",
    "        \"routing_key\",  # publish message with routing key\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    app_code = write_file_contents(f\"{d}/app/application.py\", fixture)\n",
    "    requirements = write_file_contents(\n",
    "        f\"{d}/requirements.txt\", \"\\nfaststream[docs]==0.0.1.dev20230912\"\n",
    "    )\n",
    "    dev_requirements = write_file_contents(\n",
    "        f\"{d}/dev_requirements.txt\", \"\\nfaststream[testing]==0.0.1.dev20230912\"\n",
    "    )\n",
    "\n",
    "    requirements, dev_requirements, total_usage = _generate_requirements(d, OpenAIModel.gpt4.value, [])\n",
    "\n",
    "    print(requirements)\n",
    "    assert requirements.replace(\"\\n\", \"\") == \"faststream[rabbit, docs]==0.0.1.dev20230912\"\n",
    "    \n",
    "    print(dev_requirements)\n",
    "    assert dev_requirements.replace(\"\\n\", \"\") == \"faststream[rabbit, testing]==0.0.1.dev20230912\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ebadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_project(\n",
    "    output_path: str,\n",
    "    save_intermediate_files: bool,\n",
    "    model: str,\n",
    "    total_usage: List[Dict[str, int]],\n",
    ") -> List[Dict[str, int]]:\n",
    "    with yaspin(\n",
    "        text=\"Creating a new FastStream project...\", color=\"cyan\", spinner=\"clock\"\n",
    "    ) as sp:\n",
    "        with download_and_extract_faststream_archive(\n",
    "            FASTSTREAM_TEMPLATE_ZIP_URL\n",
    "        ) as extracted_path:\n",
    "            with TemporaryDirectory() as tmp_dir:\n",
    "                app_path = f\"{tmp_dir}/app/application.py\"\n",
    "                test_path = f\"{tmp_dir}/tests/test_application.py\"\n",
    "\n",
    "                intermediate_dir_path = f\"{output_path}/{INTERMEDIATE_RESULTS_DIR_NAME}\"\n",
    "                shutil.copytree(\n",
    "                    str(extracted_path / FASTSTREAM_TEMPLATE_DIR_SUFFIX),\n",
    "                    tmp_dir,\n",
    "                    dirs_exist_ok=True,\n",
    "                )\n",
    "                shutil.copy(\n",
    "                    f\"{intermediate_dir_path}/{APPLICATION_FILE_NAME}\", app_path\n",
    "                )\n",
    "                shutil.copy(\n",
    "                    f\"{intermediate_dir_path}/{INTEGRATION_TEST_FILE_NAME}\", test_path\n",
    "                )\n",
    "\n",
    "                test_file_contents = read_file_contents(test_path)\n",
    "                test_file_contents = test_file_contents.replace(\n",
    "                    \"from application import\", \"from app.application import\"\n",
    "                )\n",
    "                write_file_contents(test_path, test_file_contents)\n",
    "\n",
    "                requirements, dev_requirements, total_usage = _generate_requirements(tmp_dir, model, total_usage)\n",
    "\n",
    "                requirements_file = f\"{tmp_dir}/requirements.txt\"\n",
    "                write_file_contents(requirements_file, requirements)\n",
    "\n",
    "                dev_requirements_file = f\"{tmp_dir}/dev_requirements.txt\"\n",
    "                write_file_contents(dev_requirements_file, dev_requirements)\n",
    "\n",
    "                shutil.copytree(tmp_dir, output_path, dirs_exist_ok=True)\n",
    "                if not save_intermediate_files:\n",
    "                    shutil.rmtree(intermediate_dir_path)\n",
    "\n",
    "        sp.text = \"\"\n",
    "        sp.ok(f\" ✔ New FastStream project created.\")\n",
    "        return total_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9cdae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ✔ New FastStream project created.     \n",
      "['README', '.github', 'dev_requirements', 'LICENSE', '_faststream_gen_tmp', 'tests', 'app', 'requirements', '.gitignore']\n",
      " ✔ New FastStream project created.     \n",
      "['README', '.github', 'dev_requirements', 'LICENSE', 'tests', 'app', 'requirements', '.gitignore']\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "fixture_application_code = \"\"\"\n",
    "message = \"hi\"\n",
    "print(message)\n",
    "\"\"\"\n",
    "\n",
    "fixture_test_code = \"\"\"\n",
    "from application import message\n",
    "\"\"\"\n",
    "\n",
    "fixture_description = \"\"\"\n",
    "description\n",
    "\"\"\"\n",
    "\n",
    "for flag in [True, False]:\n",
    "    with TemporaryDirectory() as d:\n",
    "        intermediate_results_dir = Path(d)/INTERMEDIATE_RESULTS_DIR_NAME\n",
    "        intermediate_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        app_file_name = intermediate_results_dir / APPLICATION_FILE_NAME\n",
    "        write_file_contents(str(app_file_name), fixture_application_code)\n",
    "\n",
    "        test_file_name = intermediate_results_dir / INTEGRATION_TEST_FILE_NAME\n",
    "        write_file_contents(str(test_file_name), fixture_test_code)\n",
    "\n",
    "        description_file_name = intermediate_results_dir / DESCRIPTION_FILE_NAME\n",
    "        write_file_contents(str(description_file_name), fixture_description)\n",
    "\n",
    "        create_project(d, flag, OpenAIModel.gpt4.value, [])\n",
    "        files = [p.stem for p in list(Path(f\"{d}\").glob(\"*\"))]\n",
    "        print(files)\n",
    "        if flag:\n",
    "            assert INTERMEDIATE_RESULTS_DIR_NAME in files\n",
    "        else:\n",
    "            assert INTERMEDIATE_RESULTS_DIR_NAME not in files\n",
    "        assert \"README\" in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ece203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
